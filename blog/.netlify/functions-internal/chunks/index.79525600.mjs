import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead, d as renderComponent } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           *//* empty css                           *//* empty css                          */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "discovery-of-deepgram-ai-speech-to-text", "text": "Discovery of Deepgram AI Speech-to-Text" }, { "depth": 2, "slug": "python-code-for-ai-machine-learning-topic-detection", "text": "Python Code for AI Machine Learning Topic Detection" }, { "depth": 2, "slug": "conclusion", "text": "Conclusion" }, { "depth": 2, "slug": "full-python-code-for-the-ai-machine-learning-podcast-topic-detection-project", "text": "Full Python Code for the AI Machine Learning Podcast Topic Detection Project" }], "source": "Imagine you\u2019re a Python Machine Learning Engineer. Your work day is getting ready to start with the dreaded stand-up meeting, but you're looking the most forward to deep diving into topic detection algorithms.\n\n<Panel title=\"Important Note\">\n\nIf you want to see the whole Python code snippet for topic detection, please scroll to the bottom of this post.\n\n</Panel>\n\nYou step out to get coffee down the street. A black SUV pulls up next to you, the door opens, and someone tells you to get in the truck.\n\nThey explain that your Machine Learning Python prowess is needed badly.\n\nWhy?\n\nThey need you to transcribe a podcast from speech-to-text urgently. But not just any podcast. It\u2019s Team Coco\u2019s podcast, the legendary Conan O\u2019Brien. Not only do they need it transcribed using AI speech recognition, but they also require a topic analysis to quickly analyze the topics to discover what the podcast is about.\n\nThey can\u2019t say too much about the underground Operation Machine Learning Topic Detection, other than if you can\u2019t deliver the topic modeling results or tell anyone, something terrible may happen.\n\nWeird. Ironic but weird. Yesterday, you learned about the TF-IDF (Term Frequency - Inverse Document Frequency) topic detection algorithm.\n\nYou should feel confident in your Python and Machine Learning abilities, but you have some reservations.\n\nYou think about telling your manager but remember what they said about something terrible that may happen.\n\nYou\u2019re going through self-doubt, and most importantly, you\u2019re not even sure where to start with transcribing audio speech-to-text in Python.\n\nWhat if something bad does happen if you don\u2019t complete the topic detection request?\n\nYou decide to put on your superhero cape and take on the challenge because your life could depend on it.\n\n## Discovery of Deepgram AI Speech-to-Text\n\nYou\u2019re back at your home office and not sure where to start with finding a Python speech-to-text audio transcription provider.\n\nYou try using Company A\u2019s transcription with Python, but it takes a long time to get back a transcript. Besides, the file you need to transcribe is over an hour long, and you don\u2019t have time to waste.\n\nYou try Company B\u2019s transcription again with Python. This time, the transcription comes back faster, but one big problem is accuracy. The words in the speech-to-text audio transcript you\u2019re getting back are inaccurate.\n\nYou want to give up because you don\u2019t think you\u2019ll be able to find a superior company with an API that provides transcription.\n\nThen you discover Deepgram, and everything changes.\n\nDeepgram is an AI automated speech recognition voice-to-text company that allows us to build applications that transcribe speech-to-text.\n\nYou loved how effortless it is to sign up for Deepgram by quickly grabbing a Deepgram API Key [from our website](https://console.deepgram.com/signup?jump=keys). You also immediately get hands-on experience after signing up by trying out their console missions for transcribing prerecorded audio in a matter of a few minutes.\n\nThere\u2019s even better news!\n\nDeepgam has much higher transcription accuracy than other providers, and you receive a transcript back super fast. You also discover they have a Python SDK that you can use.\n\nIt\u2019s do-or-(maybe)-die time.\n\nYou hear a tornado warning siren, but disregard it and start coding.\n\nYou won\u2019t let anything get in your way, not even a twister.\n\n## Python Code for AI Machine Learning Topic Detection\n\nYou first create a [virtual environment](https://blog.deepgram.com/python-virtual-environments/) to install your Python packages inside.\n\nNext, from the command line, you `pip install` the following Python packages inside of the virtual environment:\n\n```\npip install deepgram-sdk\npip install python-dotenv\npip install -U scikit-learn\npip install -U nltk\n```\n\nThen you create a `.env` file inside your project directory to hold your Deepgram API Key, so it\u2019s not exposed to the whole world. Inside of your `.env` file, you assign your API Key from Deepgram to a variable `DEEPGRAM_API_KEY, like so:\n\n```\nDEEPGRAM_AP_KEY=\u201Dabc123\u201D\n```\n\nNext, you create a new file called `python_topic_detection.py. You write the following code that imports Python libraries and handles the Deepgram prerecorded audio speech-to-text transcription:\n\n```python\nfrom ast import keyword\nfrom posixpath import split\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom nltk.corpus import stopwords\nimport asyncio\nimport json\nimport os\nimport nltk\n\n\nload_dotenv()\n\nPATH_TO_FILE = 'conan_podcast.mp3'\n\nasync def transcribe_with_deepgram():\n  # Initializes the Deepgram SDK\n  deepgram = Deepgram(os.getenv(\"DEEPGRAM_API_KEY\"))\n  # Open the audio file\n  with open(PATH_TO_FILE, 'rb') as audio:\n      # ...or replace mimetype as appropriate\n      source = {'buffer': audio, 'mimetype': 'audio/mp3'}\n      response = await deepgram.transcription.prerecorded(source)\n\n      if 'transcript' in response['results']['channels'][0]['alternatives'][0]:\n          transcript = response['results']['channels'][0]['alternatives'][0]['transcript']\n\n          return transcript\n```\n\nThe `transcribe_with_deepgram()` function comes from our Deepgram Python SDK, located [here in Github](https://github.com/deepgram/python-sdk).\n\nIn this method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the `prerecorded` transcription option to transcribe a recorded file to text.\n\nYou\u2019re on a roll!\n\nNext, you start writing the code for the TF-IDF Machine Learning algorithm to handle the topic detection. The tornado knocks out your power, and you realize you only have 20% laptop battery life.\n\nYou need to hurry and continue writing the following code in the same file:\n\n```python\nasync def remove_stop_words():\n  transcript_text = await transcribe_with_deepgram()\n  words = transcript_text.split()\n  final = []\n\n  nltk.download('stopwords')\n  stops = stopwords.words('english')\n\n  for word in words:\n      if word not in stops:\n          final.append(word)\n\n  final = \" \".join(final)\n\n  return final\n\n\nasync def cleaned_docs_to_vectorize():\n  final_list = []\n  transcript_final = await remove_stop_words()\n\n  split_transcript = transcript_final.split()\n\n  vectorizer = TfidfVectorizer(\n                              lowercase=True,\n                              max_features=100,\n                              max_df=0.8,\n                              min_df=4,\n                              ngram_range=(1,3),\n                              stop_words='english'\n\n                          )\n\n\n  vectors = vectorizer.fit_transform(split_transcript)\n\n  feature_names = vectorizer.get_feature_names()\n\n  dense = vectors.todense()\n  denselist = dense.tolist()\n\n  all_keywords = []\n\n  for description in denselist:\n      x = 0\n      keywords = []\n      for word in description:\n          if word > 0:\n              keywords.append(feature_names[x])\n          x=x+1\n\n      [all_keywords.append(x) for x in keywords if x not in all_keywords]\n   topic = \"\\n\".join(all_keywords)\n  print(topic)\n\n  k = 10\n\n  model = KMeans(n_clusters=k, init=\"k-means++\", max_iter=100, n_init=1)\n\n  model.fit(vectors)\n\n  centroids = model.cluster_centers_.argsort()[:, ::-1]\n\n  terms = vectorizer.get_feature_names()\n   with open(\"results.txt\", \"w\", encoding=\"utf-8\") as f:\n      for i in range(k):\n          f.write(f\"Cluster {i}\")\n          f.write(\"\\n\")\n          for ind in centroids[i, :10]:\n              f.write(' %s' % terms[ind],)\n              f.write(\"\\n\")\n          f.write(\"\\n\")\n          f.write(\"\\n\")\n\nasyncio.run(cleaned_docs_to_vectorize())\n```\n\nIn this code, you create a new function called `cleaned_docs_to_vectorize()`, which will get the previous method's transcript and remove any stop words. Stop words are unimportant, like `a, the, and, this` etc.\n\nThe algorithm will then perform the TF-IDF vectorization using these lines of code:\n\n```python\nvectorizer = TfidfVectorizer(\n                              lowercase=True,\n                              max_features=100,\n                              max_df=0.8,\n                              min_df=4,\n                              ngram_range=(1,3),\n                              stop_words='english'\n\n                          )\n```\n\nYou quickly read about the options passed into the vectorizer like `max_features` and `max_df` [on sciki-learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n\nYou have a little bit on time with 15% battery life, so you decide to use K-Means to create 10 clusters of topics. This way, they can get a more meaningful sense of the data structure from the podcast. You write the K-Means clusters to a file called `results.txt`.\n\nTo run the program, type `python3 python_topic_detection.py` from the terminal.\n\nWhen you print the topics, you see a list like the following:\n\n```\nsort\nlittle\nsitting\nwent\nnew\nknew\ncomedy\nremember\nguys\nfunny\njerry\nclub\npoint\ngilbert\nyork\nchris\nrock\nfamous\nlater\ngetting\nlong\nlove\nnight\nyear\nbob\nnorm\ncar\nnews\nspace\nastronauts\nnasa\n```\n\nBingo!\n\nYou can now make inferences about the AI Topic Detection to determine the subject matter of the podcast episode.\n\nThen, peek at your `results.txt` file to verify that you received 10 clusters. Here\u2019s an example of four of the ten groups of words using KMeans clustering:\n\n```\nCluster 0\nyeah\nthink\nve\nroast\ngot\nspace\ncat\nsay\njoke\noh\n\n\nCluster 1\nperson\nyork\njoke\ngonna\ngood\ngot\ngreat\nguy\nguys\nheard\n\n\nCluster 2\nknow\nyork\njokes\ngonna\ngood\ngot\ngreat\nguy\nguys\nheard\n\n\nCluster 3\nright\nyork\njoke\ngonna\ngood\ngot\ngreat\nguy\nguys\nheard\n```\n\nJust before your laptop battery dies, you show them the topics for Team Coco. They are very happy with your results and drive off.\n\nYou\u2019re feeling more confident than ever.\n\nYou\u2019ll never know why they needed the Machine Learning topic detection or why they chose you, but you\u2019re on top of the world right now.\n\n## Conclusion\n\nCongratulations on building the Topic Detection AI Python project with Deepgram. Now that you made it to the end of this blog post, Tweet us at [@DeepgramAI](https://twitter.com/DeepgramAI) if you have any questions or to let us know how you enjoyed this post.\n\n## Full Python Code for the AI Machine Learning Podcast Topic Detection Project\n\n```python\nfrom ast import keyword\nfrom posixpath import split\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom nltk.corpus import stopwords\nimport asyncio\nimport json\nimport os\nimport nltk\n\n\nload_dotenv()\n\nPATH_TO_FILE = 'conan_podcast.mp3'\n\nasync def transcribe_with_deepgram():\n  # Initializes the Deepgram SDK\n  deepgram = Deepgram(os.getenv(\"DEEPGRAM_API_KEY\"))\n  # Open the audio file\n  with open(PATH_TO_FILE, 'rb') as audio:\n      # ...or replace mimetype as appropriate\n      source = {'buffer': audio, 'mimetype': 'audio/mp3'}\n      response = await deepgram.transcription.prerecorded(source)\n\n      if 'transcript' in response['results']['channels'][0]['alternatives'][0]:\n          transcript = response['results']['channels'][0]['alternatives'][0]['transcript']\n\n          return transcript\n\nasync def remove_stop_words():\n  transcript_text = await transcribe_with_deepgram()\n  words = transcript_text.split()\n  final = []\n\n  nltk.download('stopwords')\n  stops = stopwords.words('english')\n\n  for word in words:\n      if word not in stops:\n          final.append(word)\n\n  final = \" \".join(final)\n\n  return final\n\n\nasync def cleaned_docs_to_vectorize():\n  final_list = []\n  transcript_final = await remove_stop_words()\n\n  split_transcript = transcript_final.split()\n\n  vectorizer = TfidfVectorizer(\n                              lowercase=True,\n                              max_features=100,\n                              max_df=0.8,\n                              min_df=4,\n                              ngram_range=(1,3),\n                              stop_words='english'\n\n                          )\n\n\n  vectors = vectorizer.fit_transform(split_transcript)\n\n  feature_names = vectorizer.get_feature_names()\n\n  dense = vectors.todense()\n  denselist = dense.tolist()\n\n  all_keywords = []\n\n  for description in denselist:\n      x = 0\n      keywords = []\n      for word in description:\n          if word > 0:\n              keywords.append(feature_names[x])\n          x=x+1\n\n      [all_keywords.append(x) for x in keywords if x not in all_keywords]\n   topic = \"\\n\".join(all_keywords)\n  print(topic)\n\n  k = 10\n\n  model = KMeans(n_clusters=k, init=\"k-means++\", max_iter=100, n_init=1)\n\n  model.fit(vectors)\n\n  centroids = model.cluster_centers_.argsort()[:, ::-1]\n\n  terms = vectorizer.get_feature_names()\n   with open(\"results.txt\", \"w\", encoding=\"utf-8\") as f:\n      for i in range(k):\n          f.write(f\"Cluster {i}\")\n          f.write(\"\\n\")\n          for ind in centroids[i, :10]:\n              f.write(' %s' % terms[ind],)\n              f.write(\"\\n\")\n          f.write(\"\\n\")\n          f.write(\"\\n\")\n\nasyncio.run(cleaned_docs_to_vectorize())\n```", "html": '<p>Imagine you\u2019re a Python Machine Learning Engineer. Your work day is getting ready to start with the dreaded stand-up meeting, but you\u2019re looking the most forward to deep diving into topic detection algorithms.</p>\n<Panel title="Important Note"><p>If you want to see the whole Python code snippet for topic detection, please scroll to the bottom of this post.</p></Panel>\n<p>You step out to get coffee down the street. A black SUV pulls up next to you, the door opens, and someone tells you to get in the truck.</p>\n<p>They explain that your Machine Learning Python prowess is needed badly.</p>\n<p>Why?</p>\n<p>They need you to transcribe a podcast from speech-to-text urgently. But not just any podcast. It\u2019s Team Coco\u2019s podcast, the legendary Conan O\u2019Brien. Not only do they need it transcribed using AI speech recognition, but they also require a topic analysis to quickly analyze the topics to discover what the podcast is about.</p>\n<p>They can\u2019t say too much about the underground Operation Machine Learning Topic Detection, other than if you can\u2019t deliver the topic modeling results or tell anyone, something terrible may happen.</p>\n<p>Weird. Ironic but weird. Yesterday, you learned about the TF-IDF (Term Frequency - Inverse Document Frequency) topic detection algorithm.</p>\n<p>You should feel confident in your Python and Machine Learning abilities, but you have some reservations.</p>\n<p>You think about telling your manager but remember what they said about something terrible that may happen.</p>\n<p>You\u2019re going through self-doubt, and most importantly, you\u2019re not even sure where to start with transcribing audio speech-to-text in Python.</p>\n<p>What if something bad does happen if you don\u2019t complete the topic detection request?</p>\n<p>You decide to put on your superhero cape and take on the challenge because your life could depend on it.</p>\n<h2 id="discovery-of-deepgram-ai-speech-to-text">Discovery of Deepgram AI Speech-to-Text</h2>\n<p>You\u2019re back at your home office and not sure where to start with finding a Python speech-to-text audio transcription provider.</p>\n<p>You try using Company A\u2019s transcription with Python, but it takes a long time to get back a transcript. Besides, the file you need to transcribe is over an hour long, and you don\u2019t have time to waste.</p>\n<p>You try Company B\u2019s transcription again with Python. This time, the transcription comes back faster, but one big problem is accuracy. The words in the speech-to-text audio transcript you\u2019re getting back are inaccurate.</p>\n<p>You want to give up because you don\u2019t think you\u2019ll be able to find a superior company with an API that provides transcription.</p>\n<p>Then you discover Deepgram, and everything changes.</p>\n<p>Deepgram is an AI automated speech recognition voice-to-text company that allows us to build applications that transcribe speech-to-text.</p>\n<p>You loved how effortless it is to sign up for Deepgram by quickly grabbing a Deepgram API Key <a href="https://console.deepgram.com/signup?jump=keys">from our website</a>. You also immediately get hands-on experience after signing up by trying out their console missions for transcribing prerecorded audio in a matter of a few minutes.</p>\n<p>There\u2019s even better news!</p>\n<p>Deepgam has much higher transcription accuracy than other providers, and you receive a transcript back super fast. You also discover they have a Python SDK that you can use.</p>\n<p>It\u2019s do-or-(maybe)-die time.</p>\n<p>You hear a tornado warning siren, but disregard it and start coding.</p>\n<p>You won\u2019t let anything get in your way, not even a twister.</p>\n<h2 id="python-code-for-ai-machine-learning-topic-detection">Python Code for AI Machine Learning Topic Detection</h2>\n<p>You first create a <a href="https://blog.deepgram.com/python-virtual-environments/">virtual environment</a> to install your Python packages inside.</p>\n<p>Next, from the command line, you <code is:raw>pip install</code> the following Python packages inside of the virtual environment:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">pip install deepgram-sdk</span></span>\n<span class="line"><span style="color: #c9d1d9">pip install python-dotenv</span></span>\n<span class="line"><span style="color: #c9d1d9">pip install -U scikit-learn</span></span>\n<span class="line"><span style="color: #c9d1d9">pip install -U nltk</span></span></code></pre>\n<p>Then you create a <code is:raw>.env</code> file inside your project directory to hold your Deepgram API Key, so it\u2019s not exposed to the whole world. Inside of your <code is:raw>.env</code> file, you assign your API Key from Deepgram to a variable `DEEPGRAM_API_KEY, like so:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">DEEPGRAM_AP_KEY=\u201Dabc123\u201D</span></span></code></pre>\n<p>Next, you create a new file called `python_topic_detection.py. You write the following code that imports Python libraries and handles the Deepgram prerecorded audio speech-to-text transcription:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> ast </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> keyword</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> posixpath </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> split</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.feature_extraction.text </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> TfidfVectorizer</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.cluster </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> KMeans</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> nltk.corpus </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> stopwords</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> nltk</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;conan_podcast.mp3&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">  deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">      source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">      response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">          transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> transcript</span></span></code></pre>\n<p>The <code is:raw>transcribe_with_deepgram()</code> function comes from our Deepgram Python SDK, located <a href="https://github.com/deepgram/python-sdk">here in Github</a>.</p>\n<p>In this method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the <code is:raw>prerecorded</code> transcription option to transcribe a recorded file to text.</p>\n<p>You\u2019re on a roll!</p>\n<p>Next, you start writing the code for the TF-IDF Machine Learning algorithm to handle the topic detection. The tornado knocks out your power, and you realize you only have 20% laptop battery life.</p>\n<p>You need to hurry and continue writing the following code in the same file:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">remove_stop_words</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_text </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>\n<span class="line"><span style="color: #C9D1D9">  words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_text.split()</span></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  nltk.download(</span><span style="color: #A5D6FF">&#39;stopwords&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">  stops </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stopwords.words(</span><span style="color: #A5D6FF">&#39;english&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> stops:</span></span>\n<span class="line"><span style="color: #C9D1D9">          final.append(word)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(final)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> final</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">cleaned_docs_to_vectorize</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  final_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> remove_stop_words()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  split_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_final.split()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">                          )</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectors </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.fit_transform(split_transcript)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  feature_names </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  dense </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectors.todense()</span></span>\n<span class="line"><span style="color: #C9D1D9">  denselist </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dense.tolist()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  all_keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> description </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> denselist:</span></span>\n<span class="line"><span style="color: #C9D1D9">      x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>\n<span class="line"><span style="color: #C9D1D9">      keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> description:</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">              keywords.append(feature_names[x])</span></span>\n<span class="line"><span style="color: #C9D1D9">          x</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">x</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      [all_keywords.append(x) </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> keywords </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> all_keywords]</span></span>\n<span class="line"><span style="color: #C9D1D9">   topic </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">.join(all_keywords)</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(topic)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  k </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> KMeans(</span><span style="color: #FFA657">n_clusters</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">k, </span><span style="color: #FFA657">init</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;k-means++&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">max_iter</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">n_init</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model.fit(vectors)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  centroids </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> model.cluster_centers_.argsort()[:, ::</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  terms </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;results.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">encoding</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;utf-8&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(k):</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Cluster </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">i</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ind </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> centroids[i, :</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&#39; </span><span style="color: #79C0FF">%s</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">%</span><span style="color: #C9D1D9"> terms[ind],)</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(cleaned_docs_to_vectorize())</span></span></code></pre>\n<p>In this code, you create a new function called <code is:raw>cleaned_docs_to_vectorize()</code>, which will get the previous method\u2019s transcript and remove any stop words. Stop words are unimportant, like <code is:raw>a, the, and, this</code> etc.</p>\n<p>The algorithm will then perform the TF-IDF vectorization using these lines of code:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">                          )</span></span></code></pre>\n<p>You quickly read about the options passed into the vectorizer like <code is:raw>max_features</code> and <code is:raw>max_df</code> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html">on sciki-learn</a>.</p>\n<p>You have a little bit on time with 15% battery life, so you decide to use K-Means to create 10 clusters of topics. This way, they can get a more meaningful sense of the data structure from the podcast. You write the K-Means clusters to a file called <code is:raw>results.txt</code>.</p>\n<p>To run the program, type <code is:raw>python3 python_topic_detection.py</code> from the terminal.</p>\n<p>When you print the topics, you see a list like the following:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">sort</span></span>\n<span class="line"><span style="color: #c9d1d9">little</span></span>\n<span class="line"><span style="color: #c9d1d9">sitting</span></span>\n<span class="line"><span style="color: #c9d1d9">went</span></span>\n<span class="line"><span style="color: #c9d1d9">new</span></span>\n<span class="line"><span style="color: #c9d1d9">knew</span></span>\n<span class="line"><span style="color: #c9d1d9">comedy</span></span>\n<span class="line"><span style="color: #c9d1d9">remember</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">funny</span></span>\n<span class="line"><span style="color: #c9d1d9">jerry</span></span>\n<span class="line"><span style="color: #c9d1d9">club</span></span>\n<span class="line"><span style="color: #c9d1d9">point</span></span>\n<span class="line"><span style="color: #c9d1d9">gilbert</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">chris</span></span>\n<span class="line"><span style="color: #c9d1d9">rock</span></span>\n<span class="line"><span style="color: #c9d1d9">famous</span></span>\n<span class="line"><span style="color: #c9d1d9">later</span></span>\n<span class="line"><span style="color: #c9d1d9">getting</span></span>\n<span class="line"><span style="color: #c9d1d9">long</span></span>\n<span class="line"><span style="color: #c9d1d9">love</span></span>\n<span class="line"><span style="color: #c9d1d9">night</span></span>\n<span class="line"><span style="color: #c9d1d9">year</span></span>\n<span class="line"><span style="color: #c9d1d9">bob</span></span>\n<span class="line"><span style="color: #c9d1d9">norm</span></span>\n<span class="line"><span style="color: #c9d1d9">car</span></span>\n<span class="line"><span style="color: #c9d1d9">news</span></span>\n<span class="line"><span style="color: #c9d1d9">space</span></span>\n<span class="line"><span style="color: #c9d1d9">astronauts</span></span>\n<span class="line"><span style="color: #c9d1d9">nasa</span></span></code></pre>\n<p>Bingo!</p>\n<p>You can now make inferences about the AI Topic Detection to determine the subject matter of the podcast episode.</p>\n<p>Then, peek at your <code is:raw>results.txt</code> file to verify that you received 10 clusters. Here\u2019s an example of four of the ten groups of words using KMeans clustering:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">Cluster 0</span></span>\n<span class="line"><span style="color: #c9d1d9">yeah</span></span>\n<span class="line"><span style="color: #c9d1d9">think</span></span>\n<span class="line"><span style="color: #c9d1d9">ve</span></span>\n<span class="line"><span style="color: #c9d1d9">roast</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">space</span></span>\n<span class="line"><span style="color: #c9d1d9">cat</span></span>\n<span class="line"><span style="color: #c9d1d9">say</span></span>\n<span class="line"><span style="color: #c9d1d9">joke</span></span>\n<span class="line"><span style="color: #c9d1d9">oh</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">Cluster 1</span></span>\n<span class="line"><span style="color: #c9d1d9">person</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">joke</span></span>\n<span class="line"><span style="color: #c9d1d9">gonna</span></span>\n<span class="line"><span style="color: #c9d1d9">good</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">great</span></span>\n<span class="line"><span style="color: #c9d1d9">guy</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">heard</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">Cluster 2</span></span>\n<span class="line"><span style="color: #c9d1d9">know</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">jokes</span></span>\n<span class="line"><span style="color: #c9d1d9">gonna</span></span>\n<span class="line"><span style="color: #c9d1d9">good</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">great</span></span>\n<span class="line"><span style="color: #c9d1d9">guy</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">heard</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">Cluster 3</span></span>\n<span class="line"><span style="color: #c9d1d9">right</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">joke</span></span>\n<span class="line"><span style="color: #c9d1d9">gonna</span></span>\n<span class="line"><span style="color: #c9d1d9">good</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">great</span></span>\n<span class="line"><span style="color: #c9d1d9">guy</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">heard</span></span></code></pre>\n<p>Just before your laptop battery dies, you show them the topics for Team Coco. They are very happy with your results and drive off.</p>\n<p>You\u2019re feeling more confident than ever.</p>\n<p>You\u2019ll never know why they needed the Machine Learning topic detection or why they chose you, but you\u2019re on top of the world right now.</p>\n<h2 id="conclusion">Conclusion</h2>\n<p>Congratulations on building the Topic Detection AI Python project with Deepgram. Now that you made it to the end of this blog post, Tweet us at <a href="https://twitter.com/DeepgramAI">@DeepgramAI</a> if you have any questions or to let us know how you enjoyed this post.</p>\n<h2 id="full-python-code-for-the-ai-machine-learning-podcast-topic-detection-project">Full Python Code for the AI Machine Learning Podcast Topic Detection Project</h2>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> ast </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> keyword</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> posixpath </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> split</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.feature_extraction.text </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> TfidfVectorizer</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.cluster </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> KMeans</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> nltk.corpus </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> stopwords</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> nltk</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;conan_podcast.mp3&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">  deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">      source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">      response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">          transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> transcript</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">remove_stop_words</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_text </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>\n<span class="line"><span style="color: #C9D1D9">  words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_text.split()</span></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  nltk.download(</span><span style="color: #A5D6FF">&#39;stopwords&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">  stops </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stopwords.words(</span><span style="color: #A5D6FF">&#39;english&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> stops:</span></span>\n<span class="line"><span style="color: #C9D1D9">          final.append(word)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(final)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> final</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">cleaned_docs_to_vectorize</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  final_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> remove_stop_words()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  split_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_final.split()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">                          )</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectors </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.fit_transform(split_transcript)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  feature_names </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  dense </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectors.todense()</span></span>\n<span class="line"><span style="color: #C9D1D9">  denselist </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dense.tolist()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  all_keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> description </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> denselist:</span></span>\n<span class="line"><span style="color: #C9D1D9">      x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>\n<span class="line"><span style="color: #C9D1D9">      keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> description:</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">              keywords.append(feature_names[x])</span></span>\n<span class="line"><span style="color: #C9D1D9">          x</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">x</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      [all_keywords.append(x) </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> keywords </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> all_keywords]</span></span>\n<span class="line"><span style="color: #C9D1D9">   topic </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">.join(all_keywords)</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(topic)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  k </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> KMeans(</span><span style="color: #FFA657">n_clusters</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">k, </span><span style="color: #FFA657">init</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;k-means++&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">max_iter</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">n_init</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model.fit(vectors)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  centroids </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> model.cluster_centers_.argsort()[:, ::</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  terms </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;results.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">encoding</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;utf-8&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(k):</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Cluster </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">i</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ind </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> centroids[i, :</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&#39; </span><span style="color: #79C0FF">%s</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">%</span><span style="color: #C9D1D9"> terms[ind],)</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(cleaned_docs_to_vectorize())</span></span></code></pre>' };
const frontmatter = { "title": "Topic Detection in Podcast Episodes with Python", "description": "This tutorial will use Python and the Deepgram API speech-to-text to perform Topic Detection using the TF-IDF Machine Learning Algorithm and KMeans Clustering.", "date": "2022-08-23T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1660892766/blog/2022/08/topic-detection-with-python/2208-Detect-Topics-in-Podcast-Episodes-with-Python-blog%402x.jpg", "authors": ["tonya-sims"], "category": "tutorial", "tags": ["python"], "seo": { "title": "Topic Detection in Podcast Episodes with Python", "description": "This tutorial will use Python and the Deepgram API speech-to-text to perform Topic Detection using the TF-IDF Machine Learning Algorithm and KMeans Clustering." }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661454121/blog/topic-detection-with-python/ograph.png" }, "shorturls": { "share": "https://dpgr.am/c1098c5", "twitter": "https://dpgr.am/335341b", "linkedin": "https://dpgr.am/11c3f1c", "reddit": "https://dpgr.am/e460418", "facebook": "https://dpgr.am/26c7cfa" }, "astro": { "headings": [{ "depth": 2, "slug": "discovery-of-deepgram-ai-speech-to-text", "text": "Discovery of Deepgram AI Speech-to-Text" }, { "depth": 2, "slug": "python-code-for-ai-machine-learning-topic-detection", "text": "Python Code for AI Machine Learning Topic Detection" }, { "depth": 2, "slug": "conclusion", "text": "Conclusion" }, { "depth": 2, "slug": "full-python-code-for-the-ai-machine-learning-podcast-topic-detection-project", "text": "Full Python Code for the AI Machine Learning Podcast Topic Detection Project" }], "source": "Imagine you\u2019re a Python Machine Learning Engineer. Your work day is getting ready to start with the dreaded stand-up meeting, but you're looking the most forward to deep diving into topic detection algorithms.\n\n<Panel title=\"Important Note\">\n\nIf you want to see the whole Python code snippet for topic detection, please scroll to the bottom of this post.\n\n</Panel>\n\nYou step out to get coffee down the street. A black SUV pulls up next to you, the door opens, and someone tells you to get in the truck.\n\nThey explain that your Machine Learning Python prowess is needed badly.\n\nWhy?\n\nThey need you to transcribe a podcast from speech-to-text urgently. But not just any podcast. It\u2019s Team Coco\u2019s podcast, the legendary Conan O\u2019Brien. Not only do they need it transcribed using AI speech recognition, but they also require a topic analysis to quickly analyze the topics to discover what the podcast is about.\n\nThey can\u2019t say too much about the underground Operation Machine Learning Topic Detection, other than if you can\u2019t deliver the topic modeling results or tell anyone, something terrible may happen.\n\nWeird. Ironic but weird. Yesterday, you learned about the TF-IDF (Term Frequency - Inverse Document Frequency) topic detection algorithm.\n\nYou should feel confident in your Python and Machine Learning abilities, but you have some reservations.\n\nYou think about telling your manager but remember what they said about something terrible that may happen.\n\nYou\u2019re going through self-doubt, and most importantly, you\u2019re not even sure where to start with transcribing audio speech-to-text in Python.\n\nWhat if something bad does happen if you don\u2019t complete the topic detection request?\n\nYou decide to put on your superhero cape and take on the challenge because your life could depend on it.\n\n## Discovery of Deepgram AI Speech-to-Text\n\nYou\u2019re back at your home office and not sure where to start with finding a Python speech-to-text audio transcription provider.\n\nYou try using Company A\u2019s transcription with Python, but it takes a long time to get back a transcript. Besides, the file you need to transcribe is over an hour long, and you don\u2019t have time to waste.\n\nYou try Company B\u2019s transcription again with Python. This time, the transcription comes back faster, but one big problem is accuracy. The words in the speech-to-text audio transcript you\u2019re getting back are inaccurate.\n\nYou want to give up because you don\u2019t think you\u2019ll be able to find a superior company with an API that provides transcription.\n\nThen you discover Deepgram, and everything changes.\n\nDeepgram is an AI automated speech recognition voice-to-text company that allows us to build applications that transcribe speech-to-text.\n\nYou loved how effortless it is to sign up for Deepgram by quickly grabbing a Deepgram API Key [from our website](https://console.deepgram.com/signup?jump=keys). You also immediately get hands-on experience after signing up by trying out their console missions for transcribing prerecorded audio in a matter of a few minutes.\n\nThere\u2019s even better news!\n\nDeepgam has much higher transcription accuracy than other providers, and you receive a transcript back super fast. You also discover they have a Python SDK that you can use.\n\nIt\u2019s do-or-(maybe)-die time.\n\nYou hear a tornado warning siren, but disregard it and start coding.\n\nYou won\u2019t let anything get in your way, not even a twister.\n\n## Python Code for AI Machine Learning Topic Detection\n\nYou first create a [virtual environment](https://blog.deepgram.com/python-virtual-environments/) to install your Python packages inside.\n\nNext, from the command line, you `pip install` the following Python packages inside of the virtual environment:\n\n```\npip install deepgram-sdk\npip install python-dotenv\npip install -U scikit-learn\npip install -U nltk\n```\n\nThen you create a `.env` file inside your project directory to hold your Deepgram API Key, so it\u2019s not exposed to the whole world. Inside of your `.env` file, you assign your API Key from Deepgram to a variable `DEEPGRAM_API_KEY, like so:\n\n```\nDEEPGRAM_AP_KEY=\u201Dabc123\u201D\n```\n\nNext, you create a new file called `python_topic_detection.py. You write the following code that imports Python libraries and handles the Deepgram prerecorded audio speech-to-text transcription:\n\n```python\nfrom ast import keyword\nfrom posixpath import split\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom nltk.corpus import stopwords\nimport asyncio\nimport json\nimport os\nimport nltk\n\n\nload_dotenv()\n\nPATH_TO_FILE = 'conan_podcast.mp3'\n\nasync def transcribe_with_deepgram():\n  # Initializes the Deepgram SDK\n  deepgram = Deepgram(os.getenv(\"DEEPGRAM_API_KEY\"))\n  # Open the audio file\n  with open(PATH_TO_FILE, 'rb') as audio:\n      # ...or replace mimetype as appropriate\n      source = {'buffer': audio, 'mimetype': 'audio/mp3'}\n      response = await deepgram.transcription.prerecorded(source)\n\n      if 'transcript' in response['results']['channels'][0]['alternatives'][0]:\n          transcript = response['results']['channels'][0]['alternatives'][0]['transcript']\n\n          return transcript\n```\n\nThe `transcribe_with_deepgram()` function comes from our Deepgram Python SDK, located [here in Github](https://github.com/deepgram/python-sdk).\n\nIn this method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the `prerecorded` transcription option to transcribe a recorded file to text.\n\nYou\u2019re on a roll!\n\nNext, you start writing the code for the TF-IDF Machine Learning algorithm to handle the topic detection. The tornado knocks out your power, and you realize you only have 20% laptop battery life.\n\nYou need to hurry and continue writing the following code in the same file:\n\n```python\nasync def remove_stop_words():\n  transcript_text = await transcribe_with_deepgram()\n  words = transcript_text.split()\n  final = []\n\n  nltk.download('stopwords')\n  stops = stopwords.words('english')\n\n  for word in words:\n      if word not in stops:\n          final.append(word)\n\n  final = \" \".join(final)\n\n  return final\n\n\nasync def cleaned_docs_to_vectorize():\n  final_list = []\n  transcript_final = await remove_stop_words()\n\n  split_transcript = transcript_final.split()\n\n  vectorizer = TfidfVectorizer(\n                              lowercase=True,\n                              max_features=100,\n                              max_df=0.8,\n                              min_df=4,\n                              ngram_range=(1,3),\n                              stop_words='english'\n\n                          )\n\n\n  vectors = vectorizer.fit_transform(split_transcript)\n\n  feature_names = vectorizer.get_feature_names()\n\n  dense = vectors.todense()\n  denselist = dense.tolist()\n\n  all_keywords = []\n\n  for description in denselist:\n      x = 0\n      keywords = []\n      for word in description:\n          if word > 0:\n              keywords.append(feature_names[x])\n          x=x+1\n\n      [all_keywords.append(x) for x in keywords if x not in all_keywords]\n   topic = \"\\n\".join(all_keywords)\n  print(topic)\n\n  k = 10\n\n  model = KMeans(n_clusters=k, init=\"k-means++\", max_iter=100, n_init=1)\n\n  model.fit(vectors)\n\n  centroids = model.cluster_centers_.argsort()[:, ::-1]\n\n  terms = vectorizer.get_feature_names()\n   with open(\"results.txt\", \"w\", encoding=\"utf-8\") as f:\n      for i in range(k):\n          f.write(f\"Cluster {i}\")\n          f.write(\"\\n\")\n          for ind in centroids[i, :10]:\n              f.write(' %s' % terms[ind],)\n              f.write(\"\\n\")\n          f.write(\"\\n\")\n          f.write(\"\\n\")\n\nasyncio.run(cleaned_docs_to_vectorize())\n```\n\nIn this code, you create a new function called `cleaned_docs_to_vectorize()`, which will get the previous method's transcript and remove any stop words. Stop words are unimportant, like `a, the, and, this` etc.\n\nThe algorithm will then perform the TF-IDF vectorization using these lines of code:\n\n```python\nvectorizer = TfidfVectorizer(\n                              lowercase=True,\n                              max_features=100,\n                              max_df=0.8,\n                              min_df=4,\n                              ngram_range=(1,3),\n                              stop_words='english'\n\n                          )\n```\n\nYou quickly read about the options passed into the vectorizer like `max_features` and `max_df` [on sciki-learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n\nYou have a little bit on time with 15% battery life, so you decide to use K-Means to create 10 clusters of topics. This way, they can get a more meaningful sense of the data structure from the podcast. You write the K-Means clusters to a file called `results.txt`.\n\nTo run the program, type `python3 python_topic_detection.py` from the terminal.\n\nWhen you print the topics, you see a list like the following:\n\n```\nsort\nlittle\nsitting\nwent\nnew\nknew\ncomedy\nremember\nguys\nfunny\njerry\nclub\npoint\ngilbert\nyork\nchris\nrock\nfamous\nlater\ngetting\nlong\nlove\nnight\nyear\nbob\nnorm\ncar\nnews\nspace\nastronauts\nnasa\n```\n\nBingo!\n\nYou can now make inferences about the AI Topic Detection to determine the subject matter of the podcast episode.\n\nThen, peek at your `results.txt` file to verify that you received 10 clusters. Here\u2019s an example of four of the ten groups of words using KMeans clustering:\n\n```\nCluster 0\nyeah\nthink\nve\nroast\ngot\nspace\ncat\nsay\njoke\noh\n\n\nCluster 1\nperson\nyork\njoke\ngonna\ngood\ngot\ngreat\nguy\nguys\nheard\n\n\nCluster 2\nknow\nyork\njokes\ngonna\ngood\ngot\ngreat\nguy\nguys\nheard\n\n\nCluster 3\nright\nyork\njoke\ngonna\ngood\ngot\ngreat\nguy\nguys\nheard\n```\n\nJust before your laptop battery dies, you show them the topics for Team Coco. They are very happy with your results and drive off.\n\nYou\u2019re feeling more confident than ever.\n\nYou\u2019ll never know why they needed the Machine Learning topic detection or why they chose you, but you\u2019re on top of the world right now.\n\n## Conclusion\n\nCongratulations on building the Topic Detection AI Python project with Deepgram. Now that you made it to the end of this blog post, Tweet us at [@DeepgramAI](https://twitter.com/DeepgramAI) if you have any questions or to let us know how you enjoyed this post.\n\n## Full Python Code for the AI Machine Learning Podcast Topic Detection Project\n\n```python\nfrom ast import keyword\nfrom posixpath import split\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom nltk.corpus import stopwords\nimport asyncio\nimport json\nimport os\nimport nltk\n\n\nload_dotenv()\n\nPATH_TO_FILE = 'conan_podcast.mp3'\n\nasync def transcribe_with_deepgram():\n  # Initializes the Deepgram SDK\n  deepgram = Deepgram(os.getenv(\"DEEPGRAM_API_KEY\"))\n  # Open the audio file\n  with open(PATH_TO_FILE, 'rb') as audio:\n      # ...or replace mimetype as appropriate\n      source = {'buffer': audio, 'mimetype': 'audio/mp3'}\n      response = await deepgram.transcription.prerecorded(source)\n\n      if 'transcript' in response['results']['channels'][0]['alternatives'][0]:\n          transcript = response['results']['channels'][0]['alternatives'][0]['transcript']\n\n          return transcript\n\nasync def remove_stop_words():\n  transcript_text = await transcribe_with_deepgram()\n  words = transcript_text.split()\n  final = []\n\n  nltk.download('stopwords')\n  stops = stopwords.words('english')\n\n  for word in words:\n      if word not in stops:\n          final.append(word)\n\n  final = \" \".join(final)\n\n  return final\n\n\nasync def cleaned_docs_to_vectorize():\n  final_list = []\n  transcript_final = await remove_stop_words()\n\n  split_transcript = transcript_final.split()\n\n  vectorizer = TfidfVectorizer(\n                              lowercase=True,\n                              max_features=100,\n                              max_df=0.8,\n                              min_df=4,\n                              ngram_range=(1,3),\n                              stop_words='english'\n\n                          )\n\n\n  vectors = vectorizer.fit_transform(split_transcript)\n\n  feature_names = vectorizer.get_feature_names()\n\n  dense = vectors.todense()\n  denselist = dense.tolist()\n\n  all_keywords = []\n\n  for description in denselist:\n      x = 0\n      keywords = []\n      for word in description:\n          if word > 0:\n              keywords.append(feature_names[x])\n          x=x+1\n\n      [all_keywords.append(x) for x in keywords if x not in all_keywords]\n   topic = \"\\n\".join(all_keywords)\n  print(topic)\n\n  k = 10\n\n  model = KMeans(n_clusters=k, init=\"k-means++\", max_iter=100, n_init=1)\n\n  model.fit(vectors)\n\n  centroids = model.cluster_centers_.argsort()[:, ::-1]\n\n  terms = vectorizer.get_feature_names()\n   with open(\"results.txt\", \"w\", encoding=\"utf-8\") as f:\n      for i in range(k):\n          f.write(f\"Cluster {i}\")\n          f.write(\"\\n\")\n          for ind in centroids[i, :10]:\n              f.write(' %s' % terms[ind],)\n              f.write(\"\\n\")\n          f.write(\"\\n\")\n          f.write(\"\\n\")\n\nasyncio.run(cleaned_docs_to_vectorize())\n```", "html": '<p>Imagine you\u2019re a Python Machine Learning Engineer. Your work day is getting ready to start with the dreaded stand-up meeting, but you\u2019re looking the most forward to deep diving into topic detection algorithms.</p>\n<Panel title="Important Note"><p>If you want to see the whole Python code snippet for topic detection, please scroll to the bottom of this post.</p></Panel>\n<p>You step out to get coffee down the street. A black SUV pulls up next to you, the door opens, and someone tells you to get in the truck.</p>\n<p>They explain that your Machine Learning Python prowess is needed badly.</p>\n<p>Why?</p>\n<p>They need you to transcribe a podcast from speech-to-text urgently. But not just any podcast. It\u2019s Team Coco\u2019s podcast, the legendary Conan O\u2019Brien. Not only do they need it transcribed using AI speech recognition, but they also require a topic analysis to quickly analyze the topics to discover what the podcast is about.</p>\n<p>They can\u2019t say too much about the underground Operation Machine Learning Topic Detection, other than if you can\u2019t deliver the topic modeling results or tell anyone, something terrible may happen.</p>\n<p>Weird. Ironic but weird. Yesterday, you learned about the TF-IDF (Term Frequency - Inverse Document Frequency) topic detection algorithm.</p>\n<p>You should feel confident in your Python and Machine Learning abilities, but you have some reservations.</p>\n<p>You think about telling your manager but remember what they said about something terrible that may happen.</p>\n<p>You\u2019re going through self-doubt, and most importantly, you\u2019re not even sure where to start with transcribing audio speech-to-text in Python.</p>\n<p>What if something bad does happen if you don\u2019t complete the topic detection request?</p>\n<p>You decide to put on your superhero cape and take on the challenge because your life could depend on it.</p>\n<h2 id="discovery-of-deepgram-ai-speech-to-text">Discovery of Deepgram AI Speech-to-Text</h2>\n<p>You\u2019re back at your home office and not sure where to start with finding a Python speech-to-text audio transcription provider.</p>\n<p>You try using Company A\u2019s transcription with Python, but it takes a long time to get back a transcript. Besides, the file you need to transcribe is over an hour long, and you don\u2019t have time to waste.</p>\n<p>You try Company B\u2019s transcription again with Python. This time, the transcription comes back faster, but one big problem is accuracy. The words in the speech-to-text audio transcript you\u2019re getting back are inaccurate.</p>\n<p>You want to give up because you don\u2019t think you\u2019ll be able to find a superior company with an API that provides transcription.</p>\n<p>Then you discover Deepgram, and everything changes.</p>\n<p>Deepgram is an AI automated speech recognition voice-to-text company that allows us to build applications that transcribe speech-to-text.</p>\n<p>You loved how effortless it is to sign up for Deepgram by quickly grabbing a Deepgram API Key <a href="https://console.deepgram.com/signup?jump=keys">from our website</a>. You also immediately get hands-on experience after signing up by trying out their console missions for transcribing prerecorded audio in a matter of a few minutes.</p>\n<p>There\u2019s even better news!</p>\n<p>Deepgam has much higher transcription accuracy than other providers, and you receive a transcript back super fast. You also discover they have a Python SDK that you can use.</p>\n<p>It\u2019s do-or-(maybe)-die time.</p>\n<p>You hear a tornado warning siren, but disregard it and start coding.</p>\n<p>You won\u2019t let anything get in your way, not even a twister.</p>\n<h2 id="python-code-for-ai-machine-learning-topic-detection">Python Code for AI Machine Learning Topic Detection</h2>\n<p>You first create a <a href="https://blog.deepgram.com/python-virtual-environments/">virtual environment</a> to install your Python packages inside.</p>\n<p>Next, from the command line, you <code is:raw>pip install</code> the following Python packages inside of the virtual environment:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">pip install deepgram-sdk</span></span>\n<span class="line"><span style="color: #c9d1d9">pip install python-dotenv</span></span>\n<span class="line"><span style="color: #c9d1d9">pip install -U scikit-learn</span></span>\n<span class="line"><span style="color: #c9d1d9">pip install -U nltk</span></span></code></pre>\n<p>Then you create a <code is:raw>.env</code> file inside your project directory to hold your Deepgram API Key, so it\u2019s not exposed to the whole world. Inside of your <code is:raw>.env</code> file, you assign your API Key from Deepgram to a variable `DEEPGRAM_API_KEY, like so:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">DEEPGRAM_AP_KEY=\u201Dabc123\u201D</span></span></code></pre>\n<p>Next, you create a new file called `python_topic_detection.py. You write the following code that imports Python libraries and handles the Deepgram prerecorded audio speech-to-text transcription:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> ast </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> keyword</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> posixpath </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> split</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.feature_extraction.text </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> TfidfVectorizer</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.cluster </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> KMeans</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> nltk.corpus </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> stopwords</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> nltk</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;conan_podcast.mp3&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">  deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">      source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">      response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">          transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> transcript</span></span></code></pre>\n<p>The <code is:raw>transcribe_with_deepgram()</code> function comes from our Deepgram Python SDK, located <a href="https://github.com/deepgram/python-sdk">here in Github</a>.</p>\n<p>In this method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the <code is:raw>prerecorded</code> transcription option to transcribe a recorded file to text.</p>\n<p>You\u2019re on a roll!</p>\n<p>Next, you start writing the code for the TF-IDF Machine Learning algorithm to handle the topic detection. The tornado knocks out your power, and you realize you only have 20% laptop battery life.</p>\n<p>You need to hurry and continue writing the following code in the same file:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">remove_stop_words</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_text </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>\n<span class="line"><span style="color: #C9D1D9">  words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_text.split()</span></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  nltk.download(</span><span style="color: #A5D6FF">&#39;stopwords&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">  stops </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stopwords.words(</span><span style="color: #A5D6FF">&#39;english&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> stops:</span></span>\n<span class="line"><span style="color: #C9D1D9">          final.append(word)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(final)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> final</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">cleaned_docs_to_vectorize</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  final_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> remove_stop_words()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  split_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_final.split()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">                          )</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectors </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.fit_transform(split_transcript)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  feature_names </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  dense </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectors.todense()</span></span>\n<span class="line"><span style="color: #C9D1D9">  denselist </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dense.tolist()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  all_keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> description </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> denselist:</span></span>\n<span class="line"><span style="color: #C9D1D9">      x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>\n<span class="line"><span style="color: #C9D1D9">      keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> description:</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">              keywords.append(feature_names[x])</span></span>\n<span class="line"><span style="color: #C9D1D9">          x</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">x</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      [all_keywords.append(x) </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> keywords </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> all_keywords]</span></span>\n<span class="line"><span style="color: #C9D1D9">   topic </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">.join(all_keywords)</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(topic)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  k </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> KMeans(</span><span style="color: #FFA657">n_clusters</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">k, </span><span style="color: #FFA657">init</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;k-means++&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">max_iter</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">n_init</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model.fit(vectors)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  centroids </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> model.cluster_centers_.argsort()[:, ::</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  terms </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;results.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">encoding</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;utf-8&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(k):</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Cluster </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">i</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ind </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> centroids[i, :</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&#39; </span><span style="color: #79C0FF">%s</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">%</span><span style="color: #C9D1D9"> terms[ind],)</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(cleaned_docs_to_vectorize())</span></span></code></pre>\n<p>In this code, you create a new function called <code is:raw>cleaned_docs_to_vectorize()</code>, which will get the previous method\u2019s transcript and remove any stop words. Stop words are unimportant, like <code is:raw>a, the, and, this</code> etc.</p>\n<p>The algorithm will then perform the TF-IDF vectorization using these lines of code:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">                          )</span></span></code></pre>\n<p>You quickly read about the options passed into the vectorizer like <code is:raw>max_features</code> and <code is:raw>max_df</code> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html">on sciki-learn</a>.</p>\n<p>You have a little bit on time with 15% battery life, so you decide to use K-Means to create 10 clusters of topics. This way, they can get a more meaningful sense of the data structure from the podcast. You write the K-Means clusters to a file called <code is:raw>results.txt</code>.</p>\n<p>To run the program, type <code is:raw>python3 python_topic_detection.py</code> from the terminal.</p>\n<p>When you print the topics, you see a list like the following:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">sort</span></span>\n<span class="line"><span style="color: #c9d1d9">little</span></span>\n<span class="line"><span style="color: #c9d1d9">sitting</span></span>\n<span class="line"><span style="color: #c9d1d9">went</span></span>\n<span class="line"><span style="color: #c9d1d9">new</span></span>\n<span class="line"><span style="color: #c9d1d9">knew</span></span>\n<span class="line"><span style="color: #c9d1d9">comedy</span></span>\n<span class="line"><span style="color: #c9d1d9">remember</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">funny</span></span>\n<span class="line"><span style="color: #c9d1d9">jerry</span></span>\n<span class="line"><span style="color: #c9d1d9">club</span></span>\n<span class="line"><span style="color: #c9d1d9">point</span></span>\n<span class="line"><span style="color: #c9d1d9">gilbert</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">chris</span></span>\n<span class="line"><span style="color: #c9d1d9">rock</span></span>\n<span class="line"><span style="color: #c9d1d9">famous</span></span>\n<span class="line"><span style="color: #c9d1d9">later</span></span>\n<span class="line"><span style="color: #c9d1d9">getting</span></span>\n<span class="line"><span style="color: #c9d1d9">long</span></span>\n<span class="line"><span style="color: #c9d1d9">love</span></span>\n<span class="line"><span style="color: #c9d1d9">night</span></span>\n<span class="line"><span style="color: #c9d1d9">year</span></span>\n<span class="line"><span style="color: #c9d1d9">bob</span></span>\n<span class="line"><span style="color: #c9d1d9">norm</span></span>\n<span class="line"><span style="color: #c9d1d9">car</span></span>\n<span class="line"><span style="color: #c9d1d9">news</span></span>\n<span class="line"><span style="color: #c9d1d9">space</span></span>\n<span class="line"><span style="color: #c9d1d9">astronauts</span></span>\n<span class="line"><span style="color: #c9d1d9">nasa</span></span></code></pre>\n<p>Bingo!</p>\n<p>You can now make inferences about the AI Topic Detection to determine the subject matter of the podcast episode.</p>\n<p>Then, peek at your <code is:raw>results.txt</code> file to verify that you received 10 clusters. Here\u2019s an example of four of the ten groups of words using KMeans clustering:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">Cluster 0</span></span>\n<span class="line"><span style="color: #c9d1d9">yeah</span></span>\n<span class="line"><span style="color: #c9d1d9">think</span></span>\n<span class="line"><span style="color: #c9d1d9">ve</span></span>\n<span class="line"><span style="color: #c9d1d9">roast</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">space</span></span>\n<span class="line"><span style="color: #c9d1d9">cat</span></span>\n<span class="line"><span style="color: #c9d1d9">say</span></span>\n<span class="line"><span style="color: #c9d1d9">joke</span></span>\n<span class="line"><span style="color: #c9d1d9">oh</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">Cluster 1</span></span>\n<span class="line"><span style="color: #c9d1d9">person</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">joke</span></span>\n<span class="line"><span style="color: #c9d1d9">gonna</span></span>\n<span class="line"><span style="color: #c9d1d9">good</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">great</span></span>\n<span class="line"><span style="color: #c9d1d9">guy</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">heard</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">Cluster 2</span></span>\n<span class="line"><span style="color: #c9d1d9">know</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">jokes</span></span>\n<span class="line"><span style="color: #c9d1d9">gonna</span></span>\n<span class="line"><span style="color: #c9d1d9">good</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">great</span></span>\n<span class="line"><span style="color: #c9d1d9">guy</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">heard</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">Cluster 3</span></span>\n<span class="line"><span style="color: #c9d1d9">right</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">joke</span></span>\n<span class="line"><span style="color: #c9d1d9">gonna</span></span>\n<span class="line"><span style="color: #c9d1d9">good</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">great</span></span>\n<span class="line"><span style="color: #c9d1d9">guy</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">heard</span></span></code></pre>\n<p>Just before your laptop battery dies, you show them the topics for Team Coco. They are very happy with your results and drive off.</p>\n<p>You\u2019re feeling more confident than ever.</p>\n<p>You\u2019ll never know why they needed the Machine Learning topic detection or why they chose you, but you\u2019re on top of the world right now.</p>\n<h2 id="conclusion">Conclusion</h2>\n<p>Congratulations on building the Topic Detection AI Python project with Deepgram. Now that you made it to the end of this blog post, Tweet us at <a href="https://twitter.com/DeepgramAI">@DeepgramAI</a> if you have any questions or to let us know how you enjoyed this post.</p>\n<h2 id="full-python-code-for-the-ai-machine-learning-podcast-topic-detection-project">Full Python Code for the AI Machine Learning Podcast Topic Detection Project</h2>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> ast </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> keyword</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> posixpath </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> split</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.feature_extraction.text </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> TfidfVectorizer</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.cluster </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> KMeans</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> nltk.corpus </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> stopwords</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> nltk</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;conan_podcast.mp3&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">  deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">      source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">      response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">          transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> transcript</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">remove_stop_words</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_text </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>\n<span class="line"><span style="color: #C9D1D9">  words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_text.split()</span></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  nltk.download(</span><span style="color: #A5D6FF">&#39;stopwords&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">  stops </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stopwords.words(</span><span style="color: #A5D6FF">&#39;english&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> stops:</span></span>\n<span class="line"><span style="color: #C9D1D9">          final.append(word)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(final)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> final</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">cleaned_docs_to_vectorize</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  final_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> remove_stop_words()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  split_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_final.split()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">                          )</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectors </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.fit_transform(split_transcript)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  feature_names </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  dense </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectors.todense()</span></span>\n<span class="line"><span style="color: #C9D1D9">  denselist </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dense.tolist()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  all_keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> description </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> denselist:</span></span>\n<span class="line"><span style="color: #C9D1D9">      x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>\n<span class="line"><span style="color: #C9D1D9">      keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> description:</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">              keywords.append(feature_names[x])</span></span>\n<span class="line"><span style="color: #C9D1D9">          x</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">x</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      [all_keywords.append(x) </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> keywords </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> all_keywords]</span></span>\n<span class="line"><span style="color: #C9D1D9">   topic </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">.join(all_keywords)</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(topic)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  k </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> KMeans(</span><span style="color: #FFA657">n_clusters</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">k, </span><span style="color: #FFA657">init</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;k-means++&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">max_iter</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">n_init</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model.fit(vectors)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  centroids </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> model.cluster_centers_.argsort()[:, ::</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  terms </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;results.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">encoding</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;utf-8&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(k):</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Cluster </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">i</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ind </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> centroids[i, :</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&#39; </span><span style="color: #79C0FF">%s</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">%</span><span style="color: #C9D1D9"> terms[ind],)</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(cleaned_docs_to_vectorize())</span></span></code></pre>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/topic-detection-with-python/index.md" };
function rawContent() {
  return "Imagine you\u2019re a Python Machine Learning Engineer. Your work day is getting ready to start with the dreaded stand-up meeting, but you're looking the most forward to deep diving into topic detection algorithms.\n\n<Panel title=\"Important Note\">\n\nIf you want to see the whole Python code snippet for topic detection, please scroll to the bottom of this post.\n\n</Panel>\n\nYou step out to get coffee down the street. A black SUV pulls up next to you, the door opens, and someone tells you to get in the truck.\n\nThey explain that your Machine Learning Python prowess is needed badly.\n\nWhy?\n\nThey need you to transcribe a podcast from speech-to-text urgently. But not just any podcast. It\u2019s Team Coco\u2019s podcast, the legendary Conan O\u2019Brien. Not only do they need it transcribed using AI speech recognition, but they also require a topic analysis to quickly analyze the topics to discover what the podcast is about.\n\nThey can\u2019t say too much about the underground Operation Machine Learning Topic Detection, other than if you can\u2019t deliver the topic modeling results or tell anyone, something terrible may happen.\n\nWeird. Ironic but weird. Yesterday, you learned about the TF-IDF (Term Frequency - Inverse Document Frequency) topic detection algorithm.\n\nYou should feel confident in your Python and Machine Learning abilities, but you have some reservations.\n\nYou think about telling your manager but remember what they said about something terrible that may happen.\n\nYou\u2019re going through self-doubt, and most importantly, you\u2019re not even sure where to start with transcribing audio speech-to-text in Python.\n\nWhat if something bad does happen if you don\u2019t complete the topic detection request?\n\nYou decide to put on your superhero cape and take on the challenge because your life could depend on it.\n\n## Discovery of Deepgram AI Speech-to-Text\n\nYou\u2019re back at your home office and not sure where to start with finding a Python speech-to-text audio transcription provider.\n\nYou try using Company A\u2019s transcription with Python, but it takes a long time to get back a transcript. Besides, the file you need to transcribe is over an hour long, and you don\u2019t have time to waste.\n\nYou try Company B\u2019s transcription again with Python. This time, the transcription comes back faster, but one big problem is accuracy. The words in the speech-to-text audio transcript you\u2019re getting back are inaccurate.\n\nYou want to give up because you don\u2019t think you\u2019ll be able to find a superior company with an API that provides transcription.\n\nThen you discover Deepgram, and everything changes.\n\nDeepgram is an AI automated speech recognition voice-to-text company that allows us to build applications that transcribe speech-to-text.\n\nYou loved how effortless it is to sign up for Deepgram by quickly grabbing a Deepgram API Key [from our website](https://console.deepgram.com/signup?jump=keys). You also immediately get hands-on experience after signing up by trying out their console missions for transcribing prerecorded audio in a matter of a few minutes.\n\nThere\u2019s even better news!\n\nDeepgam has much higher transcription accuracy than other providers, and you receive a transcript back super fast. You also discover they have a Python SDK that you can use.\n\nIt\u2019s do-or-(maybe)-die time.\n\nYou hear a tornado warning siren, but disregard it and start coding.\n\nYou won\u2019t let anything get in your way, not even a twister.\n\n## Python Code for AI Machine Learning Topic Detection\n\nYou first create a [virtual environment](https://blog.deepgram.com/python-virtual-environments/) to install your Python packages inside.\n\nNext, from the command line, you `pip install` the following Python packages inside of the virtual environment:\n\n```\npip install deepgram-sdk\npip install python-dotenv\npip install -U scikit-learn\npip install -U nltk\n```\n\nThen you create a `.env` file inside your project directory to hold your Deepgram API Key, so it\u2019s not exposed to the whole world. Inside of your `.env` file, you assign your API Key from Deepgram to a variable `DEEPGRAM_API_KEY, like so:\n\n```\nDEEPGRAM_AP_KEY=\u201Dabc123\u201D\n```\n\nNext, you create a new file called `python_topic_detection.py. You write the following code that imports Python libraries and handles the Deepgram prerecorded audio speech-to-text transcription:\n\n```python\nfrom ast import keyword\nfrom posixpath import split\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom nltk.corpus import stopwords\nimport asyncio\nimport json\nimport os\nimport nltk\n\n\nload_dotenv()\n\nPATH_TO_FILE = 'conan_podcast.mp3'\n\nasync def transcribe_with_deepgram():\n  # Initializes the Deepgram SDK\n  deepgram = Deepgram(os.getenv(\"DEEPGRAM_API_KEY\"))\n  # Open the audio file\n  with open(PATH_TO_FILE, 'rb') as audio:\n      # ...or replace mimetype as appropriate\n      source = {'buffer': audio, 'mimetype': 'audio/mp3'}\n      response = await deepgram.transcription.prerecorded(source)\n\n      if 'transcript' in response['results']['channels'][0]['alternatives'][0]:\n          transcript = response['results']['channels'][0]['alternatives'][0]['transcript']\n\n          return transcript\n```\n\nThe `transcribe_with_deepgram()` function comes from our Deepgram Python SDK, located [here in Github](https://github.com/deepgram/python-sdk).\n\nIn this method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the `prerecorded` transcription option to transcribe a recorded file to text.\n\nYou\u2019re on a roll!\n\nNext, you start writing the code for the TF-IDF Machine Learning algorithm to handle the topic detection. The tornado knocks out your power, and you realize you only have 20% laptop battery life.\n\nYou need to hurry and continue writing the following code in the same file:\n\n```python\nasync def remove_stop_words():\n  transcript_text = await transcribe_with_deepgram()\n  words = transcript_text.split()\n  final = []\n\n  nltk.download('stopwords')\n  stops = stopwords.words('english')\n\n  for word in words:\n      if word not in stops:\n          final.append(word)\n\n  final = \" \".join(final)\n\n  return final\n\n\nasync def cleaned_docs_to_vectorize():\n  final_list = []\n  transcript_final = await remove_stop_words()\n\n  split_transcript = transcript_final.split()\n\n  vectorizer = TfidfVectorizer(\n                              lowercase=True,\n                              max_features=100,\n                              max_df=0.8,\n                              min_df=4,\n                              ngram_range=(1,3),\n                              stop_words='english'\n\n                          )\n\n\n  vectors = vectorizer.fit_transform(split_transcript)\n\n  feature_names = vectorizer.get_feature_names()\n\n  dense = vectors.todense()\n  denselist = dense.tolist()\n\n  all_keywords = []\n\n  for description in denselist:\n      x = 0\n      keywords = []\n      for word in description:\n          if word > 0:\n              keywords.append(feature_names[x])\n          x=x+1\n\n      [all_keywords.append(x) for x in keywords if x not in all_keywords]\n   topic = \"\\n\".join(all_keywords)\n  print(topic)\n\n  k = 10\n\n  model = KMeans(n_clusters=k, init=\"k-means++\", max_iter=100, n_init=1)\n\n  model.fit(vectors)\n\n  centroids = model.cluster_centers_.argsort()[:, ::-1]\n\n  terms = vectorizer.get_feature_names()\n   with open(\"results.txt\", \"w\", encoding=\"utf-8\") as f:\n      for i in range(k):\n          f.write(f\"Cluster {i}\")\n          f.write(\"\\n\")\n          for ind in centroids[i, :10]:\n              f.write(' %s' % terms[ind],)\n              f.write(\"\\n\")\n          f.write(\"\\n\")\n          f.write(\"\\n\")\n\nasyncio.run(cleaned_docs_to_vectorize())\n```\n\nIn this code, you create a new function called `cleaned_docs_to_vectorize()`, which will get the previous method's transcript and remove any stop words. Stop words are unimportant, like `a, the, and, this` etc.\n\nThe algorithm will then perform the TF-IDF vectorization using these lines of code:\n\n```python\nvectorizer = TfidfVectorizer(\n                              lowercase=True,\n                              max_features=100,\n                              max_df=0.8,\n                              min_df=4,\n                              ngram_range=(1,3),\n                              stop_words='english'\n\n                          )\n```\n\nYou quickly read about the options passed into the vectorizer like `max_features` and `max_df` [on sciki-learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n\nYou have a little bit on time with 15% battery life, so you decide to use K-Means to create 10 clusters of topics. This way, they can get a more meaningful sense of the data structure from the podcast. You write the K-Means clusters to a file called `results.txt`.\n\nTo run the program, type `python3 python_topic_detection.py` from the terminal.\n\nWhen you print the topics, you see a list like the following:\n\n```\nsort\nlittle\nsitting\nwent\nnew\nknew\ncomedy\nremember\nguys\nfunny\njerry\nclub\npoint\ngilbert\nyork\nchris\nrock\nfamous\nlater\ngetting\nlong\nlove\nnight\nyear\nbob\nnorm\ncar\nnews\nspace\nastronauts\nnasa\n```\n\nBingo!\n\nYou can now make inferences about the AI Topic Detection to determine the subject matter of the podcast episode.\n\nThen, peek at your `results.txt` file to verify that you received 10 clusters. Here\u2019s an example of four of the ten groups of words using KMeans clustering:\n\n```\nCluster 0\nyeah\nthink\nve\nroast\ngot\nspace\ncat\nsay\njoke\noh\n\n\nCluster 1\nperson\nyork\njoke\ngonna\ngood\ngot\ngreat\nguy\nguys\nheard\n\n\nCluster 2\nknow\nyork\njokes\ngonna\ngood\ngot\ngreat\nguy\nguys\nheard\n\n\nCluster 3\nright\nyork\njoke\ngonna\ngood\ngot\ngreat\nguy\nguys\nheard\n```\n\nJust before your laptop battery dies, you show them the topics for Team Coco. They are very happy with your results and drive off.\n\nYou\u2019re feeling more confident than ever.\n\nYou\u2019ll never know why they needed the Machine Learning topic detection or why they chose you, but you\u2019re on top of the world right now.\n\n## Conclusion\n\nCongratulations on building the Topic Detection AI Python project with Deepgram. Now that you made it to the end of this blog post, Tweet us at [@DeepgramAI](https://twitter.com/DeepgramAI) if you have any questions or to let us know how you enjoyed this post.\n\n## Full Python Code for the AI Machine Learning Podcast Topic Detection Project\n\n```python\nfrom ast import keyword\nfrom posixpath import split\nfrom deepgram import Deepgram\nfrom dotenv import load_dotenv\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom nltk.corpus import stopwords\nimport asyncio\nimport json\nimport os\nimport nltk\n\n\nload_dotenv()\n\nPATH_TO_FILE = 'conan_podcast.mp3'\n\nasync def transcribe_with_deepgram():\n  # Initializes the Deepgram SDK\n  deepgram = Deepgram(os.getenv(\"DEEPGRAM_API_KEY\"))\n  # Open the audio file\n  with open(PATH_TO_FILE, 'rb') as audio:\n      # ...or replace mimetype as appropriate\n      source = {'buffer': audio, 'mimetype': 'audio/mp3'}\n      response = await deepgram.transcription.prerecorded(source)\n\n      if 'transcript' in response['results']['channels'][0]['alternatives'][0]:\n          transcript = response['results']['channels'][0]['alternatives'][0]['transcript']\n\n          return transcript\n\nasync def remove_stop_words():\n  transcript_text = await transcribe_with_deepgram()\n  words = transcript_text.split()\n  final = []\n\n  nltk.download('stopwords')\n  stops = stopwords.words('english')\n\n  for word in words:\n      if word not in stops:\n          final.append(word)\n\n  final = \" \".join(final)\n\n  return final\n\n\nasync def cleaned_docs_to_vectorize():\n  final_list = []\n  transcript_final = await remove_stop_words()\n\n  split_transcript = transcript_final.split()\n\n  vectorizer = TfidfVectorizer(\n                              lowercase=True,\n                              max_features=100,\n                              max_df=0.8,\n                              min_df=4,\n                              ngram_range=(1,3),\n                              stop_words='english'\n\n                          )\n\n\n  vectors = vectorizer.fit_transform(split_transcript)\n\n  feature_names = vectorizer.get_feature_names()\n\n  dense = vectors.todense()\n  denselist = dense.tolist()\n\n  all_keywords = []\n\n  for description in denselist:\n      x = 0\n      keywords = []\n      for word in description:\n          if word > 0:\n              keywords.append(feature_names[x])\n          x=x+1\n\n      [all_keywords.append(x) for x in keywords if x not in all_keywords]\n   topic = \"\\n\".join(all_keywords)\n  print(topic)\n\n  k = 10\n\n  model = KMeans(n_clusters=k, init=\"k-means++\", max_iter=100, n_init=1)\n\n  model.fit(vectors)\n\n  centroids = model.cluster_centers_.argsort()[:, ::-1]\n\n  terms = vectorizer.get_feature_names()\n   with open(\"results.txt\", \"w\", encoding=\"utf-8\") as f:\n      for i in range(k):\n          f.write(f\"Cluster {i}\")\n          f.write(\"\\n\")\n          for ind in centroids[i, :10]:\n              f.write(' %s' % terms[ind],)\n              f.write(\"\\n\")\n          f.write(\"\\n\")\n          f.write(\"\\n\")\n\nasyncio.run(cleaned_docs_to_vectorize())\n```";
}
function compiledContent() {
  return '<p>Imagine you\u2019re a Python Machine Learning Engineer. Your work day is getting ready to start with the dreaded stand-up meeting, but you\u2019re looking the most forward to deep diving into topic detection algorithms.</p>\n<Panel title="Important Note"><p>If you want to see the whole Python code snippet for topic detection, please scroll to the bottom of this post.</p></Panel>\n<p>You step out to get coffee down the street. A black SUV pulls up next to you, the door opens, and someone tells you to get in the truck.</p>\n<p>They explain that your Machine Learning Python prowess is needed badly.</p>\n<p>Why?</p>\n<p>They need you to transcribe a podcast from speech-to-text urgently. But not just any podcast. It\u2019s Team Coco\u2019s podcast, the legendary Conan O\u2019Brien. Not only do they need it transcribed using AI speech recognition, but they also require a topic analysis to quickly analyze the topics to discover what the podcast is about.</p>\n<p>They can\u2019t say too much about the underground Operation Machine Learning Topic Detection, other than if you can\u2019t deliver the topic modeling results or tell anyone, something terrible may happen.</p>\n<p>Weird. Ironic but weird. Yesterday, you learned about the TF-IDF (Term Frequency - Inverse Document Frequency) topic detection algorithm.</p>\n<p>You should feel confident in your Python and Machine Learning abilities, but you have some reservations.</p>\n<p>You think about telling your manager but remember what they said about something terrible that may happen.</p>\n<p>You\u2019re going through self-doubt, and most importantly, you\u2019re not even sure where to start with transcribing audio speech-to-text in Python.</p>\n<p>What if something bad does happen if you don\u2019t complete the topic detection request?</p>\n<p>You decide to put on your superhero cape and take on the challenge because your life could depend on it.</p>\n<h2 id="discovery-of-deepgram-ai-speech-to-text">Discovery of Deepgram AI Speech-to-Text</h2>\n<p>You\u2019re back at your home office and not sure where to start with finding a Python speech-to-text audio transcription provider.</p>\n<p>You try using Company A\u2019s transcription with Python, but it takes a long time to get back a transcript. Besides, the file you need to transcribe is over an hour long, and you don\u2019t have time to waste.</p>\n<p>You try Company B\u2019s transcription again with Python. This time, the transcription comes back faster, but one big problem is accuracy. The words in the speech-to-text audio transcript you\u2019re getting back are inaccurate.</p>\n<p>You want to give up because you don\u2019t think you\u2019ll be able to find a superior company with an API that provides transcription.</p>\n<p>Then you discover Deepgram, and everything changes.</p>\n<p>Deepgram is an AI automated speech recognition voice-to-text company that allows us to build applications that transcribe speech-to-text.</p>\n<p>You loved how effortless it is to sign up for Deepgram by quickly grabbing a Deepgram API Key <a href="https://console.deepgram.com/signup?jump=keys">from our website</a>. You also immediately get hands-on experience after signing up by trying out their console missions for transcribing prerecorded audio in a matter of a few minutes.</p>\n<p>There\u2019s even better news!</p>\n<p>Deepgam has much higher transcription accuracy than other providers, and you receive a transcript back super fast. You also discover they have a Python SDK that you can use.</p>\n<p>It\u2019s do-or-(maybe)-die time.</p>\n<p>You hear a tornado warning siren, but disregard it and start coding.</p>\n<p>You won\u2019t let anything get in your way, not even a twister.</p>\n<h2 id="python-code-for-ai-machine-learning-topic-detection">Python Code for AI Machine Learning Topic Detection</h2>\n<p>You first create a <a href="https://blog.deepgram.com/python-virtual-environments/">virtual environment</a> to install your Python packages inside.</p>\n<p>Next, from the command line, you <code is:raw>pip install</code> the following Python packages inside of the virtual environment:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">pip install deepgram-sdk</span></span>\n<span class="line"><span style="color: #c9d1d9">pip install python-dotenv</span></span>\n<span class="line"><span style="color: #c9d1d9">pip install -U scikit-learn</span></span>\n<span class="line"><span style="color: #c9d1d9">pip install -U nltk</span></span></code></pre>\n<p>Then you create a <code is:raw>.env</code> file inside your project directory to hold your Deepgram API Key, so it\u2019s not exposed to the whole world. Inside of your <code is:raw>.env</code> file, you assign your API Key from Deepgram to a variable `DEEPGRAM_API_KEY, like so:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">DEEPGRAM_AP_KEY=\u201Dabc123\u201D</span></span></code></pre>\n<p>Next, you create a new file called `python_topic_detection.py. You write the following code that imports Python libraries and handles the Deepgram prerecorded audio speech-to-text transcription:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> ast </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> keyword</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> posixpath </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> split</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.feature_extraction.text </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> TfidfVectorizer</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.cluster </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> KMeans</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> nltk.corpus </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> stopwords</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> nltk</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;conan_podcast.mp3&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">  deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">      source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">      response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">          transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> transcript</span></span></code></pre>\n<p>The <code is:raw>transcribe_with_deepgram()</code> function comes from our Deepgram Python SDK, located <a href="https://github.com/deepgram/python-sdk">here in Github</a>.</p>\n<p>In this method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the <code is:raw>prerecorded</code> transcription option to transcribe a recorded file to text.</p>\n<p>You\u2019re on a roll!</p>\n<p>Next, you start writing the code for the TF-IDF Machine Learning algorithm to handle the topic detection. The tornado knocks out your power, and you realize you only have 20% laptop battery life.</p>\n<p>You need to hurry and continue writing the following code in the same file:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">remove_stop_words</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_text </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>\n<span class="line"><span style="color: #C9D1D9">  words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_text.split()</span></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  nltk.download(</span><span style="color: #A5D6FF">&#39;stopwords&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">  stops </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stopwords.words(</span><span style="color: #A5D6FF">&#39;english&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> stops:</span></span>\n<span class="line"><span style="color: #C9D1D9">          final.append(word)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(final)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> final</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">cleaned_docs_to_vectorize</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  final_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> remove_stop_words()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  split_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_final.split()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">                          )</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectors </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.fit_transform(split_transcript)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  feature_names </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  dense </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectors.todense()</span></span>\n<span class="line"><span style="color: #C9D1D9">  denselist </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dense.tolist()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  all_keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> description </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> denselist:</span></span>\n<span class="line"><span style="color: #C9D1D9">      x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>\n<span class="line"><span style="color: #C9D1D9">      keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> description:</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">              keywords.append(feature_names[x])</span></span>\n<span class="line"><span style="color: #C9D1D9">          x</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">x</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      [all_keywords.append(x) </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> keywords </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> all_keywords]</span></span>\n<span class="line"><span style="color: #C9D1D9">   topic </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">.join(all_keywords)</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(topic)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  k </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> KMeans(</span><span style="color: #FFA657">n_clusters</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">k, </span><span style="color: #FFA657">init</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;k-means++&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">max_iter</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">n_init</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model.fit(vectors)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  centroids </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> model.cluster_centers_.argsort()[:, ::</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  terms </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;results.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">encoding</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;utf-8&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(k):</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Cluster </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">i</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ind </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> centroids[i, :</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&#39; </span><span style="color: #79C0FF">%s</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">%</span><span style="color: #C9D1D9"> terms[ind],)</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(cleaned_docs_to_vectorize())</span></span></code></pre>\n<p>In this code, you create a new function called <code is:raw>cleaned_docs_to_vectorize()</code>, which will get the previous method\u2019s transcript and remove any stop words. Stop words are unimportant, like <code is:raw>a, the, and, this</code> etc.</p>\n<p>The algorithm will then perform the TF-IDF vectorization using these lines of code:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">                          )</span></span></code></pre>\n<p>You quickly read about the options passed into the vectorizer like <code is:raw>max_features</code> and <code is:raw>max_df</code> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html">on sciki-learn</a>.</p>\n<p>You have a little bit on time with 15% battery life, so you decide to use K-Means to create 10 clusters of topics. This way, they can get a more meaningful sense of the data structure from the podcast. You write the K-Means clusters to a file called <code is:raw>results.txt</code>.</p>\n<p>To run the program, type <code is:raw>python3 python_topic_detection.py</code> from the terminal.</p>\n<p>When you print the topics, you see a list like the following:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">sort</span></span>\n<span class="line"><span style="color: #c9d1d9">little</span></span>\n<span class="line"><span style="color: #c9d1d9">sitting</span></span>\n<span class="line"><span style="color: #c9d1d9">went</span></span>\n<span class="line"><span style="color: #c9d1d9">new</span></span>\n<span class="line"><span style="color: #c9d1d9">knew</span></span>\n<span class="line"><span style="color: #c9d1d9">comedy</span></span>\n<span class="line"><span style="color: #c9d1d9">remember</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">funny</span></span>\n<span class="line"><span style="color: #c9d1d9">jerry</span></span>\n<span class="line"><span style="color: #c9d1d9">club</span></span>\n<span class="line"><span style="color: #c9d1d9">point</span></span>\n<span class="line"><span style="color: #c9d1d9">gilbert</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">chris</span></span>\n<span class="line"><span style="color: #c9d1d9">rock</span></span>\n<span class="line"><span style="color: #c9d1d9">famous</span></span>\n<span class="line"><span style="color: #c9d1d9">later</span></span>\n<span class="line"><span style="color: #c9d1d9">getting</span></span>\n<span class="line"><span style="color: #c9d1d9">long</span></span>\n<span class="line"><span style="color: #c9d1d9">love</span></span>\n<span class="line"><span style="color: #c9d1d9">night</span></span>\n<span class="line"><span style="color: #c9d1d9">year</span></span>\n<span class="line"><span style="color: #c9d1d9">bob</span></span>\n<span class="line"><span style="color: #c9d1d9">norm</span></span>\n<span class="line"><span style="color: #c9d1d9">car</span></span>\n<span class="line"><span style="color: #c9d1d9">news</span></span>\n<span class="line"><span style="color: #c9d1d9">space</span></span>\n<span class="line"><span style="color: #c9d1d9">astronauts</span></span>\n<span class="line"><span style="color: #c9d1d9">nasa</span></span></code></pre>\n<p>Bingo!</p>\n<p>You can now make inferences about the AI Topic Detection to determine the subject matter of the podcast episode.</p>\n<p>Then, peek at your <code is:raw>results.txt</code> file to verify that you received 10 clusters. Here\u2019s an example of four of the ten groups of words using KMeans clustering:</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">Cluster 0</span></span>\n<span class="line"><span style="color: #c9d1d9">yeah</span></span>\n<span class="line"><span style="color: #c9d1d9">think</span></span>\n<span class="line"><span style="color: #c9d1d9">ve</span></span>\n<span class="line"><span style="color: #c9d1d9">roast</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">space</span></span>\n<span class="line"><span style="color: #c9d1d9">cat</span></span>\n<span class="line"><span style="color: #c9d1d9">say</span></span>\n<span class="line"><span style="color: #c9d1d9">joke</span></span>\n<span class="line"><span style="color: #c9d1d9">oh</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">Cluster 1</span></span>\n<span class="line"><span style="color: #c9d1d9">person</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">joke</span></span>\n<span class="line"><span style="color: #c9d1d9">gonna</span></span>\n<span class="line"><span style="color: #c9d1d9">good</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">great</span></span>\n<span class="line"><span style="color: #c9d1d9">guy</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">heard</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">Cluster 2</span></span>\n<span class="line"><span style="color: #c9d1d9">know</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">jokes</span></span>\n<span class="line"><span style="color: #c9d1d9">gonna</span></span>\n<span class="line"><span style="color: #c9d1d9">good</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">great</span></span>\n<span class="line"><span style="color: #c9d1d9">guy</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">heard</span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9"></span></span>\n<span class="line"><span style="color: #c9d1d9">Cluster 3</span></span>\n<span class="line"><span style="color: #c9d1d9">right</span></span>\n<span class="line"><span style="color: #c9d1d9">york</span></span>\n<span class="line"><span style="color: #c9d1d9">joke</span></span>\n<span class="line"><span style="color: #c9d1d9">gonna</span></span>\n<span class="line"><span style="color: #c9d1d9">good</span></span>\n<span class="line"><span style="color: #c9d1d9">got</span></span>\n<span class="line"><span style="color: #c9d1d9">great</span></span>\n<span class="line"><span style="color: #c9d1d9">guy</span></span>\n<span class="line"><span style="color: #c9d1d9">guys</span></span>\n<span class="line"><span style="color: #c9d1d9">heard</span></span></code></pre>\n<p>Just before your laptop battery dies, you show them the topics for Team Coco. They are very happy with your results and drive off.</p>\n<p>You\u2019re feeling more confident than ever.</p>\n<p>You\u2019ll never know why they needed the Machine Learning topic detection or why they chose you, but you\u2019re on top of the world right now.</p>\n<h2 id="conclusion">Conclusion</h2>\n<p>Congratulations on building the Topic Detection AI Python project with Deepgram. Now that you made it to the end of this blog post, Tweet us at <a href="https://twitter.com/DeepgramAI">@DeepgramAI</a> if you have any questions or to let us know how you enjoyed this post.</p>\n<h2 id="full-python-code-for-the-ai-machine-learning-podcast-topic-detection-project">Full Python Code for the AI Machine Learning Podcast Topic Detection Project</h2>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> ast </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> keyword</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> posixpath </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> split</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.feature_extraction.text </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> TfidfVectorizer</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.cluster </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> KMeans</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> nltk.corpus </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> stopwords</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> nltk</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;conan_podcast.mp3&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">  deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">      source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">      response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">          transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> transcript</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">remove_stop_words</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_text </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>\n<span class="line"><span style="color: #C9D1D9">  words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_text.split()</span></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  nltk.download(</span><span style="color: #A5D6FF">&#39;stopwords&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">  stops </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stopwords.words(</span><span style="color: #A5D6FF">&#39;english&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> stops:</span></span>\n<span class="line"><span style="color: #C9D1D9">          final.append(word)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(final)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> final</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">cleaned_docs_to_vectorize</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">  final_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">  transcript_final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> remove_stop_words()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  split_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_final.split()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>\n<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">                          )</span></span>\n<span class="line"></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  vectors </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.fit_transform(split_transcript)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  feature_names </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  dense </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectors.todense()</span></span>\n<span class="line"><span style="color: #C9D1D9">  denselist </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dense.tolist()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  all_keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> description </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> denselist:</span></span>\n<span class="line"><span style="color: #C9D1D9">      x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>\n<span class="line"><span style="color: #C9D1D9">      keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> description:</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">              keywords.append(feature_names[x])</span></span>\n<span class="line"><span style="color: #C9D1D9">          x</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">x</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">      [all_keywords.append(x) </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> keywords </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> all_keywords]</span></span>\n<span class="line"><span style="color: #C9D1D9">   topic </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">.join(all_keywords)</span></span>\n<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(topic)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  k </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> KMeans(</span><span style="color: #FFA657">n_clusters</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">k, </span><span style="color: #FFA657">init</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;k-means++&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">max_iter</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">n_init</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  model.fit(vectors)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  centroids </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> model.cluster_centers_.argsort()[:, ::</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">  terms </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>\n<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;results.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">encoding</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;utf-8&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>\n<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(k):</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Cluster </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">i</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ind </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> centroids[i, :</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">]:</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&#39; </span><span style="color: #79C0FF">%s</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">%</span><span style="color: #C9D1D9"> terms[ind],)</span></span>\n<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(cleaned_docs_to_vectorize())</span></span></code></pre>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/topic-detection-with-python/index.md", "", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p>Imagine youre a Python Machine Learning Engineer. Your work day is getting ready to start with the dreaded stand-up meeting, but youre looking the most forward to deep diving into topic detection algorithms.</p>
${renderComponent($$result, "Panel", Panel, { "title": "Important Note" }, { "default": () => renderTemplate`<p>If you want to see the whole Python code snippet for topic detection, please scroll to the bottom of this post.</p>` })}
<p>You step out to get coffee down the street. A black SUV pulls up next to you, the door opens, and someone tells you to get in the truck.</p>
<p>They explain that your Machine Learning Python prowess is needed badly.</p>
<p>Why?</p>
<p>They need you to transcribe a podcast from speech-to-text urgently. But not just any podcast. Its Team Cocos podcast, the legendary Conan OBrien. Not only do they need it transcribed using AI speech recognition, but they also require a topic analysis to quickly analyze the topics to discover what the podcast is about.</p>
<p>They cant say too much about the underground Operation Machine Learning Topic Detection, other than if you cant deliver the topic modeling results or tell anyone, something terrible may happen.</p>
<p>Weird. Ironic but weird. Yesterday, you learned about the TF-IDF (Term Frequency - Inverse Document Frequency) topic detection algorithm.</p>
<p>You should feel confident in your Python and Machine Learning abilities, but you have some reservations.</p>
<p>You think about telling your manager but remember what they said about something terrible that may happen.</p>
<p>Youre going through self-doubt, and most importantly, youre not even sure where to start with transcribing audio speech-to-text in Python.</p>
<p>What if something bad does happen if you dont complete the topic detection request?</p>
<p>You decide to put on your superhero cape and take on the challenge because your life could depend on it.</p>
<h2 id="discovery-of-deepgram-ai-speech-to-text">Discovery of Deepgram AI Speech-to-Text</h2>
<p>Youre back at your home office and not sure where to start with finding a Python speech-to-text audio transcription provider.</p>
<p>You try using Company As transcription with Python, but it takes a long time to get back a transcript. Besides, the file you need to transcribe is over an hour long, and you dont have time to waste.</p>
<p>You try Company Bs transcription again with Python. This time, the transcription comes back faster, but one big problem is accuracy. The words in the speech-to-text audio transcript youre getting back are inaccurate.</p>
<p>You want to give up because you dont think youll be able to find a superior company with an API that provides transcription.</p>
<p>Then you discover Deepgram, and everything changes.</p>
<p>Deepgram is an AI automated speech recognition voice-to-text company that allows us to build applications that transcribe speech-to-text.</p>
<p>You loved how effortless it is to sign up for Deepgram by quickly grabbing a Deepgram API Key <a href="https://console.deepgram.com/signup?jump=keys">from our website</a>. You also immediately get hands-on experience after signing up by trying out their console missions for transcribing prerecorded audio in a matter of a few minutes.</p>
<p>Theres even better news!</p>
<p>Deepgam has much higher transcription accuracy than other providers, and you receive a transcript back super fast. You also discover they have a Python SDK that you can use.</p>
<p>Its do-or-(maybe)-die time.</p>
<p>You hear a tornado warning siren, but disregard it and start coding.</p>
<p>You wont let anything get in your way, not even a twister.</p>
<h2 id="python-code-for-ai-machine-learning-topic-detection">Python Code for AI Machine Learning Topic Detection</h2>
<p>You first create a <a href="https://blog.deepgram.com/python-virtual-environments/">virtual environment</a> to install your Python packages inside.</p>
<p>Next, from the command line, you <code>pip install</code> the following Python packages inside of the virtual environment:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">pip install deepgram-sdk</span></span>
<span class="line"><span style="color: #c9d1d9">pip install python-dotenv</span></span>
<span class="line"><span style="color: #c9d1d9">pip install -U scikit-learn</span></span>
<span class="line"><span style="color: #c9d1d9">pip install -U nltk</span></span></code></pre>
<p>Then you create a <code>.env</code> file inside your project directory to hold your Deepgram API Key, so its not exposed to the whole world. Inside of your <code>.env</code> file, you assign your API Key from Deepgram to a variable \`DEEPGRAM_API_KEY, like so:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">DEEPGRAM_AP_KEY=abc123</span></span></code></pre>
<p>Next, you create a new file called \`python_topic_detection.py. You write the following code that imports Python libraries and handles the Deepgram prerecorded audio speech-to-text transcription:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> ast </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> keyword</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> posixpath </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> split</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.feature_extraction.text </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> TfidfVectorizer</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.cluster </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> KMeans</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> nltk.corpus </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> stopwords</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> nltk</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;conan_podcast.mp3&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>
<span class="line"><span style="color: #C9D1D9">  deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Open the audio file</span></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>
<span class="line"><span style="color: #C9D1D9">      source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">      response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>
<span class="line"><span style="color: #C9D1D9">          transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> transcript</span></span></code></pre>
<p>The <code>transcribe_with_deepgram()</code> function comes from our Deepgram Python SDK, located <a href="https://github.com/deepgram/python-sdk">here in Github</a>.</p>
<p>In this method, you initialize the Deepgram API and open our .mp3 podcast file to read it as audio. Then you use the <code>prerecorded</code> transcription option to transcribe a recorded file to text.</p>
<p>Youre on a roll!</p>
<p>Next, you start writing the code for the TF-IDF Machine Learning algorithm to handle the topic detection. The tornado knocks out your power, and you realize you only have 20% laptop battery life.</p>
<p>You need to hurry and continue writing the following code in the same file:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">remove_stop_words</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">  transcript_text </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>
<span class="line"><span style="color: #C9D1D9">  words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_text.split()</span></span>
<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  nltk.download(</span><span style="color: #A5D6FF">&#39;stopwords&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">  stops </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stopwords.words(</span><span style="color: #A5D6FF">&#39;english&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words:</span></span>
<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> stops:</span></span>
<span class="line"><span style="color: #C9D1D9">          final.append(word)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(final)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> final</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">cleaned_docs_to_vectorize</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">  final_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>
<span class="line"><span style="color: #C9D1D9">  transcript_final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> remove_stop_words()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  split_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_final.split()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">                          )</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  vectors </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.fit_transform(split_transcript)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  feature_names </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  dense </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectors.todense()</span></span>
<span class="line"><span style="color: #C9D1D9">  denselist </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dense.tolist()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  all_keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> description </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> denselist:</span></span>
<span class="line"><span style="color: #C9D1D9">      x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>
<span class="line"><span style="color: #C9D1D9">      keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>
<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> description:</span></span>
<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">              keywords.append(feature_names[x])</span></span>
<span class="line"><span style="color: #C9D1D9">          x</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">x</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">      [all_keywords.append(x) </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> keywords </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> all_keywords]</span></span>
<span class="line"><span style="color: #C9D1D9">   topic </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">.join(all_keywords)</span></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(topic)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  k </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  model </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> KMeans(</span><span style="color: #FFA657">n_clusters</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">k, </span><span style="color: #FFA657">init</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;k-means++&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">max_iter</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">n_init</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  model.fit(vectors)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  centroids </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> model.cluster_centers_.argsort()[:, ::</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  terms </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;results.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">encoding</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;utf-8&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>
<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(k):</span></span>
<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Cluster </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">i</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ind </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> centroids[i, :</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">]:</span></span>
<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&#39; </span><span style="color: #79C0FF">%s</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">%</span><span style="color: #C9D1D9"> terms[ind],)</span></span>
<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">asyncio.run(cleaned_docs_to_vectorize())</span></span></code></pre>
<p>In this code, you create a new function called <code>cleaned_docs_to_vectorize()</code>, which will get the previous methods transcript and remove any stop words. Stop words are unimportant, like <code>a, the, and, this</code> etc.</p>
<p>The algorithm will then perform the TF-IDF vectorization using these lines of code:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #C9D1D9">vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">                          )</span></span></code></pre>
<p>You quickly read about the options passed into the vectorizer like <code>max_features</code> and <code>max_df</code> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html">on sciki-learn</a>.</p>
<p>You have a little bit on time with 15% battery life, so you decide to use K-Means to create 10 clusters of topics. This way, they can get a more meaningful sense of the data structure from the podcast. You write the K-Means clusters to a file called <code>results.txt</code>.</p>
<p>To run the program, type <code>python3 python_topic_detection.py</code> from the terminal.</p>
<p>When you print the topics, you see a list like the following:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">sort</span></span>
<span class="line"><span style="color: #c9d1d9">little</span></span>
<span class="line"><span style="color: #c9d1d9">sitting</span></span>
<span class="line"><span style="color: #c9d1d9">went</span></span>
<span class="line"><span style="color: #c9d1d9">new</span></span>
<span class="line"><span style="color: #c9d1d9">knew</span></span>
<span class="line"><span style="color: #c9d1d9">comedy</span></span>
<span class="line"><span style="color: #c9d1d9">remember</span></span>
<span class="line"><span style="color: #c9d1d9">guys</span></span>
<span class="line"><span style="color: #c9d1d9">funny</span></span>
<span class="line"><span style="color: #c9d1d9">jerry</span></span>
<span class="line"><span style="color: #c9d1d9">club</span></span>
<span class="line"><span style="color: #c9d1d9">point</span></span>
<span class="line"><span style="color: #c9d1d9">gilbert</span></span>
<span class="line"><span style="color: #c9d1d9">york</span></span>
<span class="line"><span style="color: #c9d1d9">chris</span></span>
<span class="line"><span style="color: #c9d1d9">rock</span></span>
<span class="line"><span style="color: #c9d1d9">famous</span></span>
<span class="line"><span style="color: #c9d1d9">later</span></span>
<span class="line"><span style="color: #c9d1d9">getting</span></span>
<span class="line"><span style="color: #c9d1d9">long</span></span>
<span class="line"><span style="color: #c9d1d9">love</span></span>
<span class="line"><span style="color: #c9d1d9">night</span></span>
<span class="line"><span style="color: #c9d1d9">year</span></span>
<span class="line"><span style="color: #c9d1d9">bob</span></span>
<span class="line"><span style="color: #c9d1d9">norm</span></span>
<span class="line"><span style="color: #c9d1d9">car</span></span>
<span class="line"><span style="color: #c9d1d9">news</span></span>
<span class="line"><span style="color: #c9d1d9">space</span></span>
<span class="line"><span style="color: #c9d1d9">astronauts</span></span>
<span class="line"><span style="color: #c9d1d9">nasa</span></span></code></pre>
<p>Bingo!</p>
<p>You can now make inferences about the AI Topic Detection to determine the subject matter of the podcast episode.</p>
<p>Then, peek at your <code>results.txt</code> file to verify that you received 10 clusters. Heres an example of four of the ten groups of words using KMeans clustering:</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #c9d1d9">Cluster 0</span></span>
<span class="line"><span style="color: #c9d1d9">yeah</span></span>
<span class="line"><span style="color: #c9d1d9">think</span></span>
<span class="line"><span style="color: #c9d1d9">ve</span></span>
<span class="line"><span style="color: #c9d1d9">roast</span></span>
<span class="line"><span style="color: #c9d1d9">got</span></span>
<span class="line"><span style="color: #c9d1d9">space</span></span>
<span class="line"><span style="color: #c9d1d9">cat</span></span>
<span class="line"><span style="color: #c9d1d9">say</span></span>
<span class="line"><span style="color: #c9d1d9">joke</span></span>
<span class="line"><span style="color: #c9d1d9">oh</span></span>
<span class="line"><span style="color: #c9d1d9"></span></span>
<span class="line"><span style="color: #c9d1d9"></span></span>
<span class="line"><span style="color: #c9d1d9">Cluster 1</span></span>
<span class="line"><span style="color: #c9d1d9">person</span></span>
<span class="line"><span style="color: #c9d1d9">york</span></span>
<span class="line"><span style="color: #c9d1d9">joke</span></span>
<span class="line"><span style="color: #c9d1d9">gonna</span></span>
<span class="line"><span style="color: #c9d1d9">good</span></span>
<span class="line"><span style="color: #c9d1d9">got</span></span>
<span class="line"><span style="color: #c9d1d9">great</span></span>
<span class="line"><span style="color: #c9d1d9">guy</span></span>
<span class="line"><span style="color: #c9d1d9">guys</span></span>
<span class="line"><span style="color: #c9d1d9">heard</span></span>
<span class="line"><span style="color: #c9d1d9"></span></span>
<span class="line"><span style="color: #c9d1d9"></span></span>
<span class="line"><span style="color: #c9d1d9">Cluster 2</span></span>
<span class="line"><span style="color: #c9d1d9">know</span></span>
<span class="line"><span style="color: #c9d1d9">york</span></span>
<span class="line"><span style="color: #c9d1d9">jokes</span></span>
<span class="line"><span style="color: #c9d1d9">gonna</span></span>
<span class="line"><span style="color: #c9d1d9">good</span></span>
<span class="line"><span style="color: #c9d1d9">got</span></span>
<span class="line"><span style="color: #c9d1d9">great</span></span>
<span class="line"><span style="color: #c9d1d9">guy</span></span>
<span class="line"><span style="color: #c9d1d9">guys</span></span>
<span class="line"><span style="color: #c9d1d9">heard</span></span>
<span class="line"><span style="color: #c9d1d9"></span></span>
<span class="line"><span style="color: #c9d1d9"></span></span>
<span class="line"><span style="color: #c9d1d9">Cluster 3</span></span>
<span class="line"><span style="color: #c9d1d9">right</span></span>
<span class="line"><span style="color: #c9d1d9">york</span></span>
<span class="line"><span style="color: #c9d1d9">joke</span></span>
<span class="line"><span style="color: #c9d1d9">gonna</span></span>
<span class="line"><span style="color: #c9d1d9">good</span></span>
<span class="line"><span style="color: #c9d1d9">got</span></span>
<span class="line"><span style="color: #c9d1d9">great</span></span>
<span class="line"><span style="color: #c9d1d9">guy</span></span>
<span class="line"><span style="color: #c9d1d9">guys</span></span>
<span class="line"><span style="color: #c9d1d9">heard</span></span></code></pre>
<p>Just before your laptop battery dies, you show them the topics for Team Coco. They are very happy with your results and drive off.</p>
<p>Youre feeling more confident than ever.</p>
<p>Youll never know why they needed the Machine Learning topic detection or why they chose you, but youre on top of the world right now.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Congratulations on building the Topic Detection AI Python project with Deepgram. Now that you made it to the end of this blog post, Tweet us at <a href="https://twitter.com/DeepgramAI">@DeepgramAI</a> if you have any questions or to let us know how you enjoyed this post.</p>
<h2 id="full-python-code-for-the-ai-machine-learning-podcast-topic-detection-project">Full Python Code for the AI Machine Learning Podcast Topic Detection Project</h2>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> ast </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> keyword</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> posixpath </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> split</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> dotenv </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> load_dotenv</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.feature_extraction.text </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> TfidfVectorizer</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> sklearn.cluster </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> KMeans</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> nltk.corpus </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> stopwords</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> json</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> os</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> nltk</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">load_dotenv()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;conan_podcast.mp3&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">transcribe_with_deepgram</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>
<span class="line"><span style="color: #C9D1D9">  deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(os.getenv(</span><span style="color: #A5D6FF">&quot;DEEPGRAM_API_KEY&quot;</span><span style="color: #C9D1D9">))</span></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #8B949E"># Open the audio file</span></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>
<span class="line"><span style="color: #C9D1D9">      source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/mp3&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">      response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">]:</span></span>
<span class="line"><span style="color: #C9D1D9">          transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> response[</span><span style="color: #A5D6FF">&#39;results&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;channels&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;alternatives&#39;</span><span style="color: #C9D1D9">][</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">][</span><span style="color: #A5D6FF">&#39;transcript&#39;</span><span style="color: #C9D1D9">]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> transcript</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">remove_stop_words</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">  transcript_text </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> transcribe_with_deepgram()</span></span>
<span class="line"><span style="color: #C9D1D9">  words </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_text.split()</span></span>
<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  nltk.download(</span><span style="color: #A5D6FF">&#39;stopwords&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">  stops </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stopwords.words(</span><span style="color: #A5D6FF">&#39;english&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> words:</span></span>
<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> stops:</span></span>
<span class="line"><span style="color: #C9D1D9">          final.append(word)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot; &quot;</span><span style="color: #C9D1D9">.join(final)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">return</span><span style="color: #C9D1D9"> final</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">cleaned_docs_to_vectorize</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">  final_list </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>
<span class="line"><span style="color: #C9D1D9">  transcript_final </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> remove_stop_words()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  split_transcript </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> transcript_final.split()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  vectorizer </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> TfidfVectorizer(</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">lowercase</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_features</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">max_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">0.8</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">min_df</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">,</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">ngram_range</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">,</span><span style="color: #79C0FF">3</span><span style="color: #C9D1D9">),</span></span>
<span class="line"><span style="color: #C9D1D9">                              </span><span style="color: #FFA657">stop_words</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;english&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">                          )</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  vectors </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.fit_transform(split_transcript)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  feature_names </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  dense </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectors.todense()</span></span>
<span class="line"><span style="color: #C9D1D9">  denselist </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dense.tolist()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  all_keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> description </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> denselist:</span></span>
<span class="line"><span style="color: #C9D1D9">      x </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>
<span class="line"><span style="color: #C9D1D9">      keywords </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>
<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> description:</span></span>
<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> word </span><span style="color: #FF7B72">&gt;</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">              keywords.append(feature_names[x])</span></span>
<span class="line"><span style="color: #C9D1D9">          x</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">x</span><span style="color: #FF7B72">+</span><span style="color: #79C0FF">1</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">      [all_keywords.append(x) </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> keywords </span><span style="color: #FF7B72">if</span><span style="color: #C9D1D9"> x </span><span style="color: #FF7B72">not</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> all_keywords]</span></span>
<span class="line"><span style="color: #C9D1D9">   topic </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">.join(all_keywords)</span></span>
<span class="line"><span style="color: #C9D1D9">  </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(topic)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  k </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">10</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  model </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> KMeans(</span><span style="color: #FFA657">n_clusters</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">k, </span><span style="color: #FFA657">init</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;k-means++&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">max_iter</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">100</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">n_init</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  model.fit(vectors)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  centroids </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> model.cluster_centers_.argsort()[:, ::</span><span style="color: #FF7B72">-</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">  terms </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> vectorizer.get_feature_names()</span></span>
<span class="line"><span style="color: #C9D1D9">   </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;results.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">encoding</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;utf-8&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>
<span class="line"><span style="color: #C9D1D9">      </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(k):</span></span>
<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #FF7B72">f</span><span style="color: #A5D6FF">&quot;Cluster </span><span style="color: #79C0FF">{</span><span style="color: #C9D1D9">i</span><span style="color: #79C0FF">}</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">          </span><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> ind </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> centroids[i, :</span><span style="color: #79C0FF">10</span><span style="color: #C9D1D9">]:</span></span>
<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&#39; </span><span style="color: #79C0FF">%s</span><span style="color: #A5D6FF">&#39;</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">%</span><span style="color: #C9D1D9"> terms[ind],)</span></span>
<span class="line"><span style="color: #C9D1D9">              f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">          f.write(</span><span style="color: #A5D6FF">&quot;</span><span style="color: #79C0FF">\\n</span><span style="color: #A5D6FF">&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">asyncio.run(cleaned_docs_to_vectorize())</span></span></code></pre>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/topic-detection-with-python/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
