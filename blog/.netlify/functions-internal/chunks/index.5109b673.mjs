import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           *//* empty css                           *//* empty css                          */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [], "source": "*This is the transcript for the session \u201CSparking the Future of Conversation Design\u201D presented by Braden Ream, CEO of Voiceflow, presented on day one of Project Voice X.*\xA0\n\n*The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0**94% accurate.**\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0[contact us](https://deepgram.com/contact-us/).*\n\n\\[Braden Ream:] Alrighty. Hi, everyone. Thanks for having me here. So I\u2019ve given a bunch of talks on conversation design in the past, and the one I most often give is how to structure a conversation design team, so how to build one internally, build out the best practices. I thought what may be kinda fun is\u2026 you know, we learn a lot about conversation design through the practices of actually building Voiceflow. And so I thought it could be interesting to talk about the challenges of building a conversation design tool, which will, hopefully, in effect, teach you a little bit about conversation design itself. So there\u2019s gonna be a lot of product shots, talk about a lot of a a specific customer problems, you know, without naming any names, and kinda run you through the process of actually building a tool. I\u2019ll try to keep it fairly short to sync to the point. And, you know, if you wanna chat a little bit more about Voiceflow, we\u2019ve got a social later today as well as a booth at the back. Love chatting product, but I\u2019ll try to keep it fairly succinct \u2019cause I know we\u2019re going into into lunch here.\n\nSo this is thoughts on building a conversation design tool. First time running this, so bear with me. Little bit a\u2026 yep. We already went through the goal here. Got ahead of myself. Little bit about Voiceflow, so we\u2019re used by over eighty thousand teams now. Lots of great customers out there, actually, lots of great customers here as well. I\u2019ve raised about twenty five million dollars from some great investors, including Amazon and Google, who are are present as well as some other awesome design tool folks, including Figma and InVision and and others. Cool. So why does conversation design matter? A lot of folks might actually not be familiar with it. You know, it\u2019s really come to prominent sites over the past two years.\n\n> Conversation design is essentially the UX branch of conversational AI. So it\u2019s applying best practices on the\u2026 from the design world to conversational interfaces. Now why this is becoming increasingly relevant is as the world automates. Really, the industry that a lot of us are in is the talking to people industry. Right? It\u2019s a very large space that\u2019s quickly becoming more and more automated. And as we do this, there\u2019s a lot of focus on the underlying technologies, the ASR, the TTS, the NLUs. And now we\u2019re starting to see a lot more focus on the actual human side of it, the design side. And so that is where conversation design comes in. It is about the content structure as well as the content design itself.\n\nAnd so the challenge for a lot of teams today creating conversational AI is the tools, frankly, aren\u2019t there on the collaborative side. In fact, the most common tool stack we see is going to be Word docs, Excel sheets, and Visio flowcharts. Now there\u2019s lots of flowcharting softwares out there, and I\u2019ve certainly heard people say, well, we don\u2019t use Visio. We use Miro all in the same bucket. It is typically\u2026 next slide here. You\u2019re gonna see spreadsheets are used to manage the NLU design. You\u2019re gonna see, essentially, flowcharts are managed\u2026 manage the state machine. It manages the flow of the conversation. Word docs are often doing the script of the conversation, so a very lightweight, almost like a wire frame just to give people the feel. And the three of these are used in conjunction to create a conversation design. Now the problem with this is\u2026 well, two things. One, you don\u2019t have a single source of truth. And so companies often have\u2026 you know, when you\u2019ve one conversation designer, you can usually work with spreadsheets and flowcharts. That\u2019s when you have two or more or ten or, you know, a hundred in some of these larger companies now, where they\u2019re now getting to these very large teams. And when they have to communicate conversations across different teams and organizations, it might take a week just to understand the design. In fact, when I work with some customers, I\u2019ll go into a design, and we\u2019ll be chatting about it, and it might take me an hour or two just to understand the design before I can even comment on it. And so it gets really, really messy as its scales, have multiple sources of truth. And then further, you\u2019re not able to prototype.\n\nThis is a big challenge for a lot of companies where if they\u2019re coming from Visio flowcharts or, again, Miro, whatever your flowcharting tool of choice is, you\u2019re not able to actually turn that into a usable prototype to run user testing. So a lot of companies will actually go straight from Word docs, Excel sheets, flowcharts, whatever it might be to a Jira ticket and then out to production. That\u2019s a super common workflow we see all the time. Sometimes WoZ testing, which is Wizard of Oz testing, is implemented, and that\u2019s essentially acting as though you are the assistant. So we hear companies where, you know, they\u2019ll have a human on one end the line. They\u2019ll call the other end if they\u2019re trying to simulate a call center experience, and they\u2019ll act as though they are the assistant. So that\u2019s really the low fidelity testing we have available with the existing tool stack. So this is where conversation design tools come into play like Voiceflow. So a streamline way to go from design, prototype, user testing, and then ultimately handing off to development, trying to give them artifacts that are more battle-tested because you\u2019ve actually done the prototyping, the user testing before handing it off to development as well as handing them in artifact is ultimately more readable as it\u2019s all in one place without having to dig through a spreadsheet, like, you know, a flowchart, etcetera. Some nice quotes, but I\u2019m gonna skip through these here and say conversation designs tools ultimately give you a single source of truth.\xA0And so this is the intro to a conversation design if you weren\u2019t familiar with it and sort of what it is and what conversation design tools are.\n\nI wanna spend a little bit time about talking about the role of conversation design. So I think it\u2019s fairly misunderstood what a conversation designer actually does on a daily basis. It\u2019s essentially a mix of a few different a few different roles. So it\u2019s going to be traditional UX. Most conversation designers actually come from a traditional UX background. It\u2019s probably the most common one we see. We also see copywriting as a as a fairly common background, and then you have the NLU model. When you actually look at these in terms of structure, you really have conversation designs sitting on top of the NLU model. It sort of stands on on its shoulders there, and these three practices together create what we talk\u2026 call the conversation designer. And then you\u2019re now starting to see, as these teams are getting larger, they\u2019re getting more sophisticated. The role of the conversation designer is actually starting to split within companies. You\u2019re starting to see AI trainers become a more common role, starting to see copywriters with a\u2026 you know, just very specific copyright and title, and the conversation designers really sort of the flow architect. And so you\u2019re starting to see increased specialization on the UX side of these conversational AI teams. Cool.\n\nSo when we look at, you know, a conversation design\u2026 so here\u2019s just a a sample when I pulled in from Voiceflow. You might have four different rules all working within this one design. You\u2019re gonna have the copywriter who is focused primarily on the responses that the assistant is going to give. They\u2019re going to be responsible for the persona often as well. From there, you\u2019re going to have the NLU designer. They\u2019re working with the different intents to make sure the utterances aren\u2019t conflicting, the model\u2019s actually working, and it\u2019s gonna provide the best design experience. From there, the UX designer\u2019s often responsible for the entire flow. What is the flow of the conversation? What intents are we handling, and how do they structure into each other? So that\u2019s really sort of the role. They\u2019re almost like the the flow architect almost. And then lastly is the UI designer. A lot of experiences are becoming multimodal. Voice is not\u2026 and I think, as the\xA0 previous presentation went over, voice is not the be-all, end-all interfaces one of many, and it\u2019s incredibly good input, but it\u2019s not very good at output. You know? If you\u2019re choosing a Netflix movie, you would certainly would not want to have to be read the thirty different options before you make a choice. It\u2019s gonna be crazy cognitive overload, but we\u2019ve all sat there trying to use the the keyboard on the remote to try to pick a Netflix movie. And if you know what you want, it\u2019s an amazing input interface. So you\u2019re starting to see the rise of multimodal as well as these visual designers are being added to the conversation design teams. So one, you know, thing that, I I think, a lot of folks misunderstand about even voice or other conversations design tools is that we\u2019re not content experts.\n\nYou know, a lot of folks who come from linguistics backgrounds, they might understand, you know, Grice\u2019s Maxim is thrown around quite a bit coming from sociolinguistics. These are sort of the folks who are the best at creating the ideal responses. That\u2019s not asset at Voiceflow. We actually view ourselves as giving you the tools to create the best responses. But as far as we\u2019re concerned, we\u2019re thinking about structure. We\u2019re thinking about collaboration and the workflow. That\u2019s really where we spend most of our time thinking in terms of what is actually said to the user. You know, we\u2019re average average Joes when it comes to the actual content. And so what do I mean by content? Well, that\u2019s going to be what\u2019s actually said. We focus on the content structure. We focus on how can designers visualize the structure of the conversation. How can they actually put this together in a readable, and how can they ultimately collaborate? That\u2019s really where we spend most of our time thinking. So some examples, on the far top top left there, you\u2019ll see, like, a normal response. What the designer actually puts in there\u2026 I\u2019m not a very good copywriter myself. You know, that\u2019s that\u2019s not our forte, but what we\u2019re thinking about is\u2026 k. How can we add response variance? How can we do localization, text markup, speech SSML? How can we allow for all these different structures to be applied to the content more so than what is actually said inside the content itself?\n\nSo if you work at Voiceflow, probably, the number one thing you hear preached constantly is conversation design documentation. It is the number one thing we think about. And the reason for that is, ultimately, the art of conversation design is the art of conversation documentation. You know what you wanna say as a conversation designer, and if you\u2019re a team of one, that\u2019s where you\u2019re able to put this into a\u2026 any kind of artifact you\u2019d like, and how it\u2019s actually presented is not that important. When you start to work in larger teams, it\u2019s all about how you present it in a readable format so that other people can actually use it. So conversation design is the art of conversation documentation. And in order for a conversation design to be useful, it must be easily readable, and I think we\u2019ve all seen flowcharts that look like this. This is\u2026 you know, oh, it\u2019s a little blurry on the screen there, but you can kinda get the point. It is a crazy mess of nodes, and this is how a lot of internal design artifacts look at large enterprises as well as smaller teams. Frankly, there\u2019s not much thought put into the actual design structure, and often what you\u2019ll see is folks come in, and they\u2019re unable to read it, and then they will often opt to completely redo it themselves. You just create a ton of redundancy.\n\nAnd so the best practice here is often to start out. Create a prototype. It might look really messy and spend a lot of time actually refactoring the designed to be highly readable so that other people can collaborate on it with you. So I wanted to spend some time going through essentially customers\u2019 stories that is all along this theme of documentation, so some things that we\u2019ve had to think about as a conversation design tool that you might not think about being a conversation designer. This was a big one. So when we were working with a large automaker, they were switching over their documentation base from Visio to Voiceflow, and we had a lot of seasoned VUI designers, voice user interface designers, sort of a branch within conversation design. Say they\u2026 you know, they\u2019ve been working in Visio for twenty years now, and they\u2019ve always done top to bottom, and therefore for Voiceflow is incompatible and will never work. This is something we hadn\u2019t thought about. Voiceflow was always a left to right structure. That\u2019s just\u2026 you know? In the early days of the company, it was just something we did. It was left to right. That was it. We didn\u2019t really think much about it.\n\nAs the company evolved and now we work with customers that use all different orientations, you actually need to be able to mold the tool to mesh to people\u2019s existing documentation systems so that when they\u2019re going from reading a Visio chart to a Voiceflow chart, it\u2019s going to look comparable, and they\u2019re gonna be able to understand the lay of land instantly. So problem was not being able to go to left to right. Solution was fairly simple, being able to go vertical. Another problem we had was conversation designs aren\u2019t just about the functional nodes on the canvas. It\u2019s not just about the lines. It\u2019s also about the surrounding contacts. There are sticky notes. There are little notes that designers jot down. There are comments. A lot of this wasn\u2019t present in Voiceflow. We just had the functional nodes. We thought, well, if you can build it, that\u2019s good enough. There\u2019s not\u2026 you know? No need to add any sort of additional context. And what we found is design teams were going from Visio to Voiceflow to prototype, and then back to back to Visio to document. So then they would they would document their findings from Voice\u2019s prototypes, and Voiceflow was just used as a prototyping system. So we ask why that was, and it was because they couldn\u2019t add sticky notes. It was the simplest thing, but we just hadn\u2019t thought about it as\u2026 and as a conversation design tool, we learned that the surrounding context is as important as the content itself. And so we added sticky notes, labels, images, all these things that allow your canvas to be high fidelity and flushed with context. Response variations take too much space. You don\u2019t wanna hear the same thing from your system over and over and over again, and so response variations are a big thing in conversation design. Having five, six, you know, seven responses, or more to say the same thing just to keep the experience fresh. And so in Voiceflow, we had this feature. We thought this was great, and we allowed you to stack them all like this. Well, some companies might have a hundred, and they might have a\u2026 you know, two dozen. And it started to completely clutter the canvas, and so companies were again going back to spreadsheets to put all the response variations and then linking to Voiceflow and saying, you know, this should\u2026 is what the variant should have.\n\nAnd so we saw this, and we added the ability to choose your different visibilities, \u2019cause, again, it\u2019s all about being able to either\u2026 essentially, layer your visibility. Are you gonna share everything, or are you just gonna share what\u2019s needed to be seen by that particular individual? So we have\u2026 often see this a lot with even executive stakeholders. When they come and look at a conversation design, the designer will change the visibility to be just the bare essentials of the conversation. Anything more and the executives, you know, go asking about, you know, variation fifteen, what\u2019s going on there? It\u2019s way too much. You just wanna share just the bare minimum to understand the conversation flow. But then when you\u2019re sharing with maybe a developer, you wanna be able to show all those different variations to really give the give the scope. So selective visibility has been\u2026 become incredibly important. Customers were adding a ton of designs to make the prototype work. This is a really curious one. So we were chatting with a bunch of customers and they were adding a ton of work to the designs, only to make the prototype work, and so the best example of this was personas. They wanted you test out. What happens if we have a a user who\u2019s logged in versus logged out? So what they would do is they would actually add inside the design a whole bunch of logic and variables and things to actually create these different personas that would then be used inside the prototype. Now the problem here is by doing this, the\u2026 this\u2026 developers, when they saw the design, weren\u2019t sure is this part of the design, or is this part just\u2026 to make the prototype work?\n\nAnd so this has become a super common problem, especially with the enterprise where they testing, you know, two personas, five personas when they\u2019re doing user testing, and so we added the ability to test different personas. And so you start seeing a thing where it\u2019s very customer led and that conversation design is such a new field. The UX side has been around on the IVR side for about twenty years, but in terms of the UX, sort of, adopting what\u2019s the modern UI practices to conversation design now, that\u2019s only really come in the past two years. And so we\u2019re essentially building a new category of tooling, and we\u2019re learning all this stuff as we go. Few more here. Customers were creating multiple projects for the same assistant. Designs are getting very, very large. If you run a contact center today, you\u2019re going to have massive flows, and so we saw our customers creating tons and tons of projects just to handle different variations, so we added folders. I could go off this. Yeah.\n\nLast one here. Different stakeholders need different information. What we found is that the same node on a canvas might be used differently by two different people even on the same team. So the developer is gonna look at this and go, oh, great. There is the JavaScript logic I needed. I can now reference that easily into my actual code, but the designer looks at that and has no idea what\u2019s going on often. And so we added the ability to do role-based views. You have a developer view or a designer view. It\u2019s really up to you. And so this is sort of the evolving state. As these teams get larger and larger and different roles are being added, you\u2019re gonna see these tools essentially become multifaceted in how they can actually display information depending on the rule. Since a conversation is such an abstract concept, it is going to be different to every stakeholder that views it. And so you need to be able to chunk and break down that layered visibility. It\u2019s very similar too. In a design tool, you know, you might see the color red, and the developer needs to see the hex code. And so you\u2019re gonna have that ability to break down a conversation by all of its different elements as you go through. Cool. I think we can go through this. Yeah. Some problems, I think, the industry has yet to solve, you know, intent manager\u2026 intent management. We call them an\u2026 essentially, an IMS internally.\n\nSome customers have thousands of intents, tens of thousands that you\u2019re\u2026 you know, at some of these larger companies, almost having what you have for a content management system and applying that to the intent space, especially as you deal with different locals, different NLPs and NLUs, having a robust system, the industry has yet to solve that, but there are some exciting start-ups popping up. Content management. Content management, as it relates specifically to conversational assistance, there\u2019s a couple start-ups that popped up that are exciting, but this is something that\u2019s going to be increasingly important as these assistants are deployed, not just in one local, but in multiple locals, getting to the point where it\u2019s not just countries but even down to the city level. Maybe you have a restaurant in a\u2026 one city that has a very different, you know, phrase for good morning than another, we wanna have conversational assistance, meet customers where they are, and actually be able to get down to that local level. So content management\u2019s gonna be incredibly important.\n\nThen lastly, persona management. You know, certainly brands want to have one assistant that is going to be able to interact with customers across all channels, and so having a way to manage that persona in terms of its vocabulary and how it actually interacts with customers, I think you\u2019re gonna start to see a a persona management software pop up as well. So that\u2019s some exciting stuff there, but lots more in the industry to solve on the collaborative side. And that is it on my end. I wanted to essentially have a bunch of different product product shots to kinda run through some different solutions. From the conversation design tool side, hopefully, you learned a little bit about conversation design through that process. We\u2019d love to chat with a bunch of folks. If you wanna chat about conversation design practices, the talk I\u2019ve given previously on how to actually structure our team, happy to do that as well. We\u2019ve got a booth at the back in a social today at four thirty, and there will be free drinks. So\u2026 and it\u2019s a beautiful venue right on the beach. So feel free to come by. Say hi, and we\u2019ll give you a ticket for that. And with that, thanks so much.", "html": '<p><em>This is the transcript for the session \u201CSparking the Future of Conversation Design\u201D presented by Braden Ream, CEO of Voiceflow, presented on day one of Project Voice X.</em>\xA0</p>\n<p><em>The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0<strong>94% accurate.</strong>\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0<a href="https://deepgram.com/contact-us/">contact us</a>.</em></p>\n<p>[Braden Ream:] Alrighty. Hi, everyone. Thanks for having me here. So I\u2019ve given a bunch of talks on conversation design in the past, and the one I most often give is how to structure a conversation design team, so how to build one internally, build out the best practices. I thought what may be kinda fun is\u2026 you know, we learn a lot about conversation design through the practices of actually building Voiceflow. And so I thought it could be interesting to talk about the challenges of building a conversation design tool, which will, hopefully, in effect, teach you a little bit about conversation design itself. So there\u2019s gonna be a lot of product shots, talk about a lot of a a specific customer problems, you know, without naming any names, and kinda run you through the process of actually building a tool. I\u2019ll try to keep it fairly short to sync to the point. And, you know, if you wanna chat a little bit more about Voiceflow, we\u2019ve got a social later today as well as a booth at the back. Love chatting product, but I\u2019ll try to keep it fairly succinct \u2019cause I know we\u2019re going into into lunch here.</p>\n<p>So this is thoughts on building a conversation design tool. First time running this, so bear with me. Little bit a\u2026 yep. We already went through the goal here. Got ahead of myself. Little bit about Voiceflow, so we\u2019re used by over eighty thousand teams now. Lots of great customers out there, actually, lots of great customers here as well. I\u2019ve raised about twenty five million dollars from some great investors, including Amazon and Google, who are are present as well as some other awesome design tool folks, including Figma and InVision and and others. Cool. So why does conversation design matter? A lot of folks might actually not be familiar with it. You know, it\u2019s really come to prominent sites over the past two years.</p>\n<blockquote>\n<p>Conversation design is essentially the UX branch of conversational AI. So it\u2019s applying best practices on the\u2026 from the design world to conversational interfaces. Now why this is becoming increasingly relevant is as the world automates. Really, the industry that a lot of us are in is the talking to people industry. Right? It\u2019s a very large space that\u2019s quickly becoming more and more automated. And as we do this, there\u2019s a lot of focus on the underlying technologies, the ASR, the TTS, the NLUs. And now we\u2019re starting to see a lot more focus on the actual human side of it, the design side. And so that is where conversation design comes in. It is about the content structure as well as the content design itself.</p>\n</blockquote>\n<p>And so the challenge for a lot of teams today creating conversational AI is the tools, frankly, aren\u2019t there on the collaborative side. In fact, the most common tool stack we see is going to be Word docs, Excel sheets, and Visio flowcharts. Now there\u2019s lots of flowcharting softwares out there, and I\u2019ve certainly heard people say, well, we don\u2019t use Visio. We use Miro all in the same bucket. It is typically\u2026 next slide here. You\u2019re gonna see spreadsheets are used to manage the NLU design. You\u2019re gonna see, essentially, flowcharts are managed\u2026 manage the state machine. It manages the flow of the conversation. Word docs are often doing the script of the conversation, so a very lightweight, almost like a wire frame just to give people the feel. And the three of these are used in conjunction to create a conversation design. Now the problem with this is\u2026 well, two things. One, you don\u2019t have a single source of truth. And so companies often have\u2026 you know, when you\u2019ve one conversation designer, you can usually work with spreadsheets and flowcharts. That\u2019s when you have two or more or ten or, you know, a hundred in some of these larger companies now, where they\u2019re now getting to these very large teams. And when they have to communicate conversations across different teams and organizations, it might take a week just to understand the design. In fact, when I work with some customers, I\u2019ll go into a design, and we\u2019ll be chatting about it, and it might take me an hour or two just to understand the design before I can even comment on it. And so it gets really, really messy as its scales, have multiple sources of truth. And then further, you\u2019re not able to prototype.</p>\n<p>This is a big challenge for a lot of companies where if they\u2019re coming from Visio flowcharts or, again, Miro, whatever your flowcharting tool of choice is, you\u2019re not able to actually turn that into a usable prototype to run user testing. So a lot of companies will actually go straight from Word docs, Excel sheets, flowcharts, whatever it might be to a Jira ticket and then out to production. That\u2019s a super common workflow we see all the time. Sometimes WoZ testing, which is Wizard of Oz testing, is implemented, and that\u2019s essentially acting as though you are the assistant. So we hear companies where, you know, they\u2019ll have a human on one end the line. They\u2019ll call the other end if they\u2019re trying to simulate a call center experience, and they\u2019ll act as though they are the assistant. So that\u2019s really the low fidelity testing we have available with the existing tool stack. So this is where conversation design tools come into play like Voiceflow. So a streamline way to go from design, prototype, user testing, and then ultimately handing off to development, trying to give them artifacts that are more battle-tested because you\u2019ve actually done the prototyping, the user testing before handing it off to development as well as handing them in artifact is ultimately more readable as it\u2019s all in one place without having to dig through a spreadsheet, like, you know, a flowchart, etcetera. Some nice quotes, but I\u2019m gonna skip through these here and say conversation designs tools ultimately give you a single source of truth.\xA0And so this is the intro to a conversation design if you weren\u2019t familiar with it and sort of what it is and what conversation design tools are.</p>\n<p>I wanna spend a little bit time about talking about the role of conversation design. So I think it\u2019s fairly misunderstood what a conversation designer actually does on a daily basis. It\u2019s essentially a mix of a few different a few different roles. So it\u2019s going to be traditional UX. Most conversation designers actually come from a traditional UX background. It\u2019s probably the most common one we see. We also see copywriting as a as a fairly common background, and then you have the NLU model. When you actually look at these in terms of structure, you really have conversation designs sitting on top of the NLU model. It sort of stands on on its shoulders there, and these three practices together create what we talk\u2026 call the conversation designer. And then you\u2019re now starting to see, as these teams are getting larger, they\u2019re getting more sophisticated. The role of the conversation designer is actually starting to split within companies. You\u2019re starting to see AI trainers become a more common role, starting to see copywriters with a\u2026 you know, just very specific copyright and title, and the conversation designers really sort of the flow architect. And so you\u2019re starting to see increased specialization on the UX side of these conversational AI teams. Cool.</p>\n<p>So when we look at, you know, a conversation design\u2026 so here\u2019s just a a sample when I pulled in from Voiceflow. You might have four different rules all working within this one design. You\u2019re gonna have the copywriter who is focused primarily on the responses that the assistant is going to give. They\u2019re going to be responsible for the persona often as well. From there, you\u2019re going to have the NLU designer. They\u2019re working with the different intents to make sure the utterances aren\u2019t conflicting, the model\u2019s actually working, and it\u2019s gonna provide the best design experience. From there, the UX designer\u2019s often responsible for the entire flow. What is the flow of the conversation? What intents are we handling, and how do they structure into each other? So that\u2019s really sort of the role. They\u2019re almost like the the flow architect almost. And then lastly is the UI designer. A lot of experiences are becoming multimodal. Voice is not\u2026 and I think, as the\xA0 previous presentation went over, voice is not the be-all, end-all interfaces one of many, and it\u2019s incredibly good input, but it\u2019s not very good at output. You know? If you\u2019re choosing a Netflix movie, you would certainly would not want to have to be read the thirty different options before you make a choice. It\u2019s gonna be crazy cognitive overload, but we\u2019ve all sat there trying to use the the keyboard on the remote to try to pick a Netflix movie. And if you know what you want, it\u2019s an amazing input interface. So you\u2019re starting to see the rise of multimodal as well as these visual designers are being added to the conversation design teams. So one, you know, thing that, I I think, a lot of folks misunderstand about even voice or other conversations design tools is that we\u2019re not content experts.</p>\n<p>You know, a lot of folks who come from linguistics backgrounds, they might understand, you know, Grice\u2019s Maxim is thrown around quite a bit coming from sociolinguistics. These are sort of the folks who are the best at creating the ideal responses. That\u2019s not asset at Voiceflow. We actually view ourselves as giving you the tools to create the best responses. But as far as we\u2019re concerned, we\u2019re thinking about structure. We\u2019re thinking about collaboration and the workflow. That\u2019s really where we spend most of our time thinking in terms of what is actually said to the user. You know, we\u2019re average average Joes when it comes to the actual content. And so what do I mean by content? Well, that\u2019s going to be what\u2019s actually said. We focus on the content structure. We focus on how can designers visualize the structure of the conversation. How can they actually put this together in a readable, and how can they ultimately collaborate? That\u2019s really where we spend most of our time thinking. So some examples, on the far top top left there, you\u2019ll see, like, a normal response. What the designer actually puts in there\u2026 I\u2019m not a very good copywriter myself. You know, that\u2019s that\u2019s not our forte, but what we\u2019re thinking about is\u2026 k. How can we add response variance? How can we do localization, text markup, speech SSML? How can we allow for all these different structures to be applied to the content more so than what is actually said inside the content itself?</p>\n<p>So if you work at Voiceflow, probably, the number one thing you hear preached constantly is conversation design documentation. It is the number one thing we think about. And the reason for that is, ultimately, the art of conversation design is the art of conversation documentation. You know what you wanna say as a conversation designer, and if you\u2019re a team of one, that\u2019s where you\u2019re able to put this into a\u2026 any kind of artifact you\u2019d like, and how it\u2019s actually presented is not that important. When you start to work in larger teams, it\u2019s all about how you present it in a readable format so that other people can actually use it. So conversation design is the art of conversation documentation. And in order for a conversation design to be useful, it must be easily readable, and I think we\u2019ve all seen flowcharts that look like this. This is\u2026 you know, oh, it\u2019s a little blurry on the screen there, but you can kinda get the point. It is a crazy mess of nodes, and this is how a lot of internal design artifacts look at large enterprises as well as smaller teams. Frankly, there\u2019s not much thought put into the actual design structure, and often what you\u2019ll see is folks come in, and they\u2019re unable to read it, and then they will often opt to completely redo it themselves. You just create a ton of redundancy.</p>\n<p>And so the best practice here is often to start out. Create a prototype. It might look really messy and spend a lot of time actually refactoring the designed to be highly readable so that other people can collaborate on it with you. So I wanted to spend some time going through essentially customers\u2019 stories that is all along this theme of documentation, so some things that we\u2019ve had to think about as a conversation design tool that you might not think about being a conversation designer. This was a big one. So when we were working with a large automaker, they were switching over their documentation base from Visio to Voiceflow, and we had a lot of seasoned VUI designers, voice user interface designers, sort of a branch within conversation design. Say they\u2026 you know, they\u2019ve been working in Visio for twenty years now, and they\u2019ve always done top to bottom, and therefore for Voiceflow is incompatible and will never work. This is something we hadn\u2019t thought about. Voiceflow was always a left to right structure. That\u2019s just\u2026 you know? In the early days of the company, it was just something we did. It was left to right. That was it. We didn\u2019t really think much about it.</p>\n<p>As the company evolved and now we work with customers that use all different orientations, you actually need to be able to mold the tool to mesh to people\u2019s existing documentation systems so that when they\u2019re going from reading a Visio chart to a Voiceflow chart, it\u2019s going to look comparable, and they\u2019re gonna be able to understand the lay of land instantly. So problem was not being able to go to left to right. Solution was fairly simple, being able to go vertical. Another problem we had was conversation designs aren\u2019t just about the functional nodes on the canvas. It\u2019s not just about the lines. It\u2019s also about the surrounding contacts. There are sticky notes. There are little notes that designers jot down. There are comments. A lot of this wasn\u2019t present in Voiceflow. We just had the functional nodes. We thought, well, if you can build it, that\u2019s good enough. There\u2019s not\u2026 you know? No need to add any sort of additional context. And what we found is design teams were going from Visio to Voiceflow to prototype, and then back to back to Visio to document. So then they would they would document their findings from Voice\u2019s prototypes, and Voiceflow was just used as a prototyping system. So we ask why that was, and it was because they couldn\u2019t add sticky notes. It was the simplest thing, but we just hadn\u2019t thought about it as\u2026 and as a conversation design tool, we learned that the surrounding context is as important as the content itself. And so we added sticky notes, labels, images, all these things that allow your canvas to be high fidelity and flushed with context. Response variations take too much space. You don\u2019t wanna hear the same thing from your system over and over and over again, and so response variations are a big thing in conversation design. Having five, six, you know, seven responses, or more to say the same thing just to keep the experience fresh. And so in Voiceflow, we had this feature. We thought this was great, and we allowed you to stack them all like this. Well, some companies might have a hundred, and they might have a\u2026 you know, two dozen. And it started to completely clutter the canvas, and so companies were again going back to spreadsheets to put all the response variations and then linking to Voiceflow and saying, you know, this should\u2026 is what the variant should have.</p>\n<p>And so we saw this, and we added the ability to choose your different visibilities, \u2019cause, again, it\u2019s all about being able to either\u2026 essentially, layer your visibility. Are you gonna share everything, or are you just gonna share what\u2019s needed to be seen by that particular individual? So we have\u2026 often see this a lot with even executive stakeholders. When they come and look at a conversation design, the designer will change the visibility to be just the bare essentials of the conversation. Anything more and the executives, you know, go asking about, you know, variation fifteen, what\u2019s going on there? It\u2019s way too much. You just wanna share just the bare minimum to understand the conversation flow. But then when you\u2019re sharing with maybe a developer, you wanna be able to show all those different variations to really give the give the scope. So selective visibility has been\u2026 become incredibly important. Customers were adding a ton of designs to make the prototype work. This is a really curious one. So we were chatting with a bunch of customers and they were adding a ton of work to the designs, only to make the prototype work, and so the best example of this was personas. They wanted you test out. What happens if we have a a user who\u2019s logged in versus logged out? So what they would do is they would actually add inside the design a whole bunch of logic and variables and things to actually create these different personas that would then be used inside the prototype. Now the problem here is by doing this, the\u2026 this\u2026 developers, when they saw the design, weren\u2019t sure is this part of the design, or is this part just\u2026 to make the prototype work?</p>\n<p>And so this has become a super common problem, especially with the enterprise where they testing, you know, two personas, five personas when they\u2019re doing user testing, and so we added the ability to test different personas. And so you start seeing a thing where it\u2019s very customer led and that conversation design is such a new field. The UX side has been around on the IVR side for about twenty years, but in terms of the UX, sort of, adopting what\u2019s the modern UI practices to conversation design now, that\u2019s only really come in the past two years. And so we\u2019re essentially building a new category of tooling, and we\u2019re learning all this stuff as we go. Few more here. Customers were creating multiple projects for the same assistant. Designs are getting very, very large. If you run a contact center today, you\u2019re going to have massive flows, and so we saw our customers creating tons and tons of projects just to handle different variations, so we added folders. I could go off this. Yeah.</p>\n<p>Last one here. Different stakeholders need different information. What we found is that the same node on a canvas might be used differently by two different people even on the same team. So the developer is gonna look at this and go, oh, great. There is the JavaScript logic I needed. I can now reference that easily into my actual code, but the designer looks at that and has no idea what\u2019s going on often. And so we added the ability to do role-based views. You have a developer view or a designer view. It\u2019s really up to you. And so this is sort of the evolving state. As these teams get larger and larger and different roles are being added, you\u2019re gonna see these tools essentially become multifaceted in how they can actually display information depending on the rule. Since a conversation is such an abstract concept, it is going to be different to every stakeholder that views it. And so you need to be able to chunk and break down that layered visibility. It\u2019s very similar too. In a design tool, you know, you might see the color red, and the developer needs to see the hex code. And so you\u2019re gonna have that ability to break down a conversation by all of its different elements as you go through. Cool. I think we can go through this. Yeah. Some problems, I think, the industry has yet to solve, you know, intent manager\u2026 intent management. We call them an\u2026 essentially, an IMS internally.</p>\n<p>Some customers have thousands of intents, tens of thousands that you\u2019re\u2026 you know, at some of these larger companies, almost having what you have for a content management system and applying that to the intent space, especially as you deal with different locals, different NLPs and NLUs, having a robust system, the industry has yet to solve that, but there are some exciting start-ups popping up. Content management. Content management, as it relates specifically to conversational assistance, there\u2019s a couple start-ups that popped up that are exciting, but this is something that\u2019s going to be increasingly important as these assistants are deployed, not just in one local, but in multiple locals, getting to the point where it\u2019s not just countries but even down to the city level. Maybe you have a restaurant in a\u2026 one city that has a very different, you know, phrase for good morning than another, we wanna have conversational assistance, meet customers where they are, and actually be able to get down to that local level. So content management\u2019s gonna be incredibly important.</p>\n<p>Then lastly, persona management. You know, certainly brands want to have one assistant that is going to be able to interact with customers across all channels, and so having a way to manage that persona in terms of its vocabulary and how it actually interacts with customers, I think you\u2019re gonna start to see a a persona management software pop up as well. So that\u2019s some exciting stuff there, but lots more in the industry to solve on the collaborative side. And that is it on my end. I wanted to essentially have a bunch of different product product shots to kinda run through some different solutions. From the conversation design tool side, hopefully, you learned a little bit about conversation design through that process. We\u2019d love to chat with a bunch of folks. If you wanna chat about conversation design practices, the talk I\u2019ve given previously on how to actually structure our team, happy to do that as well. We\u2019ve got a booth at the back in a social today at four thirty, and there will be free drinks. So\u2026 and it\u2019s a beautiful venue right on the beach. So feel free to come by. Say hi, and we\u2019ll give you a ticket for that. And with that, thanks so much.</p>' };
const frontmatter = { "title": "Sparking the Future of Conversation Design - Braden Ream, CEO, Voiceflow - Project Voice X", "description": "Speaking the Future of Conversation design voiceflow. This is the transcript for the session presented by Braden Ream, CEO of Voiceflow", "date": "2021-12-09T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1661981392/blog/sparking-the-future-of-conversation-design-braden-ream-ceo-voiceflow-project-voice-x/proj-voice-x-session-braden-ream-blog-thumb-554x22.png", "authors": ["claudia-ring"], "category": "speech-trends", "tags": ["conversational-ai", "project-voice-x"], "seo": { "title": "Sparking the Future of Conversation Design - Braden Ream, CEO, Voiceflow - Project Voice X", "description": "Speaking the Future of Conversation design voiceflow. This is the transcript for the session presented by Braden Ream, CEO of Voiceflow" }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661981392/blog/sparking-the-future-of-conversation-design-braden-ream-ceo-voiceflow-project-voice-x/proj-voice-x-session-braden-ream-blog-thumb-554x22.png" }, "shorturls": { "share": "https://dpgr.am/2113016", "twitter": "https://dpgr.am/f6fcfa7", "linkedin": "https://dpgr.am/7a45a55", "reddit": "https://dpgr.am/0429d31", "facebook": "https://dpgr.am/a5d913b" }, "astro": { "headings": [], "source": "*This is the transcript for the session \u201CSparking the Future of Conversation Design\u201D presented by Braden Ream, CEO of Voiceflow, presented on day one of Project Voice X.*\xA0\n\n*The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0**94% accurate.**\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0[contact us](https://deepgram.com/contact-us/).*\n\n\\[Braden Ream:] Alrighty. Hi, everyone. Thanks for having me here. So I\u2019ve given a bunch of talks on conversation design in the past, and the one I most often give is how to structure a conversation design team, so how to build one internally, build out the best practices. I thought what may be kinda fun is\u2026 you know, we learn a lot about conversation design through the practices of actually building Voiceflow. And so I thought it could be interesting to talk about the challenges of building a conversation design tool, which will, hopefully, in effect, teach you a little bit about conversation design itself. So there\u2019s gonna be a lot of product shots, talk about a lot of a a specific customer problems, you know, without naming any names, and kinda run you through the process of actually building a tool. I\u2019ll try to keep it fairly short to sync to the point. And, you know, if you wanna chat a little bit more about Voiceflow, we\u2019ve got a social later today as well as a booth at the back. Love chatting product, but I\u2019ll try to keep it fairly succinct \u2019cause I know we\u2019re going into into lunch here.\n\nSo this is thoughts on building a conversation design tool. First time running this, so bear with me. Little bit a\u2026 yep. We already went through the goal here. Got ahead of myself. Little bit about Voiceflow, so we\u2019re used by over eighty thousand teams now. Lots of great customers out there, actually, lots of great customers here as well. I\u2019ve raised about twenty five million dollars from some great investors, including Amazon and Google, who are are present as well as some other awesome design tool folks, including Figma and InVision and and others. Cool. So why does conversation design matter? A lot of folks might actually not be familiar with it. You know, it\u2019s really come to prominent sites over the past two years.\n\n> Conversation design is essentially the UX branch of conversational AI. So it\u2019s applying best practices on the\u2026 from the design world to conversational interfaces. Now why this is becoming increasingly relevant is as the world automates. Really, the industry that a lot of us are in is the talking to people industry. Right? It\u2019s a very large space that\u2019s quickly becoming more and more automated. And as we do this, there\u2019s a lot of focus on the underlying technologies, the ASR, the TTS, the NLUs. And now we\u2019re starting to see a lot more focus on the actual human side of it, the design side. And so that is where conversation design comes in. It is about the content structure as well as the content design itself.\n\nAnd so the challenge for a lot of teams today creating conversational AI is the tools, frankly, aren\u2019t there on the collaborative side. In fact, the most common tool stack we see is going to be Word docs, Excel sheets, and Visio flowcharts. Now there\u2019s lots of flowcharting softwares out there, and I\u2019ve certainly heard people say, well, we don\u2019t use Visio. We use Miro all in the same bucket. It is typically\u2026 next slide here. You\u2019re gonna see spreadsheets are used to manage the NLU design. You\u2019re gonna see, essentially, flowcharts are managed\u2026 manage the state machine. It manages the flow of the conversation. Word docs are often doing the script of the conversation, so a very lightweight, almost like a wire frame just to give people the feel. And the three of these are used in conjunction to create a conversation design. Now the problem with this is\u2026 well, two things. One, you don\u2019t have a single source of truth. And so companies often have\u2026 you know, when you\u2019ve one conversation designer, you can usually work with spreadsheets and flowcharts. That\u2019s when you have two or more or ten or, you know, a hundred in some of these larger companies now, where they\u2019re now getting to these very large teams. And when they have to communicate conversations across different teams and organizations, it might take a week just to understand the design. In fact, when I work with some customers, I\u2019ll go into a design, and we\u2019ll be chatting about it, and it might take me an hour or two just to understand the design before I can even comment on it. And so it gets really, really messy as its scales, have multiple sources of truth. And then further, you\u2019re not able to prototype.\n\nThis is a big challenge for a lot of companies where if they\u2019re coming from Visio flowcharts or, again, Miro, whatever your flowcharting tool of choice is, you\u2019re not able to actually turn that into a usable prototype to run user testing. So a lot of companies will actually go straight from Word docs, Excel sheets, flowcharts, whatever it might be to a Jira ticket and then out to production. That\u2019s a super common workflow we see all the time. Sometimes WoZ testing, which is Wizard of Oz testing, is implemented, and that\u2019s essentially acting as though you are the assistant. So we hear companies where, you know, they\u2019ll have a human on one end the line. They\u2019ll call the other end if they\u2019re trying to simulate a call center experience, and they\u2019ll act as though they are the assistant. So that\u2019s really the low fidelity testing we have available with the existing tool stack. So this is where conversation design tools come into play like Voiceflow. So a streamline way to go from design, prototype, user testing, and then ultimately handing off to development, trying to give them artifacts that are more battle-tested because you\u2019ve actually done the prototyping, the user testing before handing it off to development as well as handing them in artifact is ultimately more readable as it\u2019s all in one place without having to dig through a spreadsheet, like, you know, a flowchart, etcetera. Some nice quotes, but I\u2019m gonna skip through these here and say conversation designs tools ultimately give you a single source of truth.\xA0And so this is the intro to a conversation design if you weren\u2019t familiar with it and sort of what it is and what conversation design tools are.\n\nI wanna spend a little bit time about talking about the role of conversation design. So I think it\u2019s fairly misunderstood what a conversation designer actually does on a daily basis. It\u2019s essentially a mix of a few different a few different roles. So it\u2019s going to be traditional UX. Most conversation designers actually come from a traditional UX background. It\u2019s probably the most common one we see. We also see copywriting as a as a fairly common background, and then you have the NLU model. When you actually look at these in terms of structure, you really have conversation designs sitting on top of the NLU model. It sort of stands on on its shoulders there, and these three practices together create what we talk\u2026 call the conversation designer. And then you\u2019re now starting to see, as these teams are getting larger, they\u2019re getting more sophisticated. The role of the conversation designer is actually starting to split within companies. You\u2019re starting to see AI trainers become a more common role, starting to see copywriters with a\u2026 you know, just very specific copyright and title, and the conversation designers really sort of the flow architect. And so you\u2019re starting to see increased specialization on the UX side of these conversational AI teams. Cool.\n\nSo when we look at, you know, a conversation design\u2026 so here\u2019s just a a sample when I pulled in from Voiceflow. You might have four different rules all working within this one design. You\u2019re gonna have the copywriter who is focused primarily on the responses that the assistant is going to give. They\u2019re going to be responsible for the persona often as well. From there, you\u2019re going to have the NLU designer. They\u2019re working with the different intents to make sure the utterances aren\u2019t conflicting, the model\u2019s actually working, and it\u2019s gonna provide the best design experience. From there, the UX designer\u2019s often responsible for the entire flow. What is the flow of the conversation? What intents are we handling, and how do they structure into each other? So that\u2019s really sort of the role. They\u2019re almost like the the flow architect almost. And then lastly is the UI designer. A lot of experiences are becoming multimodal. Voice is not\u2026 and I think, as the\xA0 previous presentation went over, voice is not the be-all, end-all interfaces one of many, and it\u2019s incredibly good input, but it\u2019s not very good at output. You know? If you\u2019re choosing a Netflix movie, you would certainly would not want to have to be read the thirty different options before you make a choice. It\u2019s gonna be crazy cognitive overload, but we\u2019ve all sat there trying to use the the keyboard on the remote to try to pick a Netflix movie. And if you know what you want, it\u2019s an amazing input interface. So you\u2019re starting to see the rise of multimodal as well as these visual designers are being added to the conversation design teams. So one, you know, thing that, I I think, a lot of folks misunderstand about even voice or other conversations design tools is that we\u2019re not content experts.\n\nYou know, a lot of folks who come from linguistics backgrounds, they might understand, you know, Grice\u2019s Maxim is thrown around quite a bit coming from sociolinguistics. These are sort of the folks who are the best at creating the ideal responses. That\u2019s not asset at Voiceflow. We actually view ourselves as giving you the tools to create the best responses. But as far as we\u2019re concerned, we\u2019re thinking about structure. We\u2019re thinking about collaboration and the workflow. That\u2019s really where we spend most of our time thinking in terms of what is actually said to the user. You know, we\u2019re average average Joes when it comes to the actual content. And so what do I mean by content? Well, that\u2019s going to be what\u2019s actually said. We focus on the content structure. We focus on how can designers visualize the structure of the conversation. How can they actually put this together in a readable, and how can they ultimately collaborate? That\u2019s really where we spend most of our time thinking. So some examples, on the far top top left there, you\u2019ll see, like, a normal response. What the designer actually puts in there\u2026 I\u2019m not a very good copywriter myself. You know, that\u2019s that\u2019s not our forte, but what we\u2019re thinking about is\u2026 k. How can we add response variance? How can we do localization, text markup, speech SSML? How can we allow for all these different structures to be applied to the content more so than what is actually said inside the content itself?\n\nSo if you work at Voiceflow, probably, the number one thing you hear preached constantly is conversation design documentation. It is the number one thing we think about. And the reason for that is, ultimately, the art of conversation design is the art of conversation documentation. You know what you wanna say as a conversation designer, and if you\u2019re a team of one, that\u2019s where you\u2019re able to put this into a\u2026 any kind of artifact you\u2019d like, and how it\u2019s actually presented is not that important. When you start to work in larger teams, it\u2019s all about how you present it in a readable format so that other people can actually use it. So conversation design is the art of conversation documentation. And in order for a conversation design to be useful, it must be easily readable, and I think we\u2019ve all seen flowcharts that look like this. This is\u2026 you know, oh, it\u2019s a little blurry on the screen there, but you can kinda get the point. It is a crazy mess of nodes, and this is how a lot of internal design artifacts look at large enterprises as well as smaller teams. Frankly, there\u2019s not much thought put into the actual design structure, and often what you\u2019ll see is folks come in, and they\u2019re unable to read it, and then they will often opt to completely redo it themselves. You just create a ton of redundancy.\n\nAnd so the best practice here is often to start out. Create a prototype. It might look really messy and spend a lot of time actually refactoring the designed to be highly readable so that other people can collaborate on it with you. So I wanted to spend some time going through essentially customers\u2019 stories that is all along this theme of documentation, so some things that we\u2019ve had to think about as a conversation design tool that you might not think about being a conversation designer. This was a big one. So when we were working with a large automaker, they were switching over their documentation base from Visio to Voiceflow, and we had a lot of seasoned VUI designers, voice user interface designers, sort of a branch within conversation design. Say they\u2026 you know, they\u2019ve been working in Visio for twenty years now, and they\u2019ve always done top to bottom, and therefore for Voiceflow is incompatible and will never work. This is something we hadn\u2019t thought about. Voiceflow was always a left to right structure. That\u2019s just\u2026 you know? In the early days of the company, it was just something we did. It was left to right. That was it. We didn\u2019t really think much about it.\n\nAs the company evolved and now we work with customers that use all different orientations, you actually need to be able to mold the tool to mesh to people\u2019s existing documentation systems so that when they\u2019re going from reading a Visio chart to a Voiceflow chart, it\u2019s going to look comparable, and they\u2019re gonna be able to understand the lay of land instantly. So problem was not being able to go to left to right. Solution was fairly simple, being able to go vertical. Another problem we had was conversation designs aren\u2019t just about the functional nodes on the canvas. It\u2019s not just about the lines. It\u2019s also about the surrounding contacts. There are sticky notes. There are little notes that designers jot down. There are comments. A lot of this wasn\u2019t present in Voiceflow. We just had the functional nodes. We thought, well, if you can build it, that\u2019s good enough. There\u2019s not\u2026 you know? No need to add any sort of additional context. And what we found is design teams were going from Visio to Voiceflow to prototype, and then back to back to Visio to document. So then they would they would document their findings from Voice\u2019s prototypes, and Voiceflow was just used as a prototyping system. So we ask why that was, and it was because they couldn\u2019t add sticky notes. It was the simplest thing, but we just hadn\u2019t thought about it as\u2026 and as a conversation design tool, we learned that the surrounding context is as important as the content itself. And so we added sticky notes, labels, images, all these things that allow your canvas to be high fidelity and flushed with context. Response variations take too much space. You don\u2019t wanna hear the same thing from your system over and over and over again, and so response variations are a big thing in conversation design. Having five, six, you know, seven responses, or more to say the same thing just to keep the experience fresh. And so in Voiceflow, we had this feature. We thought this was great, and we allowed you to stack them all like this. Well, some companies might have a hundred, and they might have a\u2026 you know, two dozen. And it started to completely clutter the canvas, and so companies were again going back to spreadsheets to put all the response variations and then linking to Voiceflow and saying, you know, this should\u2026 is what the variant should have.\n\nAnd so we saw this, and we added the ability to choose your different visibilities, \u2019cause, again, it\u2019s all about being able to either\u2026 essentially, layer your visibility. Are you gonna share everything, or are you just gonna share what\u2019s needed to be seen by that particular individual? So we have\u2026 often see this a lot with even executive stakeholders. When they come and look at a conversation design, the designer will change the visibility to be just the bare essentials of the conversation. Anything more and the executives, you know, go asking about, you know, variation fifteen, what\u2019s going on there? It\u2019s way too much. You just wanna share just the bare minimum to understand the conversation flow. But then when you\u2019re sharing with maybe a developer, you wanna be able to show all those different variations to really give the give the scope. So selective visibility has been\u2026 become incredibly important. Customers were adding a ton of designs to make the prototype work. This is a really curious one. So we were chatting with a bunch of customers and they were adding a ton of work to the designs, only to make the prototype work, and so the best example of this was personas. They wanted you test out. What happens if we have a a user who\u2019s logged in versus logged out? So what they would do is they would actually add inside the design a whole bunch of logic and variables and things to actually create these different personas that would then be used inside the prototype. Now the problem here is by doing this, the\u2026 this\u2026 developers, when they saw the design, weren\u2019t sure is this part of the design, or is this part just\u2026 to make the prototype work?\n\nAnd so this has become a super common problem, especially with the enterprise where they testing, you know, two personas, five personas when they\u2019re doing user testing, and so we added the ability to test different personas. And so you start seeing a thing where it\u2019s very customer led and that conversation design is such a new field. The UX side has been around on the IVR side for about twenty years, but in terms of the UX, sort of, adopting what\u2019s the modern UI practices to conversation design now, that\u2019s only really come in the past two years. And so we\u2019re essentially building a new category of tooling, and we\u2019re learning all this stuff as we go. Few more here. Customers were creating multiple projects for the same assistant. Designs are getting very, very large. If you run a contact center today, you\u2019re going to have massive flows, and so we saw our customers creating tons and tons of projects just to handle different variations, so we added folders. I could go off this. Yeah.\n\nLast one here. Different stakeholders need different information. What we found is that the same node on a canvas might be used differently by two different people even on the same team. So the developer is gonna look at this and go, oh, great. There is the JavaScript logic I needed. I can now reference that easily into my actual code, but the designer looks at that and has no idea what\u2019s going on often. And so we added the ability to do role-based views. You have a developer view or a designer view. It\u2019s really up to you. And so this is sort of the evolving state. As these teams get larger and larger and different roles are being added, you\u2019re gonna see these tools essentially become multifaceted in how they can actually display information depending on the rule. Since a conversation is such an abstract concept, it is going to be different to every stakeholder that views it. And so you need to be able to chunk and break down that layered visibility. It\u2019s very similar too. In a design tool, you know, you might see the color red, and the developer needs to see the hex code. And so you\u2019re gonna have that ability to break down a conversation by all of its different elements as you go through. Cool. I think we can go through this. Yeah. Some problems, I think, the industry has yet to solve, you know, intent manager\u2026 intent management. We call them an\u2026 essentially, an IMS internally.\n\nSome customers have thousands of intents, tens of thousands that you\u2019re\u2026 you know, at some of these larger companies, almost having what you have for a content management system and applying that to the intent space, especially as you deal with different locals, different NLPs and NLUs, having a robust system, the industry has yet to solve that, but there are some exciting start-ups popping up. Content management. Content management, as it relates specifically to conversational assistance, there\u2019s a couple start-ups that popped up that are exciting, but this is something that\u2019s going to be increasingly important as these assistants are deployed, not just in one local, but in multiple locals, getting to the point where it\u2019s not just countries but even down to the city level. Maybe you have a restaurant in a\u2026 one city that has a very different, you know, phrase for good morning than another, we wanna have conversational assistance, meet customers where they are, and actually be able to get down to that local level. So content management\u2019s gonna be incredibly important.\n\nThen lastly, persona management. You know, certainly brands want to have one assistant that is going to be able to interact with customers across all channels, and so having a way to manage that persona in terms of its vocabulary and how it actually interacts with customers, I think you\u2019re gonna start to see a a persona management software pop up as well. So that\u2019s some exciting stuff there, but lots more in the industry to solve on the collaborative side. And that is it on my end. I wanted to essentially have a bunch of different product product shots to kinda run through some different solutions. From the conversation design tool side, hopefully, you learned a little bit about conversation design through that process. We\u2019d love to chat with a bunch of folks. If you wanna chat about conversation design practices, the talk I\u2019ve given previously on how to actually structure our team, happy to do that as well. We\u2019ve got a booth at the back in a social today at four thirty, and there will be free drinks. So\u2026 and it\u2019s a beautiful venue right on the beach. So feel free to come by. Say hi, and we\u2019ll give you a ticket for that. And with that, thanks so much.", "html": '<p><em>This is the transcript for the session \u201CSparking the Future of Conversation Design\u201D presented by Braden Ream, CEO of Voiceflow, presented on day one of Project Voice X.</em>\xA0</p>\n<p><em>The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0<strong>94% accurate.</strong>\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0<a href="https://deepgram.com/contact-us/">contact us</a>.</em></p>\n<p>[Braden Ream:] Alrighty. Hi, everyone. Thanks for having me here. So I\u2019ve given a bunch of talks on conversation design in the past, and the one I most often give is how to structure a conversation design team, so how to build one internally, build out the best practices. I thought what may be kinda fun is\u2026 you know, we learn a lot about conversation design through the practices of actually building Voiceflow. And so I thought it could be interesting to talk about the challenges of building a conversation design tool, which will, hopefully, in effect, teach you a little bit about conversation design itself. So there\u2019s gonna be a lot of product shots, talk about a lot of a a specific customer problems, you know, without naming any names, and kinda run you through the process of actually building a tool. I\u2019ll try to keep it fairly short to sync to the point. And, you know, if you wanna chat a little bit more about Voiceflow, we\u2019ve got a social later today as well as a booth at the back. Love chatting product, but I\u2019ll try to keep it fairly succinct \u2019cause I know we\u2019re going into into lunch here.</p>\n<p>So this is thoughts on building a conversation design tool. First time running this, so bear with me. Little bit a\u2026 yep. We already went through the goal here. Got ahead of myself. Little bit about Voiceflow, so we\u2019re used by over eighty thousand teams now. Lots of great customers out there, actually, lots of great customers here as well. I\u2019ve raised about twenty five million dollars from some great investors, including Amazon and Google, who are are present as well as some other awesome design tool folks, including Figma and InVision and and others. Cool. So why does conversation design matter? A lot of folks might actually not be familiar with it. You know, it\u2019s really come to prominent sites over the past two years.</p>\n<blockquote>\n<p>Conversation design is essentially the UX branch of conversational AI. So it\u2019s applying best practices on the\u2026 from the design world to conversational interfaces. Now why this is becoming increasingly relevant is as the world automates. Really, the industry that a lot of us are in is the talking to people industry. Right? It\u2019s a very large space that\u2019s quickly becoming more and more automated. And as we do this, there\u2019s a lot of focus on the underlying technologies, the ASR, the TTS, the NLUs. And now we\u2019re starting to see a lot more focus on the actual human side of it, the design side. And so that is where conversation design comes in. It is about the content structure as well as the content design itself.</p>\n</blockquote>\n<p>And so the challenge for a lot of teams today creating conversational AI is the tools, frankly, aren\u2019t there on the collaborative side. In fact, the most common tool stack we see is going to be Word docs, Excel sheets, and Visio flowcharts. Now there\u2019s lots of flowcharting softwares out there, and I\u2019ve certainly heard people say, well, we don\u2019t use Visio. We use Miro all in the same bucket. It is typically\u2026 next slide here. You\u2019re gonna see spreadsheets are used to manage the NLU design. You\u2019re gonna see, essentially, flowcharts are managed\u2026 manage the state machine. It manages the flow of the conversation. Word docs are often doing the script of the conversation, so a very lightweight, almost like a wire frame just to give people the feel. And the three of these are used in conjunction to create a conversation design. Now the problem with this is\u2026 well, two things. One, you don\u2019t have a single source of truth. And so companies often have\u2026 you know, when you\u2019ve one conversation designer, you can usually work with spreadsheets and flowcharts. That\u2019s when you have two or more or ten or, you know, a hundred in some of these larger companies now, where they\u2019re now getting to these very large teams. And when they have to communicate conversations across different teams and organizations, it might take a week just to understand the design. In fact, when I work with some customers, I\u2019ll go into a design, and we\u2019ll be chatting about it, and it might take me an hour or two just to understand the design before I can even comment on it. And so it gets really, really messy as its scales, have multiple sources of truth. And then further, you\u2019re not able to prototype.</p>\n<p>This is a big challenge for a lot of companies where if they\u2019re coming from Visio flowcharts or, again, Miro, whatever your flowcharting tool of choice is, you\u2019re not able to actually turn that into a usable prototype to run user testing. So a lot of companies will actually go straight from Word docs, Excel sheets, flowcharts, whatever it might be to a Jira ticket and then out to production. That\u2019s a super common workflow we see all the time. Sometimes WoZ testing, which is Wizard of Oz testing, is implemented, and that\u2019s essentially acting as though you are the assistant. So we hear companies where, you know, they\u2019ll have a human on one end the line. They\u2019ll call the other end if they\u2019re trying to simulate a call center experience, and they\u2019ll act as though they are the assistant. So that\u2019s really the low fidelity testing we have available with the existing tool stack. So this is where conversation design tools come into play like Voiceflow. So a streamline way to go from design, prototype, user testing, and then ultimately handing off to development, trying to give them artifacts that are more battle-tested because you\u2019ve actually done the prototyping, the user testing before handing it off to development as well as handing them in artifact is ultimately more readable as it\u2019s all in one place without having to dig through a spreadsheet, like, you know, a flowchart, etcetera. Some nice quotes, but I\u2019m gonna skip through these here and say conversation designs tools ultimately give you a single source of truth.\xA0And so this is the intro to a conversation design if you weren\u2019t familiar with it and sort of what it is and what conversation design tools are.</p>\n<p>I wanna spend a little bit time about talking about the role of conversation design. So I think it\u2019s fairly misunderstood what a conversation designer actually does on a daily basis. It\u2019s essentially a mix of a few different a few different roles. So it\u2019s going to be traditional UX. Most conversation designers actually come from a traditional UX background. It\u2019s probably the most common one we see. We also see copywriting as a as a fairly common background, and then you have the NLU model. When you actually look at these in terms of structure, you really have conversation designs sitting on top of the NLU model. It sort of stands on on its shoulders there, and these three practices together create what we talk\u2026 call the conversation designer. And then you\u2019re now starting to see, as these teams are getting larger, they\u2019re getting more sophisticated. The role of the conversation designer is actually starting to split within companies. You\u2019re starting to see AI trainers become a more common role, starting to see copywriters with a\u2026 you know, just very specific copyright and title, and the conversation designers really sort of the flow architect. And so you\u2019re starting to see increased specialization on the UX side of these conversational AI teams. Cool.</p>\n<p>So when we look at, you know, a conversation design\u2026 so here\u2019s just a a sample when I pulled in from Voiceflow. You might have four different rules all working within this one design. You\u2019re gonna have the copywriter who is focused primarily on the responses that the assistant is going to give. They\u2019re going to be responsible for the persona often as well. From there, you\u2019re going to have the NLU designer. They\u2019re working with the different intents to make sure the utterances aren\u2019t conflicting, the model\u2019s actually working, and it\u2019s gonna provide the best design experience. From there, the UX designer\u2019s often responsible for the entire flow. What is the flow of the conversation? What intents are we handling, and how do they structure into each other? So that\u2019s really sort of the role. They\u2019re almost like the the flow architect almost. And then lastly is the UI designer. A lot of experiences are becoming multimodal. Voice is not\u2026 and I think, as the\xA0 previous presentation went over, voice is not the be-all, end-all interfaces one of many, and it\u2019s incredibly good input, but it\u2019s not very good at output. You know? If you\u2019re choosing a Netflix movie, you would certainly would not want to have to be read the thirty different options before you make a choice. It\u2019s gonna be crazy cognitive overload, but we\u2019ve all sat there trying to use the the keyboard on the remote to try to pick a Netflix movie. And if you know what you want, it\u2019s an amazing input interface. So you\u2019re starting to see the rise of multimodal as well as these visual designers are being added to the conversation design teams. So one, you know, thing that, I I think, a lot of folks misunderstand about even voice or other conversations design tools is that we\u2019re not content experts.</p>\n<p>You know, a lot of folks who come from linguistics backgrounds, they might understand, you know, Grice\u2019s Maxim is thrown around quite a bit coming from sociolinguistics. These are sort of the folks who are the best at creating the ideal responses. That\u2019s not asset at Voiceflow. We actually view ourselves as giving you the tools to create the best responses. But as far as we\u2019re concerned, we\u2019re thinking about structure. We\u2019re thinking about collaboration and the workflow. That\u2019s really where we spend most of our time thinking in terms of what is actually said to the user. You know, we\u2019re average average Joes when it comes to the actual content. And so what do I mean by content? Well, that\u2019s going to be what\u2019s actually said. We focus on the content structure. We focus on how can designers visualize the structure of the conversation. How can they actually put this together in a readable, and how can they ultimately collaborate? That\u2019s really where we spend most of our time thinking. So some examples, on the far top top left there, you\u2019ll see, like, a normal response. What the designer actually puts in there\u2026 I\u2019m not a very good copywriter myself. You know, that\u2019s that\u2019s not our forte, but what we\u2019re thinking about is\u2026 k. How can we add response variance? How can we do localization, text markup, speech SSML? How can we allow for all these different structures to be applied to the content more so than what is actually said inside the content itself?</p>\n<p>So if you work at Voiceflow, probably, the number one thing you hear preached constantly is conversation design documentation. It is the number one thing we think about. And the reason for that is, ultimately, the art of conversation design is the art of conversation documentation. You know what you wanna say as a conversation designer, and if you\u2019re a team of one, that\u2019s where you\u2019re able to put this into a\u2026 any kind of artifact you\u2019d like, and how it\u2019s actually presented is not that important. When you start to work in larger teams, it\u2019s all about how you present it in a readable format so that other people can actually use it. So conversation design is the art of conversation documentation. And in order for a conversation design to be useful, it must be easily readable, and I think we\u2019ve all seen flowcharts that look like this. This is\u2026 you know, oh, it\u2019s a little blurry on the screen there, but you can kinda get the point. It is a crazy mess of nodes, and this is how a lot of internal design artifacts look at large enterprises as well as smaller teams. Frankly, there\u2019s not much thought put into the actual design structure, and often what you\u2019ll see is folks come in, and they\u2019re unable to read it, and then they will often opt to completely redo it themselves. You just create a ton of redundancy.</p>\n<p>And so the best practice here is often to start out. Create a prototype. It might look really messy and spend a lot of time actually refactoring the designed to be highly readable so that other people can collaborate on it with you. So I wanted to spend some time going through essentially customers\u2019 stories that is all along this theme of documentation, so some things that we\u2019ve had to think about as a conversation design tool that you might not think about being a conversation designer. This was a big one. So when we were working with a large automaker, they were switching over their documentation base from Visio to Voiceflow, and we had a lot of seasoned VUI designers, voice user interface designers, sort of a branch within conversation design. Say they\u2026 you know, they\u2019ve been working in Visio for twenty years now, and they\u2019ve always done top to bottom, and therefore for Voiceflow is incompatible and will never work. This is something we hadn\u2019t thought about. Voiceflow was always a left to right structure. That\u2019s just\u2026 you know? In the early days of the company, it was just something we did. It was left to right. That was it. We didn\u2019t really think much about it.</p>\n<p>As the company evolved and now we work with customers that use all different orientations, you actually need to be able to mold the tool to mesh to people\u2019s existing documentation systems so that when they\u2019re going from reading a Visio chart to a Voiceflow chart, it\u2019s going to look comparable, and they\u2019re gonna be able to understand the lay of land instantly. So problem was not being able to go to left to right. Solution was fairly simple, being able to go vertical. Another problem we had was conversation designs aren\u2019t just about the functional nodes on the canvas. It\u2019s not just about the lines. It\u2019s also about the surrounding contacts. There are sticky notes. There are little notes that designers jot down. There are comments. A lot of this wasn\u2019t present in Voiceflow. We just had the functional nodes. We thought, well, if you can build it, that\u2019s good enough. There\u2019s not\u2026 you know? No need to add any sort of additional context. And what we found is design teams were going from Visio to Voiceflow to prototype, and then back to back to Visio to document. So then they would they would document their findings from Voice\u2019s prototypes, and Voiceflow was just used as a prototyping system. So we ask why that was, and it was because they couldn\u2019t add sticky notes. It was the simplest thing, but we just hadn\u2019t thought about it as\u2026 and as a conversation design tool, we learned that the surrounding context is as important as the content itself. And so we added sticky notes, labels, images, all these things that allow your canvas to be high fidelity and flushed with context. Response variations take too much space. You don\u2019t wanna hear the same thing from your system over and over and over again, and so response variations are a big thing in conversation design. Having five, six, you know, seven responses, or more to say the same thing just to keep the experience fresh. And so in Voiceflow, we had this feature. We thought this was great, and we allowed you to stack them all like this. Well, some companies might have a hundred, and they might have a\u2026 you know, two dozen. And it started to completely clutter the canvas, and so companies were again going back to spreadsheets to put all the response variations and then linking to Voiceflow and saying, you know, this should\u2026 is what the variant should have.</p>\n<p>And so we saw this, and we added the ability to choose your different visibilities, \u2019cause, again, it\u2019s all about being able to either\u2026 essentially, layer your visibility. Are you gonna share everything, or are you just gonna share what\u2019s needed to be seen by that particular individual? So we have\u2026 often see this a lot with even executive stakeholders. When they come and look at a conversation design, the designer will change the visibility to be just the bare essentials of the conversation. Anything more and the executives, you know, go asking about, you know, variation fifteen, what\u2019s going on there? It\u2019s way too much. You just wanna share just the bare minimum to understand the conversation flow. But then when you\u2019re sharing with maybe a developer, you wanna be able to show all those different variations to really give the give the scope. So selective visibility has been\u2026 become incredibly important. Customers were adding a ton of designs to make the prototype work. This is a really curious one. So we were chatting with a bunch of customers and they were adding a ton of work to the designs, only to make the prototype work, and so the best example of this was personas. They wanted you test out. What happens if we have a a user who\u2019s logged in versus logged out? So what they would do is they would actually add inside the design a whole bunch of logic and variables and things to actually create these different personas that would then be used inside the prototype. Now the problem here is by doing this, the\u2026 this\u2026 developers, when they saw the design, weren\u2019t sure is this part of the design, or is this part just\u2026 to make the prototype work?</p>\n<p>And so this has become a super common problem, especially with the enterprise where they testing, you know, two personas, five personas when they\u2019re doing user testing, and so we added the ability to test different personas. And so you start seeing a thing where it\u2019s very customer led and that conversation design is such a new field. The UX side has been around on the IVR side for about twenty years, but in terms of the UX, sort of, adopting what\u2019s the modern UI practices to conversation design now, that\u2019s only really come in the past two years. And so we\u2019re essentially building a new category of tooling, and we\u2019re learning all this stuff as we go. Few more here. Customers were creating multiple projects for the same assistant. Designs are getting very, very large. If you run a contact center today, you\u2019re going to have massive flows, and so we saw our customers creating tons and tons of projects just to handle different variations, so we added folders. I could go off this. Yeah.</p>\n<p>Last one here. Different stakeholders need different information. What we found is that the same node on a canvas might be used differently by two different people even on the same team. So the developer is gonna look at this and go, oh, great. There is the JavaScript logic I needed. I can now reference that easily into my actual code, but the designer looks at that and has no idea what\u2019s going on often. And so we added the ability to do role-based views. You have a developer view or a designer view. It\u2019s really up to you. And so this is sort of the evolving state. As these teams get larger and larger and different roles are being added, you\u2019re gonna see these tools essentially become multifaceted in how they can actually display information depending on the rule. Since a conversation is such an abstract concept, it is going to be different to every stakeholder that views it. And so you need to be able to chunk and break down that layered visibility. It\u2019s very similar too. In a design tool, you know, you might see the color red, and the developer needs to see the hex code. And so you\u2019re gonna have that ability to break down a conversation by all of its different elements as you go through. Cool. I think we can go through this. Yeah. Some problems, I think, the industry has yet to solve, you know, intent manager\u2026 intent management. We call them an\u2026 essentially, an IMS internally.</p>\n<p>Some customers have thousands of intents, tens of thousands that you\u2019re\u2026 you know, at some of these larger companies, almost having what you have for a content management system and applying that to the intent space, especially as you deal with different locals, different NLPs and NLUs, having a robust system, the industry has yet to solve that, but there are some exciting start-ups popping up. Content management. Content management, as it relates specifically to conversational assistance, there\u2019s a couple start-ups that popped up that are exciting, but this is something that\u2019s going to be increasingly important as these assistants are deployed, not just in one local, but in multiple locals, getting to the point where it\u2019s not just countries but even down to the city level. Maybe you have a restaurant in a\u2026 one city that has a very different, you know, phrase for good morning than another, we wanna have conversational assistance, meet customers where they are, and actually be able to get down to that local level. So content management\u2019s gonna be incredibly important.</p>\n<p>Then lastly, persona management. You know, certainly brands want to have one assistant that is going to be able to interact with customers across all channels, and so having a way to manage that persona in terms of its vocabulary and how it actually interacts with customers, I think you\u2019re gonna start to see a a persona management software pop up as well. So that\u2019s some exciting stuff there, but lots more in the industry to solve on the collaborative side. And that is it on my end. I wanted to essentially have a bunch of different product product shots to kinda run through some different solutions. From the conversation design tool side, hopefully, you learned a little bit about conversation design through that process. We\u2019d love to chat with a bunch of folks. If you wanna chat about conversation design practices, the talk I\u2019ve given previously on how to actually structure our team, happy to do that as well. We\u2019ve got a booth at the back in a social today at four thirty, and there will be free drinks. So\u2026 and it\u2019s a beautiful venue right on the beach. So feel free to come by. Say hi, and we\u2019ll give you a ticket for that. And with that, thanks so much.</p>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/sparking-the-future-of-conversation-design-braden-ream-ceo-voiceflow-project-voice-x/index.md" };
function rawContent() {
  return "*This is the transcript for the session \u201CSparking the Future of Conversation Design\u201D presented by Braden Ream, CEO of Voiceflow, presented on day one of Project Voice X.*\xA0\n\n*The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0**94% accurate.**\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0[contact us](https://deepgram.com/contact-us/).*\n\n\\[Braden Ream:] Alrighty. Hi, everyone. Thanks for having me here. So I\u2019ve given a bunch of talks on conversation design in the past, and the one I most often give is how to structure a conversation design team, so how to build one internally, build out the best practices. I thought what may be kinda fun is\u2026 you know, we learn a lot about conversation design through the practices of actually building Voiceflow. And so I thought it could be interesting to talk about the challenges of building a conversation design tool, which will, hopefully, in effect, teach you a little bit about conversation design itself. So there\u2019s gonna be a lot of product shots, talk about a lot of a a specific customer problems, you know, without naming any names, and kinda run you through the process of actually building a tool. I\u2019ll try to keep it fairly short to sync to the point. And, you know, if you wanna chat a little bit more about Voiceflow, we\u2019ve got a social later today as well as a booth at the back. Love chatting product, but I\u2019ll try to keep it fairly succinct \u2019cause I know we\u2019re going into into lunch here.\n\nSo this is thoughts on building a conversation design tool. First time running this, so bear with me. Little bit a\u2026 yep. We already went through the goal here. Got ahead of myself. Little bit about Voiceflow, so we\u2019re used by over eighty thousand teams now. Lots of great customers out there, actually, lots of great customers here as well. I\u2019ve raised about twenty five million dollars from some great investors, including Amazon and Google, who are are present as well as some other awesome design tool folks, including Figma and InVision and and others. Cool. So why does conversation design matter? A lot of folks might actually not be familiar with it. You know, it\u2019s really come to prominent sites over the past two years.\n\n> Conversation design is essentially the UX branch of conversational AI. So it\u2019s applying best practices on the\u2026 from the design world to conversational interfaces. Now why this is becoming increasingly relevant is as the world automates. Really, the industry that a lot of us are in is the talking to people industry. Right? It\u2019s a very large space that\u2019s quickly becoming more and more automated. And as we do this, there\u2019s a lot of focus on the underlying technologies, the ASR, the TTS, the NLUs. And now we\u2019re starting to see a lot more focus on the actual human side of it, the design side. And so that is where conversation design comes in. It is about the content structure as well as the content design itself.\n\nAnd so the challenge for a lot of teams today creating conversational AI is the tools, frankly, aren\u2019t there on the collaborative side. In fact, the most common tool stack we see is going to be Word docs, Excel sheets, and Visio flowcharts. Now there\u2019s lots of flowcharting softwares out there, and I\u2019ve certainly heard people say, well, we don\u2019t use Visio. We use Miro all in the same bucket. It is typically\u2026 next slide here. You\u2019re gonna see spreadsheets are used to manage the NLU design. You\u2019re gonna see, essentially, flowcharts are managed\u2026 manage the state machine. It manages the flow of the conversation. Word docs are often doing the script of the conversation, so a very lightweight, almost like a wire frame just to give people the feel. And the three of these are used in conjunction to create a conversation design. Now the problem with this is\u2026 well, two things. One, you don\u2019t have a single source of truth. And so companies often have\u2026 you know, when you\u2019ve one conversation designer, you can usually work with spreadsheets and flowcharts. That\u2019s when you have two or more or ten or, you know, a hundred in some of these larger companies now, where they\u2019re now getting to these very large teams. And when they have to communicate conversations across different teams and organizations, it might take a week just to understand the design. In fact, when I work with some customers, I\u2019ll go into a design, and we\u2019ll be chatting about it, and it might take me an hour or two just to understand the design before I can even comment on it. And so it gets really, really messy as its scales, have multiple sources of truth. And then further, you\u2019re not able to prototype.\n\nThis is a big challenge for a lot of companies where if they\u2019re coming from Visio flowcharts or, again, Miro, whatever your flowcharting tool of choice is, you\u2019re not able to actually turn that into a usable prototype to run user testing. So a lot of companies will actually go straight from Word docs, Excel sheets, flowcharts, whatever it might be to a Jira ticket and then out to production. That\u2019s a super common workflow we see all the time. Sometimes WoZ testing, which is Wizard of Oz testing, is implemented, and that\u2019s essentially acting as though you are the assistant. So we hear companies where, you know, they\u2019ll have a human on one end the line. They\u2019ll call the other end if they\u2019re trying to simulate a call center experience, and they\u2019ll act as though they are the assistant. So that\u2019s really the low fidelity testing we have available with the existing tool stack. So this is where conversation design tools come into play like Voiceflow. So a streamline way to go from design, prototype, user testing, and then ultimately handing off to development, trying to give them artifacts that are more battle-tested because you\u2019ve actually done the prototyping, the user testing before handing it off to development as well as handing them in artifact is ultimately more readable as it\u2019s all in one place without having to dig through a spreadsheet, like, you know, a flowchart, etcetera. Some nice quotes, but I\u2019m gonna skip through these here and say conversation designs tools ultimately give you a single source of truth.\xA0And so this is the intro to a conversation design if you weren\u2019t familiar with it and sort of what it is and what conversation design tools are.\n\nI wanna spend a little bit time about talking about the role of conversation design. So I think it\u2019s fairly misunderstood what a conversation designer actually does on a daily basis. It\u2019s essentially a mix of a few different a few different roles. So it\u2019s going to be traditional UX. Most conversation designers actually come from a traditional UX background. It\u2019s probably the most common one we see. We also see copywriting as a as a fairly common background, and then you have the NLU model. When you actually look at these in terms of structure, you really have conversation designs sitting on top of the NLU model. It sort of stands on on its shoulders there, and these three practices together create what we talk\u2026 call the conversation designer. And then you\u2019re now starting to see, as these teams are getting larger, they\u2019re getting more sophisticated. The role of the conversation designer is actually starting to split within companies. You\u2019re starting to see AI trainers become a more common role, starting to see copywriters with a\u2026 you know, just very specific copyright and title, and the conversation designers really sort of the flow architect. And so you\u2019re starting to see increased specialization on the UX side of these conversational AI teams. Cool.\n\nSo when we look at, you know, a conversation design\u2026 so here\u2019s just a a sample when I pulled in from Voiceflow. You might have four different rules all working within this one design. You\u2019re gonna have the copywriter who is focused primarily on the responses that the assistant is going to give. They\u2019re going to be responsible for the persona often as well. From there, you\u2019re going to have the NLU designer. They\u2019re working with the different intents to make sure the utterances aren\u2019t conflicting, the model\u2019s actually working, and it\u2019s gonna provide the best design experience. From there, the UX designer\u2019s often responsible for the entire flow. What is the flow of the conversation? What intents are we handling, and how do they structure into each other? So that\u2019s really sort of the role. They\u2019re almost like the the flow architect almost. And then lastly is the UI designer. A lot of experiences are becoming multimodal. Voice is not\u2026 and I think, as the\xA0 previous presentation went over, voice is not the be-all, end-all interfaces one of many, and it\u2019s incredibly good input, but it\u2019s not very good at output. You know? If you\u2019re choosing a Netflix movie, you would certainly would not want to have to be read the thirty different options before you make a choice. It\u2019s gonna be crazy cognitive overload, but we\u2019ve all sat there trying to use the the keyboard on the remote to try to pick a Netflix movie. And if you know what you want, it\u2019s an amazing input interface. So you\u2019re starting to see the rise of multimodal as well as these visual designers are being added to the conversation design teams. So one, you know, thing that, I I think, a lot of folks misunderstand about even voice or other conversations design tools is that we\u2019re not content experts.\n\nYou know, a lot of folks who come from linguistics backgrounds, they might understand, you know, Grice\u2019s Maxim is thrown around quite a bit coming from sociolinguistics. These are sort of the folks who are the best at creating the ideal responses. That\u2019s not asset at Voiceflow. We actually view ourselves as giving you the tools to create the best responses. But as far as we\u2019re concerned, we\u2019re thinking about structure. We\u2019re thinking about collaboration and the workflow. That\u2019s really where we spend most of our time thinking in terms of what is actually said to the user. You know, we\u2019re average average Joes when it comes to the actual content. And so what do I mean by content? Well, that\u2019s going to be what\u2019s actually said. We focus on the content structure. We focus on how can designers visualize the structure of the conversation. How can they actually put this together in a readable, and how can they ultimately collaborate? That\u2019s really where we spend most of our time thinking. So some examples, on the far top top left there, you\u2019ll see, like, a normal response. What the designer actually puts in there\u2026 I\u2019m not a very good copywriter myself. You know, that\u2019s that\u2019s not our forte, but what we\u2019re thinking about is\u2026 k. How can we add response variance? How can we do localization, text markup, speech SSML? How can we allow for all these different structures to be applied to the content more so than what is actually said inside the content itself?\n\nSo if you work at Voiceflow, probably, the number one thing you hear preached constantly is conversation design documentation. It is the number one thing we think about. And the reason for that is, ultimately, the art of conversation design is the art of conversation documentation. You know what you wanna say as a conversation designer, and if you\u2019re a team of one, that\u2019s where you\u2019re able to put this into a\u2026 any kind of artifact you\u2019d like, and how it\u2019s actually presented is not that important. When you start to work in larger teams, it\u2019s all about how you present it in a readable format so that other people can actually use it. So conversation design is the art of conversation documentation. And in order for a conversation design to be useful, it must be easily readable, and I think we\u2019ve all seen flowcharts that look like this. This is\u2026 you know, oh, it\u2019s a little blurry on the screen there, but you can kinda get the point. It is a crazy mess of nodes, and this is how a lot of internal design artifacts look at large enterprises as well as smaller teams. Frankly, there\u2019s not much thought put into the actual design structure, and often what you\u2019ll see is folks come in, and they\u2019re unable to read it, and then they will often opt to completely redo it themselves. You just create a ton of redundancy.\n\nAnd so the best practice here is often to start out. Create a prototype. It might look really messy and spend a lot of time actually refactoring the designed to be highly readable so that other people can collaborate on it with you. So I wanted to spend some time going through essentially customers\u2019 stories that is all along this theme of documentation, so some things that we\u2019ve had to think about as a conversation design tool that you might not think about being a conversation designer. This was a big one. So when we were working with a large automaker, they were switching over their documentation base from Visio to Voiceflow, and we had a lot of seasoned VUI designers, voice user interface designers, sort of a branch within conversation design. Say they\u2026 you know, they\u2019ve been working in Visio for twenty years now, and they\u2019ve always done top to bottom, and therefore for Voiceflow is incompatible and will never work. This is something we hadn\u2019t thought about. Voiceflow was always a left to right structure. That\u2019s just\u2026 you know? In the early days of the company, it was just something we did. It was left to right. That was it. We didn\u2019t really think much about it.\n\nAs the company evolved and now we work with customers that use all different orientations, you actually need to be able to mold the tool to mesh to people\u2019s existing documentation systems so that when they\u2019re going from reading a Visio chart to a Voiceflow chart, it\u2019s going to look comparable, and they\u2019re gonna be able to understand the lay of land instantly. So problem was not being able to go to left to right. Solution was fairly simple, being able to go vertical. Another problem we had was conversation designs aren\u2019t just about the functional nodes on the canvas. It\u2019s not just about the lines. It\u2019s also about the surrounding contacts. There are sticky notes. There are little notes that designers jot down. There are comments. A lot of this wasn\u2019t present in Voiceflow. We just had the functional nodes. We thought, well, if you can build it, that\u2019s good enough. There\u2019s not\u2026 you know? No need to add any sort of additional context. And what we found is design teams were going from Visio to Voiceflow to prototype, and then back to back to Visio to document. So then they would they would document their findings from Voice\u2019s prototypes, and Voiceflow was just used as a prototyping system. So we ask why that was, and it was because they couldn\u2019t add sticky notes. It was the simplest thing, but we just hadn\u2019t thought about it as\u2026 and as a conversation design tool, we learned that the surrounding context is as important as the content itself. And so we added sticky notes, labels, images, all these things that allow your canvas to be high fidelity and flushed with context. Response variations take too much space. You don\u2019t wanna hear the same thing from your system over and over and over again, and so response variations are a big thing in conversation design. Having five, six, you know, seven responses, or more to say the same thing just to keep the experience fresh. And so in Voiceflow, we had this feature. We thought this was great, and we allowed you to stack them all like this. Well, some companies might have a hundred, and they might have a\u2026 you know, two dozen. And it started to completely clutter the canvas, and so companies were again going back to spreadsheets to put all the response variations and then linking to Voiceflow and saying, you know, this should\u2026 is what the variant should have.\n\nAnd so we saw this, and we added the ability to choose your different visibilities, \u2019cause, again, it\u2019s all about being able to either\u2026 essentially, layer your visibility. Are you gonna share everything, or are you just gonna share what\u2019s needed to be seen by that particular individual? So we have\u2026 often see this a lot with even executive stakeholders. When they come and look at a conversation design, the designer will change the visibility to be just the bare essentials of the conversation. Anything more and the executives, you know, go asking about, you know, variation fifteen, what\u2019s going on there? It\u2019s way too much. You just wanna share just the bare minimum to understand the conversation flow. But then when you\u2019re sharing with maybe a developer, you wanna be able to show all those different variations to really give the give the scope. So selective visibility has been\u2026 become incredibly important. Customers were adding a ton of designs to make the prototype work. This is a really curious one. So we were chatting with a bunch of customers and they were adding a ton of work to the designs, only to make the prototype work, and so the best example of this was personas. They wanted you test out. What happens if we have a a user who\u2019s logged in versus logged out? So what they would do is they would actually add inside the design a whole bunch of logic and variables and things to actually create these different personas that would then be used inside the prototype. Now the problem here is by doing this, the\u2026 this\u2026 developers, when they saw the design, weren\u2019t sure is this part of the design, or is this part just\u2026 to make the prototype work?\n\nAnd so this has become a super common problem, especially with the enterprise where they testing, you know, two personas, five personas when they\u2019re doing user testing, and so we added the ability to test different personas. And so you start seeing a thing where it\u2019s very customer led and that conversation design is such a new field. The UX side has been around on the IVR side for about twenty years, but in terms of the UX, sort of, adopting what\u2019s the modern UI practices to conversation design now, that\u2019s only really come in the past two years. And so we\u2019re essentially building a new category of tooling, and we\u2019re learning all this stuff as we go. Few more here. Customers were creating multiple projects for the same assistant. Designs are getting very, very large. If you run a contact center today, you\u2019re going to have massive flows, and so we saw our customers creating tons and tons of projects just to handle different variations, so we added folders. I could go off this. Yeah.\n\nLast one here. Different stakeholders need different information. What we found is that the same node on a canvas might be used differently by two different people even on the same team. So the developer is gonna look at this and go, oh, great. There is the JavaScript logic I needed. I can now reference that easily into my actual code, but the designer looks at that and has no idea what\u2019s going on often. And so we added the ability to do role-based views. You have a developer view or a designer view. It\u2019s really up to you. And so this is sort of the evolving state. As these teams get larger and larger and different roles are being added, you\u2019re gonna see these tools essentially become multifaceted in how they can actually display information depending on the rule. Since a conversation is such an abstract concept, it is going to be different to every stakeholder that views it. And so you need to be able to chunk and break down that layered visibility. It\u2019s very similar too. In a design tool, you know, you might see the color red, and the developer needs to see the hex code. And so you\u2019re gonna have that ability to break down a conversation by all of its different elements as you go through. Cool. I think we can go through this. Yeah. Some problems, I think, the industry has yet to solve, you know, intent manager\u2026 intent management. We call them an\u2026 essentially, an IMS internally.\n\nSome customers have thousands of intents, tens of thousands that you\u2019re\u2026 you know, at some of these larger companies, almost having what you have for a content management system and applying that to the intent space, especially as you deal with different locals, different NLPs and NLUs, having a robust system, the industry has yet to solve that, but there are some exciting start-ups popping up. Content management. Content management, as it relates specifically to conversational assistance, there\u2019s a couple start-ups that popped up that are exciting, but this is something that\u2019s going to be increasingly important as these assistants are deployed, not just in one local, but in multiple locals, getting to the point where it\u2019s not just countries but even down to the city level. Maybe you have a restaurant in a\u2026 one city that has a very different, you know, phrase for good morning than another, we wanna have conversational assistance, meet customers where they are, and actually be able to get down to that local level. So content management\u2019s gonna be incredibly important.\n\nThen lastly, persona management. You know, certainly brands want to have one assistant that is going to be able to interact with customers across all channels, and so having a way to manage that persona in terms of its vocabulary and how it actually interacts with customers, I think you\u2019re gonna start to see a a persona management software pop up as well. So that\u2019s some exciting stuff there, but lots more in the industry to solve on the collaborative side. And that is it on my end. I wanted to essentially have a bunch of different product product shots to kinda run through some different solutions. From the conversation design tool side, hopefully, you learned a little bit about conversation design through that process. We\u2019d love to chat with a bunch of folks. If you wanna chat about conversation design practices, the talk I\u2019ve given previously on how to actually structure our team, happy to do that as well. We\u2019ve got a booth at the back in a social today at four thirty, and there will be free drinks. So\u2026 and it\u2019s a beautiful venue right on the beach. So feel free to come by. Say hi, and we\u2019ll give you a ticket for that. And with that, thanks so much.";
}
function compiledContent() {
  return '<p><em>This is the transcript for the session \u201CSparking the Future of Conversation Design\u201D presented by Braden Ream, CEO of Voiceflow, presented on day one of Project Voice X.</em>\xA0</p>\n<p><em>The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was\xA0<strong>94% accurate.</strong>\xA0 Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgram\u2019s API.\xA0 If you want to see if Deepgram is right for your use case,\xA0<a href="https://deepgram.com/contact-us/">contact us</a>.</em></p>\n<p>[Braden Ream:] Alrighty. Hi, everyone. Thanks for having me here. So I\u2019ve given a bunch of talks on conversation design in the past, and the one I most often give is how to structure a conversation design team, so how to build one internally, build out the best practices. I thought what may be kinda fun is\u2026 you know, we learn a lot about conversation design through the practices of actually building Voiceflow. And so I thought it could be interesting to talk about the challenges of building a conversation design tool, which will, hopefully, in effect, teach you a little bit about conversation design itself. So there\u2019s gonna be a lot of product shots, talk about a lot of a a specific customer problems, you know, without naming any names, and kinda run you through the process of actually building a tool. I\u2019ll try to keep it fairly short to sync to the point. And, you know, if you wanna chat a little bit more about Voiceflow, we\u2019ve got a social later today as well as a booth at the back. Love chatting product, but I\u2019ll try to keep it fairly succinct \u2019cause I know we\u2019re going into into lunch here.</p>\n<p>So this is thoughts on building a conversation design tool. First time running this, so bear with me. Little bit a\u2026 yep. We already went through the goal here. Got ahead of myself. Little bit about Voiceflow, so we\u2019re used by over eighty thousand teams now. Lots of great customers out there, actually, lots of great customers here as well. I\u2019ve raised about twenty five million dollars from some great investors, including Amazon and Google, who are are present as well as some other awesome design tool folks, including Figma and InVision and and others. Cool. So why does conversation design matter? A lot of folks might actually not be familiar with it. You know, it\u2019s really come to prominent sites over the past two years.</p>\n<blockquote>\n<p>Conversation design is essentially the UX branch of conversational AI. So it\u2019s applying best practices on the\u2026 from the design world to conversational interfaces. Now why this is becoming increasingly relevant is as the world automates. Really, the industry that a lot of us are in is the talking to people industry. Right? It\u2019s a very large space that\u2019s quickly becoming more and more automated. And as we do this, there\u2019s a lot of focus on the underlying technologies, the ASR, the TTS, the NLUs. And now we\u2019re starting to see a lot more focus on the actual human side of it, the design side. And so that is where conversation design comes in. It is about the content structure as well as the content design itself.</p>\n</blockquote>\n<p>And so the challenge for a lot of teams today creating conversational AI is the tools, frankly, aren\u2019t there on the collaborative side. In fact, the most common tool stack we see is going to be Word docs, Excel sheets, and Visio flowcharts. Now there\u2019s lots of flowcharting softwares out there, and I\u2019ve certainly heard people say, well, we don\u2019t use Visio. We use Miro all in the same bucket. It is typically\u2026 next slide here. You\u2019re gonna see spreadsheets are used to manage the NLU design. You\u2019re gonna see, essentially, flowcharts are managed\u2026 manage the state machine. It manages the flow of the conversation. Word docs are often doing the script of the conversation, so a very lightweight, almost like a wire frame just to give people the feel. And the three of these are used in conjunction to create a conversation design. Now the problem with this is\u2026 well, two things. One, you don\u2019t have a single source of truth. And so companies often have\u2026 you know, when you\u2019ve one conversation designer, you can usually work with spreadsheets and flowcharts. That\u2019s when you have two or more or ten or, you know, a hundred in some of these larger companies now, where they\u2019re now getting to these very large teams. And when they have to communicate conversations across different teams and organizations, it might take a week just to understand the design. In fact, when I work with some customers, I\u2019ll go into a design, and we\u2019ll be chatting about it, and it might take me an hour or two just to understand the design before I can even comment on it. And so it gets really, really messy as its scales, have multiple sources of truth. And then further, you\u2019re not able to prototype.</p>\n<p>This is a big challenge for a lot of companies where if they\u2019re coming from Visio flowcharts or, again, Miro, whatever your flowcharting tool of choice is, you\u2019re not able to actually turn that into a usable prototype to run user testing. So a lot of companies will actually go straight from Word docs, Excel sheets, flowcharts, whatever it might be to a Jira ticket and then out to production. That\u2019s a super common workflow we see all the time. Sometimes WoZ testing, which is Wizard of Oz testing, is implemented, and that\u2019s essentially acting as though you are the assistant. So we hear companies where, you know, they\u2019ll have a human on one end the line. They\u2019ll call the other end if they\u2019re trying to simulate a call center experience, and they\u2019ll act as though they are the assistant. So that\u2019s really the low fidelity testing we have available with the existing tool stack. So this is where conversation design tools come into play like Voiceflow. So a streamline way to go from design, prototype, user testing, and then ultimately handing off to development, trying to give them artifacts that are more battle-tested because you\u2019ve actually done the prototyping, the user testing before handing it off to development as well as handing them in artifact is ultimately more readable as it\u2019s all in one place without having to dig through a spreadsheet, like, you know, a flowchart, etcetera. Some nice quotes, but I\u2019m gonna skip through these here and say conversation designs tools ultimately give you a single source of truth.\xA0And so this is the intro to a conversation design if you weren\u2019t familiar with it and sort of what it is and what conversation design tools are.</p>\n<p>I wanna spend a little bit time about talking about the role of conversation design. So I think it\u2019s fairly misunderstood what a conversation designer actually does on a daily basis. It\u2019s essentially a mix of a few different a few different roles. So it\u2019s going to be traditional UX. Most conversation designers actually come from a traditional UX background. It\u2019s probably the most common one we see. We also see copywriting as a as a fairly common background, and then you have the NLU model. When you actually look at these in terms of structure, you really have conversation designs sitting on top of the NLU model. It sort of stands on on its shoulders there, and these three practices together create what we talk\u2026 call the conversation designer. And then you\u2019re now starting to see, as these teams are getting larger, they\u2019re getting more sophisticated. The role of the conversation designer is actually starting to split within companies. You\u2019re starting to see AI trainers become a more common role, starting to see copywriters with a\u2026 you know, just very specific copyright and title, and the conversation designers really sort of the flow architect. And so you\u2019re starting to see increased specialization on the UX side of these conversational AI teams. Cool.</p>\n<p>So when we look at, you know, a conversation design\u2026 so here\u2019s just a a sample when I pulled in from Voiceflow. You might have four different rules all working within this one design. You\u2019re gonna have the copywriter who is focused primarily on the responses that the assistant is going to give. They\u2019re going to be responsible for the persona often as well. From there, you\u2019re going to have the NLU designer. They\u2019re working with the different intents to make sure the utterances aren\u2019t conflicting, the model\u2019s actually working, and it\u2019s gonna provide the best design experience. From there, the UX designer\u2019s often responsible for the entire flow. What is the flow of the conversation? What intents are we handling, and how do they structure into each other? So that\u2019s really sort of the role. They\u2019re almost like the the flow architect almost. And then lastly is the UI designer. A lot of experiences are becoming multimodal. Voice is not\u2026 and I think, as the\xA0 previous presentation went over, voice is not the be-all, end-all interfaces one of many, and it\u2019s incredibly good input, but it\u2019s not very good at output. You know? If you\u2019re choosing a Netflix movie, you would certainly would not want to have to be read the thirty different options before you make a choice. It\u2019s gonna be crazy cognitive overload, but we\u2019ve all sat there trying to use the the keyboard on the remote to try to pick a Netflix movie. And if you know what you want, it\u2019s an amazing input interface. So you\u2019re starting to see the rise of multimodal as well as these visual designers are being added to the conversation design teams. So one, you know, thing that, I I think, a lot of folks misunderstand about even voice or other conversations design tools is that we\u2019re not content experts.</p>\n<p>You know, a lot of folks who come from linguistics backgrounds, they might understand, you know, Grice\u2019s Maxim is thrown around quite a bit coming from sociolinguistics. These are sort of the folks who are the best at creating the ideal responses. That\u2019s not asset at Voiceflow. We actually view ourselves as giving you the tools to create the best responses. But as far as we\u2019re concerned, we\u2019re thinking about structure. We\u2019re thinking about collaboration and the workflow. That\u2019s really where we spend most of our time thinking in terms of what is actually said to the user. You know, we\u2019re average average Joes when it comes to the actual content. And so what do I mean by content? Well, that\u2019s going to be what\u2019s actually said. We focus on the content structure. We focus on how can designers visualize the structure of the conversation. How can they actually put this together in a readable, and how can they ultimately collaborate? That\u2019s really where we spend most of our time thinking. So some examples, on the far top top left there, you\u2019ll see, like, a normal response. What the designer actually puts in there\u2026 I\u2019m not a very good copywriter myself. You know, that\u2019s that\u2019s not our forte, but what we\u2019re thinking about is\u2026 k. How can we add response variance? How can we do localization, text markup, speech SSML? How can we allow for all these different structures to be applied to the content more so than what is actually said inside the content itself?</p>\n<p>So if you work at Voiceflow, probably, the number one thing you hear preached constantly is conversation design documentation. It is the number one thing we think about. And the reason for that is, ultimately, the art of conversation design is the art of conversation documentation. You know what you wanna say as a conversation designer, and if you\u2019re a team of one, that\u2019s where you\u2019re able to put this into a\u2026 any kind of artifact you\u2019d like, and how it\u2019s actually presented is not that important. When you start to work in larger teams, it\u2019s all about how you present it in a readable format so that other people can actually use it. So conversation design is the art of conversation documentation. And in order for a conversation design to be useful, it must be easily readable, and I think we\u2019ve all seen flowcharts that look like this. This is\u2026 you know, oh, it\u2019s a little blurry on the screen there, but you can kinda get the point. It is a crazy mess of nodes, and this is how a lot of internal design artifacts look at large enterprises as well as smaller teams. Frankly, there\u2019s not much thought put into the actual design structure, and often what you\u2019ll see is folks come in, and they\u2019re unable to read it, and then they will often opt to completely redo it themselves. You just create a ton of redundancy.</p>\n<p>And so the best practice here is often to start out. Create a prototype. It might look really messy and spend a lot of time actually refactoring the designed to be highly readable so that other people can collaborate on it with you. So I wanted to spend some time going through essentially customers\u2019 stories that is all along this theme of documentation, so some things that we\u2019ve had to think about as a conversation design tool that you might not think about being a conversation designer. This was a big one. So when we were working with a large automaker, they were switching over their documentation base from Visio to Voiceflow, and we had a lot of seasoned VUI designers, voice user interface designers, sort of a branch within conversation design. Say they\u2026 you know, they\u2019ve been working in Visio for twenty years now, and they\u2019ve always done top to bottom, and therefore for Voiceflow is incompatible and will never work. This is something we hadn\u2019t thought about. Voiceflow was always a left to right structure. That\u2019s just\u2026 you know? In the early days of the company, it was just something we did. It was left to right. That was it. We didn\u2019t really think much about it.</p>\n<p>As the company evolved and now we work with customers that use all different orientations, you actually need to be able to mold the tool to mesh to people\u2019s existing documentation systems so that when they\u2019re going from reading a Visio chart to a Voiceflow chart, it\u2019s going to look comparable, and they\u2019re gonna be able to understand the lay of land instantly. So problem was not being able to go to left to right. Solution was fairly simple, being able to go vertical. Another problem we had was conversation designs aren\u2019t just about the functional nodes on the canvas. It\u2019s not just about the lines. It\u2019s also about the surrounding contacts. There are sticky notes. There are little notes that designers jot down. There are comments. A lot of this wasn\u2019t present in Voiceflow. We just had the functional nodes. We thought, well, if you can build it, that\u2019s good enough. There\u2019s not\u2026 you know? No need to add any sort of additional context. And what we found is design teams were going from Visio to Voiceflow to prototype, and then back to back to Visio to document. So then they would they would document their findings from Voice\u2019s prototypes, and Voiceflow was just used as a prototyping system. So we ask why that was, and it was because they couldn\u2019t add sticky notes. It was the simplest thing, but we just hadn\u2019t thought about it as\u2026 and as a conversation design tool, we learned that the surrounding context is as important as the content itself. And so we added sticky notes, labels, images, all these things that allow your canvas to be high fidelity and flushed with context. Response variations take too much space. You don\u2019t wanna hear the same thing from your system over and over and over again, and so response variations are a big thing in conversation design. Having five, six, you know, seven responses, or more to say the same thing just to keep the experience fresh. And so in Voiceflow, we had this feature. We thought this was great, and we allowed you to stack them all like this. Well, some companies might have a hundred, and they might have a\u2026 you know, two dozen. And it started to completely clutter the canvas, and so companies were again going back to spreadsheets to put all the response variations and then linking to Voiceflow and saying, you know, this should\u2026 is what the variant should have.</p>\n<p>And so we saw this, and we added the ability to choose your different visibilities, \u2019cause, again, it\u2019s all about being able to either\u2026 essentially, layer your visibility. Are you gonna share everything, or are you just gonna share what\u2019s needed to be seen by that particular individual? So we have\u2026 often see this a lot with even executive stakeholders. When they come and look at a conversation design, the designer will change the visibility to be just the bare essentials of the conversation. Anything more and the executives, you know, go asking about, you know, variation fifteen, what\u2019s going on there? It\u2019s way too much. You just wanna share just the bare minimum to understand the conversation flow. But then when you\u2019re sharing with maybe a developer, you wanna be able to show all those different variations to really give the give the scope. So selective visibility has been\u2026 become incredibly important. Customers were adding a ton of designs to make the prototype work. This is a really curious one. So we were chatting with a bunch of customers and they were adding a ton of work to the designs, only to make the prototype work, and so the best example of this was personas. They wanted you test out. What happens if we have a a user who\u2019s logged in versus logged out? So what they would do is they would actually add inside the design a whole bunch of logic and variables and things to actually create these different personas that would then be used inside the prototype. Now the problem here is by doing this, the\u2026 this\u2026 developers, when they saw the design, weren\u2019t sure is this part of the design, or is this part just\u2026 to make the prototype work?</p>\n<p>And so this has become a super common problem, especially with the enterprise where they testing, you know, two personas, five personas when they\u2019re doing user testing, and so we added the ability to test different personas. And so you start seeing a thing where it\u2019s very customer led and that conversation design is such a new field. The UX side has been around on the IVR side for about twenty years, but in terms of the UX, sort of, adopting what\u2019s the modern UI practices to conversation design now, that\u2019s only really come in the past two years. And so we\u2019re essentially building a new category of tooling, and we\u2019re learning all this stuff as we go. Few more here. Customers were creating multiple projects for the same assistant. Designs are getting very, very large. If you run a contact center today, you\u2019re going to have massive flows, and so we saw our customers creating tons and tons of projects just to handle different variations, so we added folders. I could go off this. Yeah.</p>\n<p>Last one here. Different stakeholders need different information. What we found is that the same node on a canvas might be used differently by two different people even on the same team. So the developer is gonna look at this and go, oh, great. There is the JavaScript logic I needed. I can now reference that easily into my actual code, but the designer looks at that and has no idea what\u2019s going on often. And so we added the ability to do role-based views. You have a developer view or a designer view. It\u2019s really up to you. And so this is sort of the evolving state. As these teams get larger and larger and different roles are being added, you\u2019re gonna see these tools essentially become multifaceted in how they can actually display information depending on the rule. Since a conversation is such an abstract concept, it is going to be different to every stakeholder that views it. And so you need to be able to chunk and break down that layered visibility. It\u2019s very similar too. In a design tool, you know, you might see the color red, and the developer needs to see the hex code. And so you\u2019re gonna have that ability to break down a conversation by all of its different elements as you go through. Cool. I think we can go through this. Yeah. Some problems, I think, the industry has yet to solve, you know, intent manager\u2026 intent management. We call them an\u2026 essentially, an IMS internally.</p>\n<p>Some customers have thousands of intents, tens of thousands that you\u2019re\u2026 you know, at some of these larger companies, almost having what you have for a content management system and applying that to the intent space, especially as you deal with different locals, different NLPs and NLUs, having a robust system, the industry has yet to solve that, but there are some exciting start-ups popping up. Content management. Content management, as it relates specifically to conversational assistance, there\u2019s a couple start-ups that popped up that are exciting, but this is something that\u2019s going to be increasingly important as these assistants are deployed, not just in one local, but in multiple locals, getting to the point where it\u2019s not just countries but even down to the city level. Maybe you have a restaurant in a\u2026 one city that has a very different, you know, phrase for good morning than another, we wanna have conversational assistance, meet customers where they are, and actually be able to get down to that local level. So content management\u2019s gonna be incredibly important.</p>\n<p>Then lastly, persona management. You know, certainly brands want to have one assistant that is going to be able to interact with customers across all channels, and so having a way to manage that persona in terms of its vocabulary and how it actually interacts with customers, I think you\u2019re gonna start to see a a persona management software pop up as well. So that\u2019s some exciting stuff there, but lots more in the industry to solve on the collaborative side. And that is it on my end. I wanted to essentially have a bunch of different product product shots to kinda run through some different solutions. From the conversation design tool side, hopefully, you learned a little bit about conversation design through that process. We\u2019d love to chat with a bunch of folks. If you wanna chat about conversation design practices, the talk I\u2019ve given previously on how to actually structure our team, happy to do that as well. We\u2019ve got a booth at the back in a social today at four thirty, and there will be free drinks. So\u2026 and it\u2019s a beautiful venue right on the beach. So feel free to come by. Say hi, and we\u2019ll give you a ticket for that. And with that, thanks so much.</p>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/sparking-the-future-of-conversation-design-braden-ream-ceo-voiceflow-project-voice-x/index.md", "https://blog.deepgram.com/", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p><em>This is the transcript for the session Sparking the Future of Conversation Design presented by Braden Ream, CEO of Voiceflow, presented on day one of Project Voice X.</em></p>
<p><em>The transcript below has been modified by the Deepgram team for readability as a blog post, but the original Deepgram ASR-generated transcript was<strong>94% accurate.</strong> Features like diarization, custom vocabulary (keyword boosting), redaction, punctuation, profanity filtering and numeral formatting are all available through Deepgrams API. If you want to see if Deepgram is right for your use case,<a href="https://deepgram.com/contact-us/">contact us</a>.</em></p>
<p>[Braden Ream:] Alrighty. Hi, everyone. Thanks for having me here. So Ive given a bunch of talks on conversation design in the past, and the one I most often give is how to structure a conversation design team, so how to build one internally, build out the best practices. I thought what may be kinda fun is you know, we learn a lot about conversation design through the practices of actually building Voiceflow. And so I thought it could be interesting to talk about the challenges of building a conversation design tool, which will, hopefully, in effect, teach you a little bit about conversation design itself. So theres gonna be a lot of product shots, talk about a lot of a a specific customer problems, you know, without naming any names, and kinda run you through the process of actually building a tool. Ill try to keep it fairly short to sync to the point. And, you know, if you wanna chat a little bit more about Voiceflow, weve got a social later today as well as a booth at the back. Love chatting product, but Ill try to keep it fairly succinct cause I know were going into into lunch here.</p>
<p>So this is thoughts on building a conversation design tool. First time running this, so bear with me. Little bit a yep. We already went through the goal here. Got ahead of myself. Little bit about Voiceflow, so were used by over eighty thousand teams now. Lots of great customers out there, actually, lots of great customers here as well. Ive raised about twenty five million dollars from some great investors, including Amazon and Google, who are are present as well as some other awesome design tool folks, including Figma and InVision and and others. Cool. So why does conversation design matter? A lot of folks might actually not be familiar with it. You know, its really come to prominent sites over the past two years.</p>
<blockquote>
<p>Conversation design is essentially the UX branch of conversational AI. So its applying best practices on the from the design world to conversational interfaces. Now why this is becoming increasingly relevant is as the world automates. Really, the industry that a lot of us are in is the talking to people industry. Right? Its a very large space thats quickly becoming more and more automated. And as we do this, theres a lot of focus on the underlying technologies, the ASR, the TTS, the NLUs. And now were starting to see a lot more focus on the actual human side of it, the design side. And so that is where conversation design comes in. It is about the content structure as well as the content design itself.</p>
</blockquote>
<p>And so the challenge for a lot of teams today creating conversational AI is the tools, frankly, arent there on the collaborative side. In fact, the most common tool stack we see is going to be Word docs, Excel sheets, and Visio flowcharts. Now theres lots of flowcharting softwares out there, and Ive certainly heard people say, well, we dont use Visio. We use Miro all in the same bucket. It is typically next slide here. Youre gonna see spreadsheets are used to manage the NLU design. Youre gonna see, essentially, flowcharts are managed manage the state machine. It manages the flow of the conversation. Word docs are often doing the script of the conversation, so a very lightweight, almost like a wire frame just to give people the feel. And the three of these are used in conjunction to create a conversation design. Now the problem with this is well, two things. One, you dont have a single source of truth. And so companies often have you know, when youve one conversation designer, you can usually work with spreadsheets and flowcharts. Thats when you have two or more or ten or, you know, a hundred in some of these larger companies now, where theyre now getting to these very large teams. And when they have to communicate conversations across different teams and organizations, it might take a week just to understand the design. In fact, when I work with some customers, Ill go into a design, and well be chatting about it, and it might take me an hour or two just to understand the design before I can even comment on it. And so it gets really, really messy as its scales, have multiple sources of truth. And then further, youre not able to prototype.</p>
<p>This is a big challenge for a lot of companies where if theyre coming from Visio flowcharts or, again, Miro, whatever your flowcharting tool of choice is, youre not able to actually turn that into a usable prototype to run user testing. So a lot of companies will actually go straight from Word docs, Excel sheets, flowcharts, whatever it might be to a Jira ticket and then out to production. Thats a super common workflow we see all the time. Sometimes WoZ testing, which is Wizard of Oz testing, is implemented, and thats essentially acting as though you are the assistant. So we hear companies where, you know, theyll have a human on one end the line. Theyll call the other end if theyre trying to simulate a call center experience, and theyll act as though they are the assistant. So thats really the low fidelity testing we have available with the existing tool stack. So this is where conversation design tools come into play like Voiceflow. So a streamline way to go from design, prototype, user testing, and then ultimately handing off to development, trying to give them artifacts that are more battle-tested because youve actually done the prototyping, the user testing before handing it off to development as well as handing them in artifact is ultimately more readable as its all in one place without having to dig through a spreadsheet, like, you know, a flowchart, etcetera. Some nice quotes, but Im gonna skip through these here and say conversation designs tools ultimately give you a single source of truth.And so this is the intro to a conversation design if you werent familiar with it and sort of what it is and what conversation design tools are.</p>
<p>I wanna spend a little bit time about talking about the role of conversation design. So I think its fairly misunderstood what a conversation designer actually does on a daily basis. Its essentially a mix of a few different a few different roles. So its going to be traditional UX. Most conversation designers actually come from a traditional UX background. Its probably the most common one we see. We also see copywriting as a as a fairly common background, and then you have the NLU model. When you actually look at these in terms of structure, you really have conversation designs sitting on top of the NLU model. It sort of stands on on its shoulders there, and these three practices together create what we talk call the conversation designer. And then youre now starting to see, as these teams are getting larger, theyre getting more sophisticated. The role of the conversation designer is actually starting to split within companies. Youre starting to see AI trainers become a more common role, starting to see copywriters with a you know, just very specific copyright and title, and the conversation designers really sort of the flow architect. And so youre starting to see increased specialization on the UX side of these conversational AI teams. Cool.</p>
<p>So when we look at, you know, a conversation design so heres just a a sample when I pulled in from Voiceflow. You might have four different rules all working within this one design. Youre gonna have the copywriter who is focused primarily on the responses that the assistant is going to give. Theyre going to be responsible for the persona often as well. From there, youre going to have the NLU designer. Theyre working with the different intents to make sure the utterances arent conflicting, the models actually working, and its gonna provide the best design experience. From there, the UX designers often responsible for the entire flow. What is the flow of the conversation? What intents are we handling, and how do they structure into each other? So thats really sort of the role. Theyre almost like the the flow architect almost. And then lastly is the UI designer. A lot of experiences are becoming multimodal. Voice is not and I think, as the previous presentation went over, voice is not the be-all, end-all interfaces one of many, and its incredibly good input, but its not very good at output. You know? If youre choosing a Netflix movie, you would certainly would not want to have to be read the thirty different options before you make a choice. Its gonna be crazy cognitive overload, but weve all sat there trying to use the the keyboard on the remote to try to pick a Netflix movie. And if you know what you want, its an amazing input interface. So youre starting to see the rise of multimodal as well as these visual designers are being added to the conversation design teams. So one, you know, thing that, I I think, a lot of folks misunderstand about even voice or other conversations design tools is that were not content experts.</p>
<p>You know, a lot of folks who come from linguistics backgrounds, they might understand, you know, Grices Maxim is thrown around quite a bit coming from sociolinguistics. These are sort of the folks who are the best at creating the ideal responses. Thats not asset at Voiceflow. We actually view ourselves as giving you the tools to create the best responses. But as far as were concerned, were thinking about structure. Were thinking about collaboration and the workflow. Thats really where we spend most of our time thinking in terms of what is actually said to the user. You know, were average average Joes when it comes to the actual content. And so what do I mean by content? Well, thats going to be whats actually said. We focus on the content structure. We focus on how can designers visualize the structure of the conversation. How can they actually put this together in a readable, and how can they ultimately collaborate? Thats really where we spend most of our time thinking. So some examples, on the far top top left there, youll see, like, a normal response. What the designer actually puts in there Im not a very good copywriter myself. You know, thats thats not our forte, but what were thinking about is k. How can we add response variance? How can we do localization, text markup, speech SSML? How can we allow for all these different structures to be applied to the content more so than what is actually said inside the content itself?</p>
<p>So if you work at Voiceflow, probably, the number one thing you hear preached constantly is conversation design documentation. It is the number one thing we think about. And the reason for that is, ultimately, the art of conversation design is the art of conversation documentation. You know what you wanna say as a conversation designer, and if youre a team of one, thats where youre able to put this into a any kind of artifact youd like, and how its actually presented is not that important. When you start to work in larger teams, its all about how you present it in a readable format so that other people can actually use it. So conversation design is the art of conversation documentation. And in order for a conversation design to be useful, it must be easily readable, and I think weve all seen flowcharts that look like this. This is you know, oh, its a little blurry on the screen there, but you can kinda get the point. It is a crazy mess of nodes, and this is how a lot of internal design artifacts look at large enterprises as well as smaller teams. Frankly, theres not much thought put into the actual design structure, and often what youll see is folks come in, and theyre unable to read it, and then they will often opt to completely redo it themselves. You just create a ton of redundancy.</p>
<p>And so the best practice here is often to start out. Create a prototype. It might look really messy and spend a lot of time actually refactoring the designed to be highly readable so that other people can collaborate on it with you. So I wanted to spend some time going through essentially customers stories that is all along this theme of documentation, so some things that weve had to think about as a conversation design tool that you might not think about being a conversation designer. This was a big one. So when we were working with a large automaker, they were switching over their documentation base from Visio to Voiceflow, and we had a lot of seasoned VUI designers, voice user interface designers, sort of a branch within conversation design. Say they you know, theyve been working in Visio for twenty years now, and theyve always done top to bottom, and therefore for Voiceflow is incompatible and will never work. This is something we hadnt thought about. Voiceflow was always a left to right structure. Thats just you know? In the early days of the company, it was just something we did. It was left to right. That was it. We didnt really think much about it.</p>
<p>As the company evolved and now we work with customers that use all different orientations, you actually need to be able to mold the tool to mesh to peoples existing documentation systems so that when theyre going from reading a Visio chart to a Voiceflow chart, its going to look comparable, and theyre gonna be able to understand the lay of land instantly. So problem was not being able to go to left to right. Solution was fairly simple, being able to go vertical. Another problem we had was conversation designs arent just about the functional nodes on the canvas. Its not just about the lines. Its also about the surrounding contacts. There are sticky notes. There are little notes that designers jot down. There are comments. A lot of this wasnt present in Voiceflow. We just had the functional nodes. We thought, well, if you can build it, thats good enough. Theres not you know? No need to add any sort of additional context. And what we found is design teams were going from Visio to Voiceflow to prototype, and then back to back to Visio to document. So then they would they would document their findings from Voices prototypes, and Voiceflow was just used as a prototyping system. So we ask why that was, and it was because they couldnt add sticky notes. It was the simplest thing, but we just hadnt thought about it as and as a conversation design tool, we learned that the surrounding context is as important as the content itself. And so we added sticky notes, labels, images, all these things that allow your canvas to be high fidelity and flushed with context. Response variations take too much space. You dont wanna hear the same thing from your system over and over and over again, and so response variations are a big thing in conversation design. Having five, six, you know, seven responses, or more to say the same thing just to keep the experience fresh. And so in Voiceflow, we had this feature. We thought this was great, and we allowed you to stack them all like this. Well, some companies might have a hundred, and they might have a you know, two dozen. And it started to completely clutter the canvas, and so companies were again going back to spreadsheets to put all the response variations and then linking to Voiceflow and saying, you know, this should is what the variant should have.</p>
<p>And so we saw this, and we added the ability to choose your different visibilities, cause, again, its all about being able to either essentially, layer your visibility. Are you gonna share everything, or are you just gonna share whats needed to be seen by that particular individual? So we have often see this a lot with even executive stakeholders. When they come and look at a conversation design, the designer will change the visibility to be just the bare essentials of the conversation. Anything more and the executives, you know, go asking about, you know, variation fifteen, whats going on there? Its way too much. You just wanna share just the bare minimum to understand the conversation flow. But then when youre sharing with maybe a developer, you wanna be able to show all those different variations to really give the give the scope. So selective visibility has been become incredibly important. Customers were adding a ton of designs to make the prototype work. This is a really curious one. So we were chatting with a bunch of customers and they were adding a ton of work to the designs, only to make the prototype work, and so the best example of this was personas. They wanted you test out. What happens if we have a a user whos logged in versus logged out? So what they would do is they would actually add inside the design a whole bunch of logic and variables and things to actually create these different personas that would then be used inside the prototype. Now the problem here is by doing this, the this developers, when they saw the design, werent sure is this part of the design, or is this part just to make the prototype work?</p>
<p>And so this has become a super common problem, especially with the enterprise where they testing, you know, two personas, five personas when theyre doing user testing, and so we added the ability to test different personas. And so you start seeing a thing where its very customer led and that conversation design is such a new field. The UX side has been around on the IVR side for about twenty years, but in terms of the UX, sort of, adopting whats the modern UI practices to conversation design now, thats only really come in the past two years. And so were essentially building a new category of tooling, and were learning all this stuff as we go. Few more here. Customers were creating multiple projects for the same assistant. Designs are getting very, very large. If you run a contact center today, youre going to have massive flows, and so we saw our customers creating tons and tons of projects just to handle different variations, so we added folders. I could go off this. Yeah.</p>
<p>Last one here. Different stakeholders need different information. What we found is that the same node on a canvas might be used differently by two different people even on the same team. So the developer is gonna look at this and go, oh, great. There is the JavaScript logic I needed. I can now reference that easily into my actual code, but the designer looks at that and has no idea whats going on often. And so we added the ability to do role-based views. You have a developer view or a designer view. Its really up to you. And so this is sort of the evolving state. As these teams get larger and larger and different roles are being added, youre gonna see these tools essentially become multifaceted in how they can actually display information depending on the rule. Since a conversation is such an abstract concept, it is going to be different to every stakeholder that views it. And so you need to be able to chunk and break down that layered visibility. Its very similar too. In a design tool, you know, you might see the color red, and the developer needs to see the hex code. And so youre gonna have that ability to break down a conversation by all of its different elements as you go through. Cool. I think we can go through this. Yeah. Some problems, I think, the industry has yet to solve, you know, intent manager intent management. We call them an essentially, an IMS internally.</p>
<p>Some customers have thousands of intents, tens of thousands that youre you know, at some of these larger companies, almost having what you have for a content management system and applying that to the intent space, especially as you deal with different locals, different NLPs and NLUs, having a robust system, the industry has yet to solve that, but there are some exciting start-ups popping up. Content management. Content management, as it relates specifically to conversational assistance, theres a couple start-ups that popped up that are exciting, but this is something thats going to be increasingly important as these assistants are deployed, not just in one local, but in multiple locals, getting to the point where its not just countries but even down to the city level. Maybe you have a restaurant in a one city that has a very different, you know, phrase for good morning than another, we wanna have conversational assistance, meet customers where they are, and actually be able to get down to that local level. So content managements gonna be incredibly important.</p>
<p>Then lastly, persona management. You know, certainly brands want to have one assistant that is going to be able to interact with customers across all channels, and so having a way to manage that persona in terms of its vocabulary and how it actually interacts with customers, I think youre gonna start to see a a persona management software pop up as well. So thats some exciting stuff there, but lots more in the industry to solve on the collaborative side. And that is it on my end. I wanted to essentially have a bunch of different product product shots to kinda run through some different solutions. From the conversation design tool side, hopefully, you learned a little bit about conversation design through that process. Wed love to chat with a bunch of folks. If you wanna chat about conversation design practices, the talk Ive given previously on how to actually structure our team, happy to do that as well. Weve got a booth at the back in a social today at four thirty, and there will be free drinks. So and its a beautiful venue right on the beach. So feel free to come by. Say hi, and well give you a ticket for that. And with that, thanks so much.</p>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/sparking-the-future-of-conversation-design-braden-ream-ceo-voiceflow-project-voice-x/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
