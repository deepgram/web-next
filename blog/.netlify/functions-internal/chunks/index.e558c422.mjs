import { c as createAstro, a as createComponent, r as renderTemplate, b as renderHead } from '../entry.mjs';
import Slugger from 'github-slugger';
import '@astrojs/netlify/netlify-functions.js';
import 'preact';
import 'preact-render-to-string';
import 'vue';
import 'vue/server-renderer';
import 'html-escaper';
import 'node-html-parser';
import 'axios';
/* empty css                           *//* empty css                           *//* empty css                           */import '@storyblok/js';
/* empty css                           *//* empty css                          */import 'clone-deep';
import 'slugify';
import 'shiki';
/* empty css                           */import 'camelcase';
import '@astrojs/rss';
/* empty css                           */import 'mime';
import 'cookie';
import 'kleur/colors';
import 'string-width';
import 'path-browserify';
import 'path-to-regexp';

const metadata = { "headings": [{ "depth": 2, "slug": "an-introduction-to-audio-data", "text": "An Introduction to Audio Data" }, { "depth": 3, "slug": "what-is-a-sampling-rate", "text": "What Is a Sampling Rate?" }, { "depth": 3, "slug": "types-of-audio-data", "text": "Types of Audio Data" }, { "depth": 2, "slug": "ways-to-use-audio-data", "text": "Ways To Use Audio Data" }, { "depth": 2, "slug": "recording-audio-data-with-python", "text": "Recording Audio Data With Python" }, { "depth": 3, "slug": "use-pyaudio-to-record-sound", "text": "Use PyAudio To Record Sound" }, { "depth": 3, "slug": "record-with-python-sounddevice", "text": "Record With Python-Sounddevice" }, { "depth": 2, "slug": "playing-audio-data-with-python", "text": "Playing Audio Data With Python" }, { "depth": 3, "slug": "use-pyaudio-to-play-audio", "text": "Use Pyaudio To Play Audio" }, { "depth": 3, "slug": "play-audio-with-python-sounddevice", "text": "Play Audio With Python-sounddevice" }, { "depth": 2, "slug": "clipping-audio-data-with-python", "text": "Clipping Audio Data With Python" }, { "depth": 3, "slug": "clip-audio-with-pydub", "text": "Clip Audio With Pydub" }, { "depth": 3, "slug": "trim-audio-clips-with-ffmpeg", "text": "Trim Audio Clips With FFMPEG" }, { "depth": 2, "slug": "manipulating-audio-data-sampling-rates-with-python", "text": "Manipulating Audio Data Sampling Rates With Python" }, { "depth": 3, "slug": "pydub", "text": "Pydub" }, { "depth": 3, "slug": "scipy", "text": "Scipy" }, { "depth": 2, "slug": "changing-volume-of-audio-data-with-python", "text": "Changing Volume of Audio Data with Python" }, { "depth": 2, "slug": "combining-two-audio-files-with-python", "text": "Combining Two Audio Files With Python" }, { "depth": 2, "slug": "overlay-two-audio-files-with-python", "text": "Overlay Two Audio Files With Python" }, { "depth": 2, "slug": "changing-audio-data-file-formats-with-python", "text": "Changing Audio Data File Formats With Python" }, { "depth": 2, "slug": "transcribe-audio-data-with-a-web-api", "text": "Transcribe Audio Data With a Web API" }, { "depth": 2, "slug": "summary-of-the-best-python-tools-for-manipulating-audio-data", "text": "Summary of the Best Python Tools for Manipulating Audio Data" }, { "depth": 2, "slug": "further-reading", "text": "Further Reading" }], "source": '\nPython provides us with many packages to manipulate audio data, but they don\u2019t all work. As Python developers, we\u2019re all familiar with the usual challenges - solving environments, compatibility between versions, and finding the right packages. This post covers how to do all of that for working with audio data. You can find a [GitHub repo here](https://github.com/deepgram-devs/basic_audio_data_manip) with all the samples discussed below.\n\nNote that this post is written using Python 3.9 as many audio packages have not yet been upgraded to work with 3.10 or 3.11. In this post we\u2019ll cover:\n\n*   [An Introduction to Audio Data](#an-introduction-to-audio-data)\n*   [Ways To Use Audio Data](#ways-to-use-audio-data)\n*   [Recording Audio Data With Python](#recording-audio-data-with-python)\n*   [Playing Audio Data With Python](#playing-audio-data-with-python)\n*   [Clipping Audio Data With Python](#clipping-audio-data-with-python)\n*   [Manipulating Audio Data Sampling Rates With Python](#manipulating-audio-data-sampling-rates-with-python)\n*   [Changing Volume of Audio Data With Python](#changing-volume-of-audio-data-with-python)\n*   [Combining Two Audio Files With Python](#combining-two-audio-files-with-python)\n*   [Overlay Two Audio Files With Python](#overlay-two-audio-files-with-python)\n*   [Changing Audio Data File Formats With Python](#changing-audio-data-file-formats-with-python)\n*   [Transcribe Audio Data With a Web API](#transcribe-audio-data-with-a-web-api)\n*   [Summary of the Best Python Tools for Manipulating Audio Data](#summary-of-the-best-python-tools-for-manipulating-audio-data)\n\n## An Introduction to Audio Data\n\nWhat is audio data? Simply put, audio data is any data format that comes in the form of audio. At a fundamental level, there are not many ways to represent sound. The large number of audio data file types is due to the number of approaches to compress and package the data. Let\u2019s take a look at two fundamental concepts before we jump deeper - sampling rates and types of audio data formats.\n\n### What Is a Sampling Rate?\n\nA sampling rate, sometimes also referred to as a frame rate, is the number of times per second that we measure the amplitude of the signal. It is measured in frames per second or Hertz (Hz). An ideal rate can be determined using [Nyquist\u2019s Sampling Theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem). Some common sampling rates are 16 kHz (common for VoiP), 44.1 kHz (common in CDs), and 96 kHz (common in DVDs and Blu-Ray).\n\n### Types of Audio Data\n\n![](https://res.cloudinary.com/deepgram/image/upload/v1654876366/blog/2022/06/best-python-audio-manipulation-tools/types-of-audio-data.png)\n\nThere\u2019s one well known way to represent sound - using waves. However, computers can represent that data in many ways. The most common audio data file types are `.wav` and `.mp3`. The main difference between `.wav` and `.mp3` files is that `.wav` files are not compressed and `.mp3` files are. This makes `.wav` files great for when you need the highest quality audio and `.mp3` files best when you need fast streaming.\n\nOther file types include Audio Interchange File Format (AIFF), raw Pulse Code Modulation (PCM) data, and Advanced Audio Coding (AAC). AIFF is a file format developed by Apple to be used on Mac OS much like WAVE files were initially developed by Microsoft. PCM is the raw audio data format. AAC\u2019s were meant to be the successor to MP3 files, but did not catch on as a replay format. However, it did catch on as a popular streaming audio format and is used by YouTube, iPhones, and Nintendo.\n\n## Ways To Use Audio Data\n\nAudio data is becoming more and more ubiquitous. It\u2019s created on phone calls, remote video meeting recordings, for music and videos, and so much more. How can we use all this audio data being created? We can layer sound bites for music, change the volume of different sound streams to make it easier to hear everyone from a VoiP call, or transcribe a call to read later. Of course, this only covers some of the things we can do with sound data, there are many other valuable ways to use audio that we haven\u2019t even discovered.\n\n## Recording Audio Data With Python\n\nTwo of the most basic things you can do with audio data in Python are playing and recording audio. In the next two sections we\u2019ll cover how to use two popular Python sound libraries to play and record audio data. First, we\u2019ll take a look at how to record audio data with `sounddevice` and `pyaudio`.\n\nBefore we get started with the code, we\u2019ll have to install the prerequisite libraries. PyAudio is a wrapper around PortAudio. The installation will be different for Windows and Mac. On Mac OS, you can use `brew` to install `portaudio` after installing your X-Code tools. For Windows, see [this answer on StackOverflow](https://stackoverflow.com/questions/52283840/i-cant-install-pyaudio-on-windows-how-to-solve-error-microsoft-visual-c-14/52284344#52284344).\n\nHow to Install PyAudio (on Mac):\n\n    xcode-select --install\n    brew remove portaudio\n    brew install portaudio\n    pip install pyaudio\n\nIf you are having trouble, use this command instead to specify your build locations for portaudio:\n\n    pip install --global-option=\'build_ext\' --global-option="-I$(brew --prefix)/include" --global-option="-L$(brew --prefix)/lib" pyaudio\n\nTo install `python-sounddevice`, run the line `pip install sounddevice scipy` in the command line. We will need `scipy` for downloading the streamed data and for later use.\n\n### Use PyAudio To Record Sound\n\nIn this example, we\u2019re going to use PyAudio and the Python native `wave` library to record some sound and save it into a file. We\u2019ll start by importing the two libraries and declaring constants. The constants we need to declare up front are the chunk size (the number of frames saved at a time), the format (16 bit), the number of channels (1), the sampling rate (44100), the length of our recording (3 seconds), and the filename we want to save our recording to.\n\nFrom there, we create a PyAudio object. We\u2019ll use the PyAudio object to create a stream with the constants we set above. Then, we\u2019ll initialize an empty list of frames to hold the frames. Next, we\u2019ll use the stream to read data while we still have time left in our 3 second timeframe and save it in the chunk size of 1024 bits.\n\nWe need to close and terminate our stream after 3 seconds. Finally, we\u2019ll use the `wave` library to save the streamed audio data into a `.wav` file with the preset constants we declared above.\n\n```py\nimport pyaudio\nimport wave\n\nchunk = 1024\nsample_format = pyaudio.paInt16\nchannels = 1\nfs = 44100 # frames per channel\nseconds = 3\nfilename = "output_pyaudio.wav"\n\np=pyaudio.PyAudio()\n\nprint("Recording ...")\n\nstream = p.open(format = sample_format,\n                channels = channels,\n                rate = fs,\n                frames_per_buffer =  chunk,\n                input = True)\n\nframes = []\nfor i in range(0, int(fs/chunk * seconds)):\n    data = stream.read(chunk)\n    frames.append(data)\n\nstream.stop_stream()\nstream.close()\np.terminate()\n\nprint("... Ending Recording")\nwith wave.open(filename, \'wb\') as wf:\n    wf.setnchannels(channels)\n    wf.setsampwidth(p.get_sample_size(sample_format))\n    wf.setframerate(fs)\n    wf.writeframes(b\'\'.join(frames))\n    wf.close()\n```\n\n### Record With Python-Sounddevice\n\nPython-Sounddevice, or just `sounddevice` when you import it or install it through `pip`, is a simple sound recording and playing library. We can see below that it takes much less code to simply make a recording than `pyaudio`.\n\nFirst, we import the libraries we need, `sounddevice` and the `write` function from `scipy.io.wavfile`. Next, we declare a couple constants for the sampling rate and the length of recording. Once we have those, we just record, ask `sounddevice` to wait, and then use `scipy` to write the recorded audio.\n\n```py\nimport sounddevice as sd\nfrom scipy.io.wavfile import write\n\nfs = 44100\nseconds = 3\n\nrecording = sd.rec(int(seconds*fs), samplerate=fs, channels=1)\nsd.wait()\nwrite(\'output_sounddevice.wav\', fs, recording)\n```\n\n## Playing Audio Data With Python\n\nPlaying audio data is the sister function to recording audio data. Only being able to record data would be almost useless. For this section, we\u2019re going to use the same libraries we did above, `pyaudio`, and `sounddevice`. However, we will also need one more library for using `sounddevice` to play audio data, `soundfile`. We need to run this command in the terminal: `pip install soundfile` to install it.\n\n### Use Pyaudio To Play Audio\n\nOnce again, we\u2019ll use the built-in `wave` library along with `pyaudio` to play some sound. We\u2019ll use the recording we made above and the same chunk size. We will start our functionality by opening the file and creating a `pyaudio` object.\n\nWe will then use the `pyaudio` object to open a stream with specifications extracted from the wave file. Next, we\u2019ll create a data object that reads the frames of the wave file in the specified chunk size. To actually play the sound, we\u2019ll loop through the data file and write it to the stream while it is not an empty bit. Finally, we\u2019ll close the stream and terminate the `pyaudio` object.\n\n```py\nimport pyaudio\nimport wave\n\n# declare constants and initialize portaudio/pyaudio object\nfilename = \'output_pyaudio.wav\'\nchunk = 1024\nwf = wave.open(filename, \'rb\')\npa = pyaudio.PyAudio()\n\n# create stream using info from the file\nstream = pa.open(format = pa.get_format_from_width(wf.getsampwidth()),\n                channels = wf.getnchannels(),\n                rate = wf.getframerate(),\n                output = True)\n\n# read in the frames as data\ndata = wf.readframes(chunk)\n\n# while the data isn\'t empty\nwhile data != b\'\':\n    stream.write(data)\n    data = wf.readframes(chunk)\n\n# cleanup\nstream.close()\npa.terminate()\n```\n\n### Play Audio With Python-sounddevice\n\nOnce again, we see the simplification of playing audio that `sounddevice` offers over `pyaudio`. Remember that both the playing and recording simplifications also come with the need to install and use two extra libraries though.\n\nFor this example, we will import the `sounddevice` and `soundfile` libraries. Then, we will feed the filename to `soundfile` to `read` us the data and the sampling rate. Finally, we use `sounddevice` to `play` the resulting sound and make the process wait while the sound finishes playing.\n\n```py\nimport sounddevice\nimport soundfile\n\nfilename = "output_sounddevice.wav"\ndata, fs = soundfile.read(filename, dtype=\'float32\')\nsounddevice.play(data, fs)\nstatus = sounddevice.wait()\n```\n\n## Clipping Audio Data With Python\n\nNow that we\u2019ve covered the simplest acts of playing and recording audio, let\u2019s move onto how to change the audio data. The first thing we\u2019ll cover is clipping or trimming audio data. For this example, we\u2019ll need to install two more libraries, `pydub` and `ffmpeg-python`. We can install these with pip in the command line as usual using `pip install pydub ffmpeg-python`.\n\n### Clip Audio With Pydub\n\nAs we will see here and further down the post, the `pydub` library is a swiss army knife of audio manipulation tools. To trim audio data with `pydub`, we only need the `AudioSegment` object. To start, we\u2019ll define the first and last milliseconds we want to clip out. Then, we\u2019ll load the audio file with `AudioSegment`.\n\nTo clip our audio file down, we\u2019ll create a list that only contains the data from the start to the end millisecond in our audio file. Finally, we\u2019ll use the `export` function of the `AudioSegment` object we extracted to save the file in `.wav` format.\n\n```py\nfrom pydub import AudioSegment\n\n# start at 0 milliseconds\n# end at 1500 milliseconds\nstart = 0\nend = 1500\n\nsound = AudioSegment.from_wav("output_pyaudio.wav")\nextract = sound[start:end]\n\nextract.export("trimmed_output_pydub.wav", format="wav")\n```\n\n### Trim Audio Clips With FFMPEG\n\nFFMPEG is a well known audio manipulation library, usually used in the command line. You can use the `sys` and `subprocess` libraries that are native to Python to use FFMPEG, but I find that using the SDK is easier and more satisfying.\n\nEven though we had to install this SDK with `pip install ffmpeg-python`, we actually import it as just `ffmpeg`. The first thing we\u2019ll do is get an input object. Then, we\u2019ll use the `ffmpeg.input` object to call the `atrim` function and trim the recording down to 1 second. Next, we\u2019ll create an output using the newly cut data. Finally, we\u2019ll need to call `ffmpeg` to actually run the `output` call and save our file.\n\n```py\nimport ffmpeg\n\naudio_input = ffmpeg.input("output_sounddevice.wav")\naudio_cut = audio_input.audio.filter(\'atrim\', duration=1)\naudio_output = ffmpeg.output(audio_cut, \'trimmed_output_ffmpeg.wav\', format=\'wav\')\nffmpeg.run(audio_output)\n```\n\n## Manipulating Audio Data Sampling Rates With Python\n\nHere\u2019s where things get a bit trickier. Sampling rates play a huge part in how audio data sounds. When you\u2019re changing the number of frames per second that represents a sound, a lot of funky things can happen. If not done right, it can affect the speed, the pitch, and the quality of your sound. For our examples, we\u2019ll be using `pydub` and `scipy`. Both libraries we already downloaded earlier.\n\n![Sample Rate Change in Audio File](https://res.cloudinary.com/deepgram/image/upload/v1654876364/blog/2022/06/best-python-audio-manipulation-tools/sample-rate.png)\n\n### Pydub\n\nAs mentioned above, `pydub` has a variety of tools for manipulating audio data, and changing the sample rate safely is one of them. The `AudioSegment` object has a wonderful `set_frame_rate` command that can be used to set the frame rate of the audio segment without changing the pitch, speed, or applying any other distortions. To save it, we will use the `export` function again.\n\n```py\nfrom pydub import AudioSegment\n\nsound = AudioSegment.from_wav(\'output_pyaudio.wav\')\nsound_w_new_fs = sound.set_frame_rate(16000)\nsound_w_new_fs.export("new_fs_output_pydub.wav", format="wav")\n```\n\n### Scipy\n\nIf you are so inclined and also mathematically skilled, you can apply your own sampling rate change with `scipy`. The most popular reasons to use `scipy` to customize your sampling is for advanced use cases like research, music, or special effects.\n\nRead in the sample rate and audio data using `wavfile`. Using the read-in sample rate and a desired new sample rate, create a new number of samples. To do the resampling, we call on the `resample` function from `scipy.signal`. This resample function applies a fourier transform and may cause distortion. This is a much more advanced technique and should probably only be used if necessary.\n\n```py\nfrom scipy.io import wavfile\nimport scipy.signal\n\nnew_fs = 88200\n# open data\nsample_rate, data = wavfile.read(\'output_pyaudio.wav\')\n\n# resample data\nnew_num_samples = round(len(data)*float(new_fs)/sample_rate)\ndata = scipy.signal.resample(data, new_num_samples)\nwavfile.write(filename="new_fs_output_scipy.wav", rate=88200, data=data)\n```\n\n## Changing Volume of Audio Data with Python\n\nThe next four things we\u2019re going to cover all use `pydub`. Partially because it is the easiest to use, partially because it is the only one that is updated enough to work with the latest versions of Python.\n\nChanging volume with the `AudioSegment` object from `pydub` is extremely easy. After importing the libraries and functions we need and opening up the `.wav` file, the only thing we need to do is add or subtract from the object representing the open `.wav` file.\n\nThe `play` function plays both sounds, one after the other, so that we can hear that one is louder and the other is softer. We can save the files using the `export` function as we have been doing so far.\n\n```py\nfrom pydub import AudioSegment\nfrom pydub.playback import play\n\nsound = AudioSegment.from_wav("new_fs_output_pydub.wav")\n\n# 3 dB up\nlouder = sound + 3\n# 3 dB down\nquieter = sound - 3\n\nplay(louder)\nplay(quieter)\n\nlouder.export("louder_output.wav", format="wav")\nquieter.export("quieter_output.wav", format="wav")\n```\n\n## Combining Two Audio Files With Python\n\nWe can also use `pydub` to combine two audio data files in Python. Once we open up the `.wav` files with `AudioSegment`, all we have to do to append them is add them. We can play the sound to make sure we got it and then export it into a file.\n\n```py\nfrom pydub import AudioSegment\nfrom pydub.playback import play\n\nsound1 = AudioSegment.from_wav("louder_output.wav")\nsound2 = AudioSegment.from_wav("quieter_output.wav")\n\ncombined = sound1 + sound2\n\nplay(combined)\ncombined.export("louder_and_quieter.wav", format="wav")\n```\n\n## Overlay Two Audio Files With Python\n\nYou\u2019d think that overlaying audio data would be harder than combining them, but the `AudioSegment` object from the `pydub` library makes it quite easy. All we do is call the `overlay` function and pass it the sound we want to overlay and the position (in milliseconds) we want to overlay it at.\n\n```py\nfrom pydub import AudioSegment\nfrom pydub.playback import play\n\nsound1 = AudioSegment.from_wav("louder_output.wav")\nsound2 = AudioSegment.from_wav("quieter_output.wav")\n\noverlay = sound1.overlay(sound2, position=1000)\n\nplay(overlay)\noverlay.export("overlaid_1sec_offset.wav", format="wav")\n```\n\n## Changing Audio Data File Formats With Python\n\nWe\u2019ve covered a lot of ways to manipulate audio data in Python from the basic playing and recording to overlaying different sounds. What if we just need our audio file in a different format? We can also use `pydub` to convert audio formats.\n\nThe `AudioSegment` object\u2019s `export` function that we\u2019ve been using in the sections above has the capability to define the output object\u2019s format. All we have to do to save it as a different format is pass that format to the `export` function. In the example below, I\u2019ve opened up a `.wav` file and saved it as a `.mp3`.\n\n```py\nfrom pydub import AudioSegment\n\nwav_audio = AudioSegment.from_wav("louder_output.wav")\nmp3_audio = wav_audio.export("louder.mp3", format="mp3")\n```\n\n## Transcribe Audio Data With a Web API\n\nFinally, we come to the last bit of audio data manipulation to be covered in this primer to audio data in Python. Having the transcription of an audio file can be useful for many reasons. You can use it to [visualize your data](https://blog.deepgram.com/python-graphing-transcripts/), [search for keywords from a library of audio files](https://blog.deepgram.com/python-script-compliance/), or get inputs for Natural Language Understanding (NLU) models.\n\nTo transcribe your audio with a Web API, you\u2019ll need to sign up for a [free Deepgram API key](https://console.deepgram.com/signup?jump=keys) and run `pip install deepgram-sdk` in your terminal.\n\nWe\u2019ll be using `asyncio` to asynchronously make the API request. Before we create our function, we need to make sure that we have the API key and the file name. The function will initialize the Deepgram SDK, open the local file, and send it to the transcription endpoint. Then it will wait for the response and dump it into a JSON file formatted with a tab of 4 spaces. We will then both print the JSON result to the terminal and save it as a `.txt` file. Finally, we\u2019ll use `asyncio` to run the function.\n\n```py\nfrom deepgram import Deepgram\nfrom config import dg_secret_key\nimport asyncio, json\n\nDEEPGRAM_API_KEY = dg_secret_key\nPATH_TO_FILE = \'louder_output.wav\'\n\nasync def main():\n    # Initializes the Deepgram SDK\n    deepgram = Deepgram(DEEPGRAM_API_KEY)\n    # Open the audio file\n    with open(PATH_TO_FILE, \'rb\') as audio:\n        # ...or replace mimetype as appropriate\n        source = {\'buffer\': audio, \'mimetype\': \'audio/wav\'}\n        response = await deepgram.transcription.prerecorded(source, {\'punctuate\': True})\n        json_obj = json.dumps(response, indent=4)\n        print(json_obj)\n        with open("transcribed.txt", "w") as f:\n            f.write(json_obj)\n\nasyncio.run(main())\n```\n\n## Summary of the Best Python Tools for Manipulating Audio Data\n\nAudio data covers a large swath of data that isn\u2019t commonly thought about when it comes to data analysis and manipulation. In this post, we covered how to use some of the most up-to-date Python libraries for manipulating audio data.\n\nWe learned how to play and record audio data using `pyaudio` and `python-sounddevice`. How to trim data with `pydub` and `ffmpeg`, and how to resample data with `pydub` and `scipy`. Then we saw how we can use `pydub` as a swiss army knife of audio to change the volume, combine or overlay files, and change the file format. Finally, we saw how we can easily use the Deepgram SDK to transcribe audio data.\n\n## Further Reading\n\n*   [Lecture Notes on Audio Data from Penn](https://www.ling.upenn.edu/courses/Spring_2003/ling538/Lecnotes/AudioData.html)\n*   [Audio File Formats](https://en.wikipedia.org/wiki/Audio_file_format)\n\n        ', "html": '<p>Python provides us with many packages to manipulate audio data, but they don\u2019t all work. As Python developers, we\u2019re all familiar with the usual challenges - solving environments, compatibility between versions, and finding the right packages. This post covers how to do all of that for working with audio data. You can find a <a href="https://github.com/deepgram-devs/basic_audio_data_manip">GitHub repo here</a> with all the samples discussed below.</p>\n<p>Note that this post is written using Python 3.9 as many audio packages have not yet been upgraded to work with 3.10 or 3.11. In this post we\u2019ll cover:</p>\n<ul>\n<li><a href="#an-introduction-to-audio-data">An Introduction to Audio Data</a></li>\n<li><a href="#ways-to-use-audio-data">Ways To Use Audio Data</a></li>\n<li><a href="#recording-audio-data-with-python">Recording Audio Data With Python</a></li>\n<li><a href="#playing-audio-data-with-python">Playing Audio Data With Python</a></li>\n<li><a href="#clipping-audio-data-with-python">Clipping Audio Data With Python</a></li>\n<li><a href="#manipulating-audio-data-sampling-rates-with-python">Manipulating Audio Data Sampling Rates With Python</a></li>\n<li><a href="#changing-volume-of-audio-data-with-python">Changing Volume of Audio Data With Python</a></li>\n<li><a href="#combining-two-audio-files-with-python">Combining Two Audio Files With Python</a></li>\n<li><a href="#overlay-two-audio-files-with-python">Overlay Two Audio Files With Python</a></li>\n<li><a href="#changing-audio-data-file-formats-with-python">Changing Audio Data File Formats With Python</a></li>\n<li><a href="#transcribe-audio-data-with-a-web-api">Transcribe Audio Data With a Web API</a></li>\n<li><a href="#summary-of-the-best-python-tools-for-manipulating-audio-data">Summary of the Best Python Tools for Manipulating Audio Data</a></li>\n</ul>\n<h2 id="an-introduction-to-audio-data">An Introduction to Audio Data</h2>\n<p>What is audio data? Simply put, audio data is any data format that comes in the form of audio. At a fundamental level, there are not many ways to represent sound. The large number of audio data file types is due to the number of approaches to compress and package the data. Let\u2019s take a look at two fundamental concepts before we jump deeper - sampling rates and types of audio data formats.</p>\n<h3 id="what-is-a-sampling-rate">What Is a Sampling Rate?</h3>\n<p>A sampling rate, sometimes also referred to as a frame rate, is the number of times per second that we measure the amplitude of the signal. It is measured in frames per second or Hertz (Hz). An ideal rate can be determined using <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Nyquist\u2019s Sampling Theorem</a>. Some common sampling rates are 16 kHz (common for VoiP), 44.1 kHz (common in CDs), and 96 kHz (common in DVDs and Blu-Ray).</p>\n<h3 id="types-of-audio-data">Types of Audio Data</h3>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654876366/blog/2022/06/best-python-audio-manipulation-tools/types-of-audio-data.png" alt=""></p>\n<p>There\u2019s one well known way to represent sound - using waves. However, computers can represent that data in many ways. The most common audio data file types are <code is:raw>.wav</code> and <code is:raw>.mp3</code>. The main difference between <code is:raw>.wav</code> and <code is:raw>.mp3</code> files is that <code is:raw>.wav</code> files are not compressed and <code is:raw>.mp3</code> files are. This makes <code is:raw>.wav</code> files great for when you need the highest quality audio and <code is:raw>.mp3</code> files best when you need fast streaming.</p>\n<p>Other file types include Audio Interchange File Format (AIFF), raw Pulse Code Modulation (PCM) data, and Advanced Audio Coding (AAC). AIFF is a file format developed by Apple to be used on Mac OS much like WAVE files were initially developed by Microsoft. PCM is the raw audio data format. AAC\u2019s were meant to be the successor to MP3 files, but did not catch on as a replay format. However, it did catch on as a popular streaming audio format and is used by YouTube, iPhones, and Nintendo.</p>\n<h2 id="ways-to-use-audio-data">Ways To Use Audio Data</h2>\n<p>Audio data is becoming more and more ubiquitous. It\u2019s created on phone calls, remote video meeting recordings, for music and videos, and so much more. How can we use all this audio data being created? We can layer sound bites for music, change the volume of different sound streams to make it easier to hear everyone from a VoiP call, or transcribe a call to read later. Of course, this only covers some of the things we can do with sound data, there are many other valuable ways to use audio that we haven\u2019t even discovered.</p>\n<h2 id="recording-audio-data-with-python">Recording Audio Data With Python</h2>\n<p>Two of the most basic things you can do with audio data in Python are playing and recording audio. In the next two sections we\u2019ll cover how to use two popular Python sound libraries to play and record audio data. First, we\u2019ll take a look at how to record audio data with <code is:raw>sounddevice</code> and <code is:raw>pyaudio</code>.</p>\n<p>Before we get started with the code, we\u2019ll have to install the prerequisite libraries. PyAudio is a wrapper around PortAudio. The installation will be different for Windows and Mac. On Mac OS, you can use <code is:raw>brew</code> to install <code is:raw>portaudio</code> after installing your X-Code tools. For Windows, see <a href="https://stackoverflow.com/questions/52283840/i-cant-install-pyaudio-on-windows-how-to-solve-error-microsoft-visual-c-14/52284344#52284344">this answer on StackOverflow</a>.</p>\n<p>How to Install PyAudio (on Mac):</p>\n<p>xcode-select \u2014install\nbrew remove portaudio\nbrew install portaudio\npip install pyaudio</p>\n<p>If you are having trouble, use this command instead to specify your build locations for portaudio:</p>\n<p>pip install \u2014global-option=\u2018build_ext\u2019 \u2014global-option=\u201C-I$(brew \u2014prefix)/include\u201D \u2014global-option=\u201C-L$(brew \u2014prefix)/lib\u201D pyaudio</p>\n<p>To install <code is:raw>python-sounddevice</code>, run the line <code is:raw>pip install sounddevice scipy</code> in the command line. We will need <code is:raw>scipy</code> for downloading the streamed data and for later use.</p>\n<h3 id="use-pyaudio-to-record-sound">Use PyAudio To Record Sound</h3>\n<p>In this example, we\u2019re going to use PyAudio and the Python native <code is:raw>wave</code> library to record some sound and save it into a file. We\u2019ll start by importing the two libraries and declaring constants. The constants we need to declare up front are the chunk size (the number of frames saved at a time), the format (16 bit), the number of channels (1), the sampling rate (44100), the length of our recording (3 seconds), and the filename we want to save our recording to.</p>\n<p>From there, we create a PyAudio object. We\u2019ll use the PyAudio object to create a stream with the constants we set above. Then, we\u2019ll initialize an empty list of frames to hold the frames. Next, we\u2019ll use the stream to read data while we still have time left in our 3 second timeframe and save it in the chunk size of 1024 bits.</p>\n<p>We need to close and terminate our stream after 3 seconds. Finally, we\u2019ll use the <code is:raw>wave</code> library to save the streamed audio data into a <code is:raw>.wav</code> file with the preset constants we declared above.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wave</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_format </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pyaudio.paInt16</span></span>\n<span class="line"><span style="color: #C9D1D9">channels </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span></span>\n<span class="line"><span style="color: #C9D1D9">fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">44100</span><span style="color: #C9D1D9"> </span><span style="color: #8B949E"># frames per channel</span></span>\n<span class="line"><span style="color: #C9D1D9">seconds </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;output_pyaudio.wav&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">p</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">pyaudio.PyAudio()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Recording ...&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">stream </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.open(</span><span style="color: #FFA657">format</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_format,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">channels</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> channels,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">rate</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> fs,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">frames_per_buffer</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">  chunk,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">input</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(fs</span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> seconds)):</span></span>\n<span class="line"><span style="color: #C9D1D9">    data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stream.read(chunk)</span></span>\n<span class="line"><span style="color: #C9D1D9">    frames.append(data)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">stream.stop_stream()</span></span>\n<span class="line"><span style="color: #C9D1D9">stream.close()</span></span>\n<span class="line"><span style="color: #C9D1D9">p.terminate()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;... Ending Recording&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> wave.open(filename, </span><span style="color: #A5D6FF">&#39;wb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> wf:</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.setnchannels(channels)</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.setsampwidth(p.get_sample_size(sample_format))</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.setframerate(fs)</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.writeframes(</span><span style="color: #FF7B72">b</span><span style="color: #A5D6FF">&#39;&#39;</span><span style="color: #C9D1D9">.join(frames))</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.close()</span></span></code></pre>\n<h3 id="record-with-python-sounddevice">Record With Python-Sounddevice</h3>\n<p>Python-Sounddevice, or just <code is:raw>sounddevice</code> when you import it or install it through <code is:raw>pip</code>, is a simple sound recording and playing library. We can see below that it takes much less code to simply make a recording than <code is:raw>pyaudio</code>.</p>\n<p>First, we import the libraries we need, <code is:raw>sounddevice</code> and the <code is:raw>write</code> function from <code is:raw>scipy.io.wavfile</code>. Next, we declare a couple constants for the sampling rate and the length of recording. Once we have those, we just record, ask <code is:raw>sounddevice</code> to wait, and then use <code is:raw>scipy</code> to write the recorded audio.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> sounddevice </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> sd</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> scipy.io.wavfile </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> write</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">44100</span></span>\n<span class="line"><span style="color: #C9D1D9">seconds </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">recording </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sd.rec(</span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(seconds</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">fs), </span><span style="color: #FFA657">samplerate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">fs, </span><span style="color: #FFA657">channels</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sd.wait()</span></span>\n<span class="line"><span style="color: #C9D1D9">write(</span><span style="color: #A5D6FF">&#39;output_sounddevice.wav&#39;</span><span style="color: #C9D1D9">, fs, recording)</span></span></code></pre>\n<h2 id="playing-audio-data-with-python">Playing Audio Data With Python</h2>\n<p>Playing audio data is the sister function to recording audio data. Only being able to record data would be almost useless. For this section, we\u2019re going to use the same libraries we did above, <code is:raw>pyaudio</code>, and <code is:raw>sounddevice</code>. However, we will also need one more library for using <code is:raw>sounddevice</code> to play audio data, <code is:raw>soundfile</code>. We need to run this command in the terminal: <code is:raw>pip install soundfile</code> to install it.</p>\n<h3 id="use-pyaudio-to-play-audio">Use Pyaudio To Play Audio</h3>\n<p>Once again, we\u2019ll use the built-in <code is:raw>wave</code> library along with <code is:raw>pyaudio</code> to play some sound. We\u2019ll use the recording we made above and the same chunk size. We will start our functionality by opening the file and creating a <code is:raw>pyaudio</code> object.</p>\n<p>We will then use the <code is:raw>pyaudio</code> object to open a stream with specifications extracted from the wave file. Next, we\u2019ll create a data object that reads the frames of the wave file in the specified chunk size. To actually play the sound, we\u2019ll loop through the data file and write it to the stream while it is not an empty bit. Finally, we\u2019ll close the stream and terminate the <code is:raw>pyaudio</code> object.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wave</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># declare constants and initialize portaudio/pyaudio object</span></span>\n<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span></span>\n<span class="line"><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>\n<span class="line"><span style="color: #C9D1D9">wf </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wave.open(filename, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">pa </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pyaudio.PyAudio()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># create stream using info from the file</span></span>\n<span class="line"><span style="color: #C9D1D9">stream </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pa.open(</span><span style="color: #FFA657">format</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pa.get_format_from_width(wf.getsampwidth()),</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">channels</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.getnchannels(),</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">rate</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.getframerate(),</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">output</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># read in the frames as data</span></span>\n<span class="line"><span style="color: #C9D1D9">data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.readframes(chunk)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># while the data isn&#39;t empty</span></span>\n<span class="line"><span style="color: #FF7B72">while</span><span style="color: #C9D1D9"> data </span><span style="color: #FF7B72">!=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">b</span><span style="color: #A5D6FF">&#39;&#39;</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">    stream.write(data)</span></span>\n<span class="line"><span style="color: #C9D1D9">    data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.readframes(chunk)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># cleanup</span></span>\n<span class="line"><span style="color: #C9D1D9">stream.close()</span></span>\n<span class="line"><span style="color: #C9D1D9">pa.terminate()</span></span></code></pre>\n<h3 id="play-audio-with-python-sounddevice">Play Audio With Python-sounddevice</h3>\n<p>Once again, we see the simplification of playing audio that <code is:raw>sounddevice</code> offers over <code is:raw>pyaudio</code>. Remember that both the playing and recording simplifications also come with the need to install and use two extra libraries though.</p>\n<p>For this example, we will import the <code is:raw>sounddevice</code> and <code is:raw>soundfile</code> libraries. Then, we will feed the filename to <code is:raw>soundfile</code> to <code is:raw>read</code> us the data and the sampling rate. Finally, we use <code is:raw>sounddevice</code> to <code is:raw>play</code> the resulting sound and make the process wait while the sound finishes playing.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> sounddevice</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> soundfile</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;output_sounddevice.wav&quot;</span></span>\n<span class="line"><span style="color: #C9D1D9">data, fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> soundfile.read(filename, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;float32&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sounddevice.play(data, fs)</span></span>\n<span class="line"><span style="color: #C9D1D9">status </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sounddevice.wait()</span></span></code></pre>\n<h2 id="clipping-audio-data-with-python">Clipping Audio Data With Python</h2>\n<p>Now that we\u2019ve covered the simplest acts of playing and recording audio, let\u2019s move onto how to change the audio data. The first thing we\u2019ll cover is clipping or trimming audio data. For this example, we\u2019ll need to install two more libraries, <code is:raw>pydub</code> and <code is:raw>ffmpeg-python</code>. We can install these with pip in the command line as usual using <code is:raw>pip install pydub ffmpeg-python</code>.</p>\n<h3 id="clip-audio-with-pydub">Clip Audio With Pydub</h3>\n<p>As we will see here and further down the post, the <code is:raw>pydub</code> library is a swiss army knife of audio manipulation tools. To trim audio data with <code is:raw>pydub</code>, we only need the <code is:raw>AudioSegment</code> object. To start, we\u2019ll define the first and last milliseconds we want to clip out. Then, we\u2019ll load the audio file with <code is:raw>AudioSegment</code>.</p>\n<p>To clip our audio file down, we\u2019ll create a list that only contains the data from the start to the end millisecond in our audio file. Finally, we\u2019ll use the <code is:raw>export</code> function of the <code is:raw>AudioSegment</code> object we extracted to save the file in <code is:raw>.wav</code> format.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># start at 0 milliseconds</span></span>\n<span class="line"><span style="color: #8B949E"># end at 1500 milliseconds</span></span>\n<span class="line"><span style="color: #C9D1D9">start </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>\n<span class="line"><span style="color: #C9D1D9">end </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1500</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;output_pyaudio.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">extract </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound[start:end]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">extract.export(</span><span style="color: #A5D6FF">&quot;trimmed_output_pydub.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h3 id="trim-audio-clips-with-ffmpeg">Trim Audio Clips With FFMPEG</h3>\n<p>FFMPEG is a well known audio manipulation library, usually used in the command line. You can use the <code is:raw>sys</code> and <code is:raw>subprocess</code> libraries that are native to Python to use FFMPEG, but I find that using the SDK is easier and more satisfying.</p>\n<p>Even though we had to install this SDK with <code is:raw>pip install ffmpeg-python</code>, we actually import it as just <code is:raw>ffmpeg</code>. The first thing we\u2019ll do is get an input object. Then, we\u2019ll use the <code is:raw>ffmpeg.input</code> object to call the <code is:raw>atrim</code> function and trim the recording down to 1 second. Next, we\u2019ll create an output using the newly cut data. Finally, we\u2019ll need to call <code is:raw>ffmpeg</code> to actually run the <code is:raw>output</code> call and save our file.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> ffmpeg</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">audio_input </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ffmpeg.input(</span><span style="color: #A5D6FF">&quot;output_sounddevice.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">audio_cut </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> audio_input.audio.filter(</span><span style="color: #A5D6FF">&#39;atrim&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">duration</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">audio_output </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ffmpeg.output(audio_cut, </span><span style="color: #A5D6FF">&#39;trimmed_output_ffmpeg.wav&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;wav&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">ffmpeg.run(audio_output)</span></span></code></pre>\n<h2 id="manipulating-audio-data-sampling-rates-with-python">Manipulating Audio Data Sampling Rates With Python</h2>\n<p>Here\u2019s where things get a bit trickier. Sampling rates play a huge part in how audio data sounds. When you\u2019re changing the number of frames per second that represents a sound, a lot of funky things can happen. If not done right, it can affect the speed, the pitch, and the quality of your sound. For our examples, we\u2019ll be using <code is:raw>pydub</code> and <code is:raw>scipy</code>. Both libraries we already downloaded earlier.</p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654876364/blog/2022/06/best-python-audio-manipulation-tools/sample-rate.png" alt="Sample Rate Change in Audio File"></p>\n<h3 id="pydub">Pydub</h3>\n<p>As mentioned above, <code is:raw>pydub</code> has a variety of tools for manipulating audio data, and changing the sample rate safely is one of them. The <code is:raw>AudioSegment</code> object has a wonderful <code is:raw>set_frame_rate</code> command that can be used to set the frame rate of the audio segment without changing the pitch, speed, or applying any other distortions. To save it, we will use the <code is:raw>export</code> function again.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound_w_new_fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound.set_frame_rate(</span><span style="color: #79C0FF">16000</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound_w_new_fs.export(</span><span style="color: #A5D6FF">&quot;new_fs_output_pydub.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h3 id="scipy">Scipy</h3>\n<p>If you are so inclined and also mathematically skilled, you can apply your own sampling rate change with <code is:raw>scipy</code>. The most popular reasons to use <code is:raw>scipy</code> to customize your sampling is for advanced use cases like research, music, or special effects.</p>\n<p>Read in the sample rate and audio data using <code is:raw>wavfile</code>. Using the read-in sample rate and a desired new sample rate, create a new number of samples. To do the resampling, we call on the <code is:raw>resample</code> function from <code is:raw>scipy.signal</code>. This resample function applies a fourier transform and may cause distortion. This is a much more advanced technique and should probably only be used if necessary.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> scipy.io </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wavfile</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> scipy.signal</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">new_fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">88200</span></span>\n<span class="line"><span style="color: #8B949E"># open data</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_rate, data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wavfile.read(</span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># resample data</span></span>\n<span class="line"><span style="color: #C9D1D9">new_num_samples </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">round</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">len</span><span style="color: #C9D1D9">(data)</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">float</span><span style="color: #C9D1D9">(new_fs)</span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> scipy.signal.resample(data, new_num_samples)</span></span>\n<span class="line"><span style="color: #C9D1D9">wavfile.write(</span><span style="color: #FFA657">filename</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;new_fs_output_scipy.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">88200</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">data</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">data)</span></span></code></pre>\n<h2 id="changing-volume-of-audio-data-with-python">Changing Volume of Audio Data with Python</h2>\n<p>The next four things we\u2019re going to cover all use <code is:raw>pydub</code>. Partially because it is the easiest to use, partially because it is the only one that is updated enough to work with the latest versions of Python.</p>\n<p>Changing volume with the <code is:raw>AudioSegment</code> object from <code is:raw>pydub</code> is extremely easy. After importing the libraries and functions we need and opening up the <code is:raw>.wav</code> file, the only thing we need to do is add or subtract from the object representing the open <code is:raw>.wav</code> file.</p>\n<p>The <code is:raw>play</code> function plays both sounds, one after the other, so that we can hear that one is louder and the other is softer. We can save the files using the <code is:raw>export</code> function as we have been doing so far.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;new_fs_output_pydub.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># 3 dB up</span></span>\n<span class="line"><span style="color: #C9D1D9">louder </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"><span style="color: #8B949E"># 3 dB down</span></span>\n<span class="line"><span style="color: #C9D1D9">quieter </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">play(louder)</span></span>\n<span class="line"><span style="color: #C9D1D9">play(quieter)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">louder.export(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">quieter.export(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="combining-two-audio-files-with-python">Combining Two Audio Files With Python</h2>\n<p>We can also use <code is:raw>pydub</code> to combine two audio data files in Python. Once we open up the <code is:raw>.wav</code> files with <code is:raw>AudioSegment</code>, all we have to do to append them is add them. We can play the sound to make sure we got it and then export it into a file.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">combined </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound1 </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> sound2</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">play(combined)</span></span>\n<span class="line"><span style="color: #C9D1D9">combined.export(</span><span style="color: #A5D6FF">&quot;louder_and_quieter.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="overlay-two-audio-files-with-python">Overlay Two Audio Files With Python</h2>\n<p>You\u2019d think that overlaying audio data would be harder than combining them, but the <code is:raw>AudioSegment</code> object from the <code is:raw>pydub</code> library makes it quite easy. All we do is call the <code is:raw>overlay</code> function and pass it the sound we want to overlay and the position (in milliseconds) we want to overlay it at.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">overlay </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound1.overlay(sound2, </span><span style="color: #FFA657">position</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">play(overlay)</span></span>\n<span class="line"><span style="color: #C9D1D9">overlay.export(</span><span style="color: #A5D6FF">&quot;overlaid_1sec_offset.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="changing-audio-data-file-formats-with-python">Changing Audio Data File Formats With Python</h2>\n<p>We\u2019ve covered a lot of ways to manipulate audio data in Python from the basic playing and recording to overlaying different sounds. What if we just need our audio file in a different format? We can also use <code is:raw>pydub</code> to convert audio formats.</p>\n<p>The <code is:raw>AudioSegment</code> object\u2019s <code is:raw>export</code> function that we\u2019ve been using in the sections above has the capability to define the output object\u2019s format. All we have to do to save it as a different format is pass that format to the <code is:raw>export</code> function. In the example below, I\u2019ve opened up a <code is:raw>.wav</code> file and saved it as a <code is:raw>.mp3</code>.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">wav_audio </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">mp3_audio </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wav_audio.export(</span><span style="color: #A5D6FF">&quot;louder.mp3&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;mp3&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="transcribe-audio-data-with-a-web-api">Transcribe Audio Data With a Web API</h2>\n<p>Finally, we come to the last bit of audio data manipulation to be covered in this primer to audio data in Python. Having the transcription of an audio file can be useful for many reasons. You can use it to <a href="https://blog.deepgram.com/python-graphing-transcripts/">visualize your data</a>, <a href="https://blog.deepgram.com/python-script-compliance/">search for keywords from a library of audio files</a>, or get inputs for Natural Language Understanding (NLU) models.</p>\n<p>To transcribe your audio with a Web API, you\u2019ll need to sign up for a <a href="https://console.deepgram.com/signup?jump=keys">free Deepgram API key</a> and run <code is:raw>pip install deepgram-sdk</code> in your terminal.</p>\n<p>We\u2019ll be using <code is:raw>asyncio</code> to asynchronously make the API request. Before we create our function, we need to make sure that we have the API key and the file name. The function will initialize the Deepgram SDK, open the local file, and send it to the transcription endpoint. Then it will wait for the response and dump it into a JSON file formatted with a tab of 4 spaces. We will then both print the JSON result to the terminal and save it as a <code is:raw>.txt</code> file. Finally, we\u2019ll use <code is:raw>asyncio</code> to run the function.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> config </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> dg_secret_key</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio, json</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dg_secret_key</span></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;louder_output.wav&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">main</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">    deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(</span><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">        source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">        response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">})</span></span>\n<span class="line"><span style="color: #C9D1D9">        json_obj </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> json.dumps(response, </span><span style="color: #FFA657">indent</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(json_obj)</span></span>\n<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;transcribed.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>\n<span class="line"><span style="color: #C9D1D9">            f.write(json_obj)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(main())</span></span></code></pre>\n<h2 id="summary-of-the-best-python-tools-for-manipulating-audio-data">Summary of the Best Python Tools for Manipulating Audio Data</h2>\n<p>Audio data covers a large swath of data that isn\u2019t commonly thought about when it comes to data analysis and manipulation. In this post, we covered how to use some of the most up-to-date Python libraries for manipulating audio data.</p>\n<p>We learned how to play and record audio data using <code is:raw>pyaudio</code> and <code is:raw>python-sounddevice</code>. How to trim data with <code is:raw>pydub</code> and <code is:raw>ffmpeg</code>, and how to resample data with <code is:raw>pydub</code> and <code is:raw>scipy</code>. Then we saw how we can use <code is:raw>pydub</code> as a swiss army knife of audio to change the volume, combine or overlay files, and change the file format. Finally, we saw how we can easily use the Deepgram SDK to transcribe audio data.</p>\n<h2 id="further-reading">Further Reading</h2>\n<ul>\n<li>\n<p><a href="https://www.ling.upenn.edu/courses/Spring_2003/ling538/Lecnotes/AudioData.html">Lecture Notes on Audio Data from Penn</a></p>\n</li>\n<li>\n<p><a href="https://en.wikipedia.org/wiki/Audio_file_format">Audio File Formats</a></p>\n</li>\n</ul>' };
const frontmatter = { "title": "Best Python Tools for Manipulating Audio Data", "description": "A comprehensive guide on using Python to work with audio files.", "date": "2022-06-13T00:00:00.000Z", "cover": "https://res.cloudinary.com/deepgram/image/upload/v1654884969/blog/2022/06/best-python-audio-manipulation-tools/cover.jpg", "authors": ["yujian-tang"], "category": "tutorial", "tags": ["python"], "seo": { "title": "Best Python Tools for Manipulating Audio Data", "description": "A comprehensive guide on using Python to work with audio files." }, "shorturls": { "share": "https://dpgr.am/737f53a", "twitter": "https://dpgr.am/b27d19f", "linkedin": "https://dpgr.am/de1fc03", "reddit": "https://dpgr.am/42f1085", "facebook": "https://dpgr.am/29312b6" }, "og": { "image": "https://res.cloudinary.com/deepgram/image/upload/v1661454091/blog/best-python-audio-manipulation-tools/ograph.png" }, "astro": { "headings": [{ "depth": 2, "slug": "an-introduction-to-audio-data", "text": "An Introduction to Audio Data" }, { "depth": 3, "slug": "what-is-a-sampling-rate", "text": "What Is a Sampling Rate?" }, { "depth": 3, "slug": "types-of-audio-data", "text": "Types of Audio Data" }, { "depth": 2, "slug": "ways-to-use-audio-data", "text": "Ways To Use Audio Data" }, { "depth": 2, "slug": "recording-audio-data-with-python", "text": "Recording Audio Data With Python" }, { "depth": 3, "slug": "use-pyaudio-to-record-sound", "text": "Use PyAudio To Record Sound" }, { "depth": 3, "slug": "record-with-python-sounddevice", "text": "Record With Python-Sounddevice" }, { "depth": 2, "slug": "playing-audio-data-with-python", "text": "Playing Audio Data With Python" }, { "depth": 3, "slug": "use-pyaudio-to-play-audio", "text": "Use Pyaudio To Play Audio" }, { "depth": 3, "slug": "play-audio-with-python-sounddevice", "text": "Play Audio With Python-sounddevice" }, { "depth": 2, "slug": "clipping-audio-data-with-python", "text": "Clipping Audio Data With Python" }, { "depth": 3, "slug": "clip-audio-with-pydub", "text": "Clip Audio With Pydub" }, { "depth": 3, "slug": "trim-audio-clips-with-ffmpeg", "text": "Trim Audio Clips With FFMPEG" }, { "depth": 2, "slug": "manipulating-audio-data-sampling-rates-with-python", "text": "Manipulating Audio Data Sampling Rates With Python" }, { "depth": 3, "slug": "pydub", "text": "Pydub" }, { "depth": 3, "slug": "scipy", "text": "Scipy" }, { "depth": 2, "slug": "changing-volume-of-audio-data-with-python", "text": "Changing Volume of Audio Data with Python" }, { "depth": 2, "slug": "combining-two-audio-files-with-python", "text": "Combining Two Audio Files With Python" }, { "depth": 2, "slug": "overlay-two-audio-files-with-python", "text": "Overlay Two Audio Files With Python" }, { "depth": 2, "slug": "changing-audio-data-file-formats-with-python", "text": "Changing Audio Data File Formats With Python" }, { "depth": 2, "slug": "transcribe-audio-data-with-a-web-api", "text": "Transcribe Audio Data With a Web API" }, { "depth": 2, "slug": "summary-of-the-best-python-tools-for-manipulating-audio-data", "text": "Summary of the Best Python Tools for Manipulating Audio Data" }, { "depth": 2, "slug": "further-reading", "text": "Further Reading" }], "source": '\nPython provides us with many packages to manipulate audio data, but they don\u2019t all work. As Python developers, we\u2019re all familiar with the usual challenges - solving environments, compatibility between versions, and finding the right packages. This post covers how to do all of that for working with audio data. You can find a [GitHub repo here](https://github.com/deepgram-devs/basic_audio_data_manip) with all the samples discussed below.\n\nNote that this post is written using Python 3.9 as many audio packages have not yet been upgraded to work with 3.10 or 3.11. In this post we\u2019ll cover:\n\n*   [An Introduction to Audio Data](#an-introduction-to-audio-data)\n*   [Ways To Use Audio Data](#ways-to-use-audio-data)\n*   [Recording Audio Data With Python](#recording-audio-data-with-python)\n*   [Playing Audio Data With Python](#playing-audio-data-with-python)\n*   [Clipping Audio Data With Python](#clipping-audio-data-with-python)\n*   [Manipulating Audio Data Sampling Rates With Python](#manipulating-audio-data-sampling-rates-with-python)\n*   [Changing Volume of Audio Data With Python](#changing-volume-of-audio-data-with-python)\n*   [Combining Two Audio Files With Python](#combining-two-audio-files-with-python)\n*   [Overlay Two Audio Files With Python](#overlay-two-audio-files-with-python)\n*   [Changing Audio Data File Formats With Python](#changing-audio-data-file-formats-with-python)\n*   [Transcribe Audio Data With a Web API](#transcribe-audio-data-with-a-web-api)\n*   [Summary of the Best Python Tools for Manipulating Audio Data](#summary-of-the-best-python-tools-for-manipulating-audio-data)\n\n## An Introduction to Audio Data\n\nWhat is audio data? Simply put, audio data is any data format that comes in the form of audio. At a fundamental level, there are not many ways to represent sound. The large number of audio data file types is due to the number of approaches to compress and package the data. Let\u2019s take a look at two fundamental concepts before we jump deeper - sampling rates and types of audio data formats.\n\n### What Is a Sampling Rate?\n\nA sampling rate, sometimes also referred to as a frame rate, is the number of times per second that we measure the amplitude of the signal. It is measured in frames per second or Hertz (Hz). An ideal rate can be determined using [Nyquist\u2019s Sampling Theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem). Some common sampling rates are 16 kHz (common for VoiP), 44.1 kHz (common in CDs), and 96 kHz (common in DVDs and Blu-Ray).\n\n### Types of Audio Data\n\n![](https://res.cloudinary.com/deepgram/image/upload/v1654876366/blog/2022/06/best-python-audio-manipulation-tools/types-of-audio-data.png)\n\nThere\u2019s one well known way to represent sound - using waves. However, computers can represent that data in many ways. The most common audio data file types are `.wav` and `.mp3`. The main difference between `.wav` and `.mp3` files is that `.wav` files are not compressed and `.mp3` files are. This makes `.wav` files great for when you need the highest quality audio and `.mp3` files best when you need fast streaming.\n\nOther file types include Audio Interchange File Format (AIFF), raw Pulse Code Modulation (PCM) data, and Advanced Audio Coding (AAC). AIFF is a file format developed by Apple to be used on Mac OS much like WAVE files were initially developed by Microsoft. PCM is the raw audio data format. AAC\u2019s were meant to be the successor to MP3 files, but did not catch on as a replay format. However, it did catch on as a popular streaming audio format and is used by YouTube, iPhones, and Nintendo.\n\n## Ways To Use Audio Data\n\nAudio data is becoming more and more ubiquitous. It\u2019s created on phone calls, remote video meeting recordings, for music and videos, and so much more. How can we use all this audio data being created? We can layer sound bites for music, change the volume of different sound streams to make it easier to hear everyone from a VoiP call, or transcribe a call to read later. Of course, this only covers some of the things we can do with sound data, there are many other valuable ways to use audio that we haven\u2019t even discovered.\n\n## Recording Audio Data With Python\n\nTwo of the most basic things you can do with audio data in Python are playing and recording audio. In the next two sections we\u2019ll cover how to use two popular Python sound libraries to play and record audio data. First, we\u2019ll take a look at how to record audio data with `sounddevice` and `pyaudio`.\n\nBefore we get started with the code, we\u2019ll have to install the prerequisite libraries. PyAudio is a wrapper around PortAudio. The installation will be different for Windows and Mac. On Mac OS, you can use `brew` to install `portaudio` after installing your X-Code tools. For Windows, see [this answer on StackOverflow](https://stackoverflow.com/questions/52283840/i-cant-install-pyaudio-on-windows-how-to-solve-error-microsoft-visual-c-14/52284344#52284344).\n\nHow to Install PyAudio (on Mac):\n\n    xcode-select --install\n    brew remove portaudio\n    brew install portaudio\n    pip install pyaudio\n\nIf you are having trouble, use this command instead to specify your build locations for portaudio:\n\n    pip install --global-option=\'build_ext\' --global-option="-I$(brew --prefix)/include" --global-option="-L$(brew --prefix)/lib" pyaudio\n\nTo install `python-sounddevice`, run the line `pip install sounddevice scipy` in the command line. We will need `scipy` for downloading the streamed data and for later use.\n\n### Use PyAudio To Record Sound\n\nIn this example, we\u2019re going to use PyAudio and the Python native `wave` library to record some sound and save it into a file. We\u2019ll start by importing the two libraries and declaring constants. The constants we need to declare up front are the chunk size (the number of frames saved at a time), the format (16 bit), the number of channels (1), the sampling rate (44100), the length of our recording (3 seconds), and the filename we want to save our recording to.\n\nFrom there, we create a PyAudio object. We\u2019ll use the PyAudio object to create a stream with the constants we set above. Then, we\u2019ll initialize an empty list of frames to hold the frames. Next, we\u2019ll use the stream to read data while we still have time left in our 3 second timeframe and save it in the chunk size of 1024 bits.\n\nWe need to close and terminate our stream after 3 seconds. Finally, we\u2019ll use the `wave` library to save the streamed audio data into a `.wav` file with the preset constants we declared above.\n\n```py\nimport pyaudio\nimport wave\n\nchunk = 1024\nsample_format = pyaudio.paInt16\nchannels = 1\nfs = 44100 # frames per channel\nseconds = 3\nfilename = "output_pyaudio.wav"\n\np=pyaudio.PyAudio()\n\nprint("Recording ...")\n\nstream = p.open(format = sample_format,\n                channels = channels,\n                rate = fs,\n                frames_per_buffer =  chunk,\n                input = True)\n\nframes = []\nfor i in range(0, int(fs/chunk * seconds)):\n    data = stream.read(chunk)\n    frames.append(data)\n\nstream.stop_stream()\nstream.close()\np.terminate()\n\nprint("... Ending Recording")\nwith wave.open(filename, \'wb\') as wf:\n    wf.setnchannels(channels)\n    wf.setsampwidth(p.get_sample_size(sample_format))\n    wf.setframerate(fs)\n    wf.writeframes(b\'\'.join(frames))\n    wf.close()\n```\n\n### Record With Python-Sounddevice\n\nPython-Sounddevice, or just `sounddevice` when you import it or install it through `pip`, is a simple sound recording and playing library. We can see below that it takes much less code to simply make a recording than `pyaudio`.\n\nFirst, we import the libraries we need, `sounddevice` and the `write` function from `scipy.io.wavfile`. Next, we declare a couple constants for the sampling rate and the length of recording. Once we have those, we just record, ask `sounddevice` to wait, and then use `scipy` to write the recorded audio.\n\n```py\nimport sounddevice as sd\nfrom scipy.io.wavfile import write\n\nfs = 44100\nseconds = 3\n\nrecording = sd.rec(int(seconds*fs), samplerate=fs, channels=1)\nsd.wait()\nwrite(\'output_sounddevice.wav\', fs, recording)\n```\n\n## Playing Audio Data With Python\n\nPlaying audio data is the sister function to recording audio data. Only being able to record data would be almost useless. For this section, we\u2019re going to use the same libraries we did above, `pyaudio`, and `sounddevice`. However, we will also need one more library for using `sounddevice` to play audio data, `soundfile`. We need to run this command in the terminal: `pip install soundfile` to install it.\n\n### Use Pyaudio To Play Audio\n\nOnce again, we\u2019ll use the built-in `wave` library along with `pyaudio` to play some sound. We\u2019ll use the recording we made above and the same chunk size. We will start our functionality by opening the file and creating a `pyaudio` object.\n\nWe will then use the `pyaudio` object to open a stream with specifications extracted from the wave file. Next, we\u2019ll create a data object that reads the frames of the wave file in the specified chunk size. To actually play the sound, we\u2019ll loop through the data file and write it to the stream while it is not an empty bit. Finally, we\u2019ll close the stream and terminate the `pyaudio` object.\n\n```py\nimport pyaudio\nimport wave\n\n# declare constants and initialize portaudio/pyaudio object\nfilename = \'output_pyaudio.wav\'\nchunk = 1024\nwf = wave.open(filename, \'rb\')\npa = pyaudio.PyAudio()\n\n# create stream using info from the file\nstream = pa.open(format = pa.get_format_from_width(wf.getsampwidth()),\n                channels = wf.getnchannels(),\n                rate = wf.getframerate(),\n                output = True)\n\n# read in the frames as data\ndata = wf.readframes(chunk)\n\n# while the data isn\'t empty\nwhile data != b\'\':\n    stream.write(data)\n    data = wf.readframes(chunk)\n\n# cleanup\nstream.close()\npa.terminate()\n```\n\n### Play Audio With Python-sounddevice\n\nOnce again, we see the simplification of playing audio that `sounddevice` offers over `pyaudio`. Remember that both the playing and recording simplifications also come with the need to install and use two extra libraries though.\n\nFor this example, we will import the `sounddevice` and `soundfile` libraries. Then, we will feed the filename to `soundfile` to `read` us the data and the sampling rate. Finally, we use `sounddevice` to `play` the resulting sound and make the process wait while the sound finishes playing.\n\n```py\nimport sounddevice\nimport soundfile\n\nfilename = "output_sounddevice.wav"\ndata, fs = soundfile.read(filename, dtype=\'float32\')\nsounddevice.play(data, fs)\nstatus = sounddevice.wait()\n```\n\n## Clipping Audio Data With Python\n\nNow that we\u2019ve covered the simplest acts of playing and recording audio, let\u2019s move onto how to change the audio data. The first thing we\u2019ll cover is clipping or trimming audio data. For this example, we\u2019ll need to install two more libraries, `pydub` and `ffmpeg-python`. We can install these with pip in the command line as usual using `pip install pydub ffmpeg-python`.\n\n### Clip Audio With Pydub\n\nAs we will see here and further down the post, the `pydub` library is a swiss army knife of audio manipulation tools. To trim audio data with `pydub`, we only need the `AudioSegment` object. To start, we\u2019ll define the first and last milliseconds we want to clip out. Then, we\u2019ll load the audio file with `AudioSegment`.\n\nTo clip our audio file down, we\u2019ll create a list that only contains the data from the start to the end millisecond in our audio file. Finally, we\u2019ll use the `export` function of the `AudioSegment` object we extracted to save the file in `.wav` format.\n\n```py\nfrom pydub import AudioSegment\n\n# start at 0 milliseconds\n# end at 1500 milliseconds\nstart = 0\nend = 1500\n\nsound = AudioSegment.from_wav("output_pyaudio.wav")\nextract = sound[start:end]\n\nextract.export("trimmed_output_pydub.wav", format="wav")\n```\n\n### Trim Audio Clips With FFMPEG\n\nFFMPEG is a well known audio manipulation library, usually used in the command line. You can use the `sys` and `subprocess` libraries that are native to Python to use FFMPEG, but I find that using the SDK is easier and more satisfying.\n\nEven though we had to install this SDK with `pip install ffmpeg-python`, we actually import it as just `ffmpeg`. The first thing we\u2019ll do is get an input object. Then, we\u2019ll use the `ffmpeg.input` object to call the `atrim` function and trim the recording down to 1 second. Next, we\u2019ll create an output using the newly cut data. Finally, we\u2019ll need to call `ffmpeg` to actually run the `output` call and save our file.\n\n```py\nimport ffmpeg\n\naudio_input = ffmpeg.input("output_sounddevice.wav")\naudio_cut = audio_input.audio.filter(\'atrim\', duration=1)\naudio_output = ffmpeg.output(audio_cut, \'trimmed_output_ffmpeg.wav\', format=\'wav\')\nffmpeg.run(audio_output)\n```\n\n## Manipulating Audio Data Sampling Rates With Python\n\nHere\u2019s where things get a bit trickier. Sampling rates play a huge part in how audio data sounds. When you\u2019re changing the number of frames per second that represents a sound, a lot of funky things can happen. If not done right, it can affect the speed, the pitch, and the quality of your sound. For our examples, we\u2019ll be using `pydub` and `scipy`. Both libraries we already downloaded earlier.\n\n![Sample Rate Change in Audio File](https://res.cloudinary.com/deepgram/image/upload/v1654876364/blog/2022/06/best-python-audio-manipulation-tools/sample-rate.png)\n\n### Pydub\n\nAs mentioned above, `pydub` has a variety of tools for manipulating audio data, and changing the sample rate safely is one of them. The `AudioSegment` object has a wonderful `set_frame_rate` command that can be used to set the frame rate of the audio segment without changing the pitch, speed, or applying any other distortions. To save it, we will use the `export` function again.\n\n```py\nfrom pydub import AudioSegment\n\nsound = AudioSegment.from_wav(\'output_pyaudio.wav\')\nsound_w_new_fs = sound.set_frame_rate(16000)\nsound_w_new_fs.export("new_fs_output_pydub.wav", format="wav")\n```\n\n### Scipy\n\nIf you are so inclined and also mathematically skilled, you can apply your own sampling rate change with `scipy`. The most popular reasons to use `scipy` to customize your sampling is for advanced use cases like research, music, or special effects.\n\nRead in the sample rate and audio data using `wavfile`. Using the read-in sample rate and a desired new sample rate, create a new number of samples. To do the resampling, we call on the `resample` function from `scipy.signal`. This resample function applies a fourier transform and may cause distortion. This is a much more advanced technique and should probably only be used if necessary.\n\n```py\nfrom scipy.io import wavfile\nimport scipy.signal\n\nnew_fs = 88200\n# open data\nsample_rate, data = wavfile.read(\'output_pyaudio.wav\')\n\n# resample data\nnew_num_samples = round(len(data)*float(new_fs)/sample_rate)\ndata = scipy.signal.resample(data, new_num_samples)\nwavfile.write(filename="new_fs_output_scipy.wav", rate=88200, data=data)\n```\n\n## Changing Volume of Audio Data with Python\n\nThe next four things we\u2019re going to cover all use `pydub`. Partially because it is the easiest to use, partially because it is the only one that is updated enough to work with the latest versions of Python.\n\nChanging volume with the `AudioSegment` object from `pydub` is extremely easy. After importing the libraries and functions we need and opening up the `.wav` file, the only thing we need to do is add or subtract from the object representing the open `.wav` file.\n\nThe `play` function plays both sounds, one after the other, so that we can hear that one is louder and the other is softer. We can save the files using the `export` function as we have been doing so far.\n\n```py\nfrom pydub import AudioSegment\nfrom pydub.playback import play\n\nsound = AudioSegment.from_wav("new_fs_output_pydub.wav")\n\n# 3 dB up\nlouder = sound + 3\n# 3 dB down\nquieter = sound - 3\n\nplay(louder)\nplay(quieter)\n\nlouder.export("louder_output.wav", format="wav")\nquieter.export("quieter_output.wav", format="wav")\n```\n\n## Combining Two Audio Files With Python\n\nWe can also use `pydub` to combine two audio data files in Python. Once we open up the `.wav` files with `AudioSegment`, all we have to do to append them is add them. We can play the sound to make sure we got it and then export it into a file.\n\n```py\nfrom pydub import AudioSegment\nfrom pydub.playback import play\n\nsound1 = AudioSegment.from_wav("louder_output.wav")\nsound2 = AudioSegment.from_wav("quieter_output.wav")\n\ncombined = sound1 + sound2\n\nplay(combined)\ncombined.export("louder_and_quieter.wav", format="wav")\n```\n\n## Overlay Two Audio Files With Python\n\nYou\u2019d think that overlaying audio data would be harder than combining them, but the `AudioSegment` object from the `pydub` library makes it quite easy. All we do is call the `overlay` function and pass it the sound we want to overlay and the position (in milliseconds) we want to overlay it at.\n\n```py\nfrom pydub import AudioSegment\nfrom pydub.playback import play\n\nsound1 = AudioSegment.from_wav("louder_output.wav")\nsound2 = AudioSegment.from_wav("quieter_output.wav")\n\noverlay = sound1.overlay(sound2, position=1000)\n\nplay(overlay)\noverlay.export("overlaid_1sec_offset.wav", format="wav")\n```\n\n## Changing Audio Data File Formats With Python\n\nWe\u2019ve covered a lot of ways to manipulate audio data in Python from the basic playing and recording to overlaying different sounds. What if we just need our audio file in a different format? We can also use `pydub` to convert audio formats.\n\nThe `AudioSegment` object\u2019s `export` function that we\u2019ve been using in the sections above has the capability to define the output object\u2019s format. All we have to do to save it as a different format is pass that format to the `export` function. In the example below, I\u2019ve opened up a `.wav` file and saved it as a `.mp3`.\n\n```py\nfrom pydub import AudioSegment\n\nwav_audio = AudioSegment.from_wav("louder_output.wav")\nmp3_audio = wav_audio.export("louder.mp3", format="mp3")\n```\n\n## Transcribe Audio Data With a Web API\n\nFinally, we come to the last bit of audio data manipulation to be covered in this primer to audio data in Python. Having the transcription of an audio file can be useful for many reasons. You can use it to [visualize your data](https://blog.deepgram.com/python-graphing-transcripts/), [search for keywords from a library of audio files](https://blog.deepgram.com/python-script-compliance/), or get inputs for Natural Language Understanding (NLU) models.\n\nTo transcribe your audio with a Web API, you\u2019ll need to sign up for a [free Deepgram API key](https://console.deepgram.com/signup?jump=keys) and run `pip install deepgram-sdk` in your terminal.\n\nWe\u2019ll be using `asyncio` to asynchronously make the API request. Before we create our function, we need to make sure that we have the API key and the file name. The function will initialize the Deepgram SDK, open the local file, and send it to the transcription endpoint. Then it will wait for the response and dump it into a JSON file formatted with a tab of 4 spaces. We will then both print the JSON result to the terminal and save it as a `.txt` file. Finally, we\u2019ll use `asyncio` to run the function.\n\n```py\nfrom deepgram import Deepgram\nfrom config import dg_secret_key\nimport asyncio, json\n\nDEEPGRAM_API_KEY = dg_secret_key\nPATH_TO_FILE = \'louder_output.wav\'\n\nasync def main():\n    # Initializes the Deepgram SDK\n    deepgram = Deepgram(DEEPGRAM_API_KEY)\n    # Open the audio file\n    with open(PATH_TO_FILE, \'rb\') as audio:\n        # ...or replace mimetype as appropriate\n        source = {\'buffer\': audio, \'mimetype\': \'audio/wav\'}\n        response = await deepgram.transcription.prerecorded(source, {\'punctuate\': True})\n        json_obj = json.dumps(response, indent=4)\n        print(json_obj)\n        with open("transcribed.txt", "w") as f:\n            f.write(json_obj)\n\nasyncio.run(main())\n```\n\n## Summary of the Best Python Tools for Manipulating Audio Data\n\nAudio data covers a large swath of data that isn\u2019t commonly thought about when it comes to data analysis and manipulation. In this post, we covered how to use some of the most up-to-date Python libraries for manipulating audio data.\n\nWe learned how to play and record audio data using `pyaudio` and `python-sounddevice`. How to trim data with `pydub` and `ffmpeg`, and how to resample data with `pydub` and `scipy`. Then we saw how we can use `pydub` as a swiss army knife of audio to change the volume, combine or overlay files, and change the file format. Finally, we saw how we can easily use the Deepgram SDK to transcribe audio data.\n\n## Further Reading\n\n*   [Lecture Notes on Audio Data from Penn](https://www.ling.upenn.edu/courses/Spring_2003/ling538/Lecnotes/AudioData.html)\n*   [Audio File Formats](https://en.wikipedia.org/wiki/Audio_file_format)\n\n        ', "html": '<p>Python provides us with many packages to manipulate audio data, but they don\u2019t all work. As Python developers, we\u2019re all familiar with the usual challenges - solving environments, compatibility between versions, and finding the right packages. This post covers how to do all of that for working with audio data. You can find a <a href="https://github.com/deepgram-devs/basic_audio_data_manip">GitHub repo here</a> with all the samples discussed below.</p>\n<p>Note that this post is written using Python 3.9 as many audio packages have not yet been upgraded to work with 3.10 or 3.11. In this post we\u2019ll cover:</p>\n<ul>\n<li><a href="#an-introduction-to-audio-data">An Introduction to Audio Data</a></li>\n<li><a href="#ways-to-use-audio-data">Ways To Use Audio Data</a></li>\n<li><a href="#recording-audio-data-with-python">Recording Audio Data With Python</a></li>\n<li><a href="#playing-audio-data-with-python">Playing Audio Data With Python</a></li>\n<li><a href="#clipping-audio-data-with-python">Clipping Audio Data With Python</a></li>\n<li><a href="#manipulating-audio-data-sampling-rates-with-python">Manipulating Audio Data Sampling Rates With Python</a></li>\n<li><a href="#changing-volume-of-audio-data-with-python">Changing Volume of Audio Data With Python</a></li>\n<li><a href="#combining-two-audio-files-with-python">Combining Two Audio Files With Python</a></li>\n<li><a href="#overlay-two-audio-files-with-python">Overlay Two Audio Files With Python</a></li>\n<li><a href="#changing-audio-data-file-formats-with-python">Changing Audio Data File Formats With Python</a></li>\n<li><a href="#transcribe-audio-data-with-a-web-api">Transcribe Audio Data With a Web API</a></li>\n<li><a href="#summary-of-the-best-python-tools-for-manipulating-audio-data">Summary of the Best Python Tools for Manipulating Audio Data</a></li>\n</ul>\n<h2 id="an-introduction-to-audio-data">An Introduction to Audio Data</h2>\n<p>What is audio data? Simply put, audio data is any data format that comes in the form of audio. At a fundamental level, there are not many ways to represent sound. The large number of audio data file types is due to the number of approaches to compress and package the data. Let\u2019s take a look at two fundamental concepts before we jump deeper - sampling rates and types of audio data formats.</p>\n<h3 id="what-is-a-sampling-rate">What Is a Sampling Rate?</h3>\n<p>A sampling rate, sometimes also referred to as a frame rate, is the number of times per second that we measure the amplitude of the signal. It is measured in frames per second or Hertz (Hz). An ideal rate can be determined using <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Nyquist\u2019s Sampling Theorem</a>. Some common sampling rates are 16 kHz (common for VoiP), 44.1 kHz (common in CDs), and 96 kHz (common in DVDs and Blu-Ray).</p>\n<h3 id="types-of-audio-data">Types of Audio Data</h3>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654876366/blog/2022/06/best-python-audio-manipulation-tools/types-of-audio-data.png" alt=""></p>\n<p>There\u2019s one well known way to represent sound - using waves. However, computers can represent that data in many ways. The most common audio data file types are <code is:raw>.wav</code> and <code is:raw>.mp3</code>. The main difference between <code is:raw>.wav</code> and <code is:raw>.mp3</code> files is that <code is:raw>.wav</code> files are not compressed and <code is:raw>.mp3</code> files are. This makes <code is:raw>.wav</code> files great for when you need the highest quality audio and <code is:raw>.mp3</code> files best when you need fast streaming.</p>\n<p>Other file types include Audio Interchange File Format (AIFF), raw Pulse Code Modulation (PCM) data, and Advanced Audio Coding (AAC). AIFF is a file format developed by Apple to be used on Mac OS much like WAVE files were initially developed by Microsoft. PCM is the raw audio data format. AAC\u2019s were meant to be the successor to MP3 files, but did not catch on as a replay format. However, it did catch on as a popular streaming audio format and is used by YouTube, iPhones, and Nintendo.</p>\n<h2 id="ways-to-use-audio-data">Ways To Use Audio Data</h2>\n<p>Audio data is becoming more and more ubiquitous. It\u2019s created on phone calls, remote video meeting recordings, for music and videos, and so much more. How can we use all this audio data being created? We can layer sound bites for music, change the volume of different sound streams to make it easier to hear everyone from a VoiP call, or transcribe a call to read later. Of course, this only covers some of the things we can do with sound data, there are many other valuable ways to use audio that we haven\u2019t even discovered.</p>\n<h2 id="recording-audio-data-with-python">Recording Audio Data With Python</h2>\n<p>Two of the most basic things you can do with audio data in Python are playing and recording audio. In the next two sections we\u2019ll cover how to use two popular Python sound libraries to play and record audio data. First, we\u2019ll take a look at how to record audio data with <code is:raw>sounddevice</code> and <code is:raw>pyaudio</code>.</p>\n<p>Before we get started with the code, we\u2019ll have to install the prerequisite libraries. PyAudio is a wrapper around PortAudio. The installation will be different for Windows and Mac. On Mac OS, you can use <code is:raw>brew</code> to install <code is:raw>portaudio</code> after installing your X-Code tools. For Windows, see <a href="https://stackoverflow.com/questions/52283840/i-cant-install-pyaudio-on-windows-how-to-solve-error-microsoft-visual-c-14/52284344#52284344">this answer on StackOverflow</a>.</p>\n<p>How to Install PyAudio (on Mac):</p>\n<p>xcode-select \u2014install\nbrew remove portaudio\nbrew install portaudio\npip install pyaudio</p>\n<p>If you are having trouble, use this command instead to specify your build locations for portaudio:</p>\n<p>pip install \u2014global-option=\u2018build_ext\u2019 \u2014global-option=\u201C-I$(brew \u2014prefix)/include\u201D \u2014global-option=\u201C-L$(brew \u2014prefix)/lib\u201D pyaudio</p>\n<p>To install <code is:raw>python-sounddevice</code>, run the line <code is:raw>pip install sounddevice scipy</code> in the command line. We will need <code is:raw>scipy</code> for downloading the streamed data and for later use.</p>\n<h3 id="use-pyaudio-to-record-sound">Use PyAudio To Record Sound</h3>\n<p>In this example, we\u2019re going to use PyAudio and the Python native <code is:raw>wave</code> library to record some sound and save it into a file. We\u2019ll start by importing the two libraries and declaring constants. The constants we need to declare up front are the chunk size (the number of frames saved at a time), the format (16 bit), the number of channels (1), the sampling rate (44100), the length of our recording (3 seconds), and the filename we want to save our recording to.</p>\n<p>From there, we create a PyAudio object. We\u2019ll use the PyAudio object to create a stream with the constants we set above. Then, we\u2019ll initialize an empty list of frames to hold the frames. Next, we\u2019ll use the stream to read data while we still have time left in our 3 second timeframe and save it in the chunk size of 1024 bits.</p>\n<p>We need to close and terminate our stream after 3 seconds. Finally, we\u2019ll use the <code is:raw>wave</code> library to save the streamed audio data into a <code is:raw>.wav</code> file with the preset constants we declared above.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wave</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_format </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pyaudio.paInt16</span></span>\n<span class="line"><span style="color: #C9D1D9">channels </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span></span>\n<span class="line"><span style="color: #C9D1D9">fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">44100</span><span style="color: #C9D1D9"> </span><span style="color: #8B949E"># frames per channel</span></span>\n<span class="line"><span style="color: #C9D1D9">seconds </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;output_pyaudio.wav&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">p</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">pyaudio.PyAudio()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Recording ...&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">stream </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.open(</span><span style="color: #FFA657">format</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_format,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">channels</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> channels,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">rate</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> fs,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">frames_per_buffer</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">  chunk,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">input</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(fs</span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> seconds)):</span></span>\n<span class="line"><span style="color: #C9D1D9">    data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stream.read(chunk)</span></span>\n<span class="line"><span style="color: #C9D1D9">    frames.append(data)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">stream.stop_stream()</span></span>\n<span class="line"><span style="color: #C9D1D9">stream.close()</span></span>\n<span class="line"><span style="color: #C9D1D9">p.terminate()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;... Ending Recording&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> wave.open(filename, </span><span style="color: #A5D6FF">&#39;wb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> wf:</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.setnchannels(channels)</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.setsampwidth(p.get_sample_size(sample_format))</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.setframerate(fs)</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.writeframes(</span><span style="color: #FF7B72">b</span><span style="color: #A5D6FF">&#39;&#39;</span><span style="color: #C9D1D9">.join(frames))</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.close()</span></span></code></pre>\n<h3 id="record-with-python-sounddevice">Record With Python-Sounddevice</h3>\n<p>Python-Sounddevice, or just <code is:raw>sounddevice</code> when you import it or install it through <code is:raw>pip</code>, is a simple sound recording and playing library. We can see below that it takes much less code to simply make a recording than <code is:raw>pyaudio</code>.</p>\n<p>First, we import the libraries we need, <code is:raw>sounddevice</code> and the <code is:raw>write</code> function from <code is:raw>scipy.io.wavfile</code>. Next, we declare a couple constants for the sampling rate and the length of recording. Once we have those, we just record, ask <code is:raw>sounddevice</code> to wait, and then use <code is:raw>scipy</code> to write the recorded audio.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> sounddevice </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> sd</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> scipy.io.wavfile </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> write</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">44100</span></span>\n<span class="line"><span style="color: #C9D1D9">seconds </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">recording </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sd.rec(</span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(seconds</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">fs), </span><span style="color: #FFA657">samplerate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">fs, </span><span style="color: #FFA657">channels</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sd.wait()</span></span>\n<span class="line"><span style="color: #C9D1D9">write(</span><span style="color: #A5D6FF">&#39;output_sounddevice.wav&#39;</span><span style="color: #C9D1D9">, fs, recording)</span></span></code></pre>\n<h2 id="playing-audio-data-with-python">Playing Audio Data With Python</h2>\n<p>Playing audio data is the sister function to recording audio data. Only being able to record data would be almost useless. For this section, we\u2019re going to use the same libraries we did above, <code is:raw>pyaudio</code>, and <code is:raw>sounddevice</code>. However, we will also need one more library for using <code is:raw>sounddevice</code> to play audio data, <code is:raw>soundfile</code>. We need to run this command in the terminal: <code is:raw>pip install soundfile</code> to install it.</p>\n<h3 id="use-pyaudio-to-play-audio">Use Pyaudio To Play Audio</h3>\n<p>Once again, we\u2019ll use the built-in <code is:raw>wave</code> library along with <code is:raw>pyaudio</code> to play some sound. We\u2019ll use the recording we made above and the same chunk size. We will start our functionality by opening the file and creating a <code is:raw>pyaudio</code> object.</p>\n<p>We will then use the <code is:raw>pyaudio</code> object to open a stream with specifications extracted from the wave file. Next, we\u2019ll create a data object that reads the frames of the wave file in the specified chunk size. To actually play the sound, we\u2019ll loop through the data file and write it to the stream while it is not an empty bit. Finally, we\u2019ll close the stream and terminate the <code is:raw>pyaudio</code> object.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wave</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># declare constants and initialize portaudio/pyaudio object</span></span>\n<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span></span>\n<span class="line"><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>\n<span class="line"><span style="color: #C9D1D9">wf </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wave.open(filename, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">pa </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pyaudio.PyAudio()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># create stream using info from the file</span></span>\n<span class="line"><span style="color: #C9D1D9">stream </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pa.open(</span><span style="color: #FFA657">format</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pa.get_format_from_width(wf.getsampwidth()),</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">channels</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.getnchannels(),</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">rate</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.getframerate(),</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">output</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># read in the frames as data</span></span>\n<span class="line"><span style="color: #C9D1D9">data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.readframes(chunk)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># while the data isn&#39;t empty</span></span>\n<span class="line"><span style="color: #FF7B72">while</span><span style="color: #C9D1D9"> data </span><span style="color: #FF7B72">!=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">b</span><span style="color: #A5D6FF">&#39;&#39;</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">    stream.write(data)</span></span>\n<span class="line"><span style="color: #C9D1D9">    data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.readframes(chunk)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># cleanup</span></span>\n<span class="line"><span style="color: #C9D1D9">stream.close()</span></span>\n<span class="line"><span style="color: #C9D1D9">pa.terminate()</span></span></code></pre>\n<h3 id="play-audio-with-python-sounddevice">Play Audio With Python-sounddevice</h3>\n<p>Once again, we see the simplification of playing audio that <code is:raw>sounddevice</code> offers over <code is:raw>pyaudio</code>. Remember that both the playing and recording simplifications also come with the need to install and use two extra libraries though.</p>\n<p>For this example, we will import the <code is:raw>sounddevice</code> and <code is:raw>soundfile</code> libraries. Then, we will feed the filename to <code is:raw>soundfile</code> to <code is:raw>read</code> us the data and the sampling rate. Finally, we use <code is:raw>sounddevice</code> to <code is:raw>play</code> the resulting sound and make the process wait while the sound finishes playing.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> sounddevice</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> soundfile</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;output_sounddevice.wav&quot;</span></span>\n<span class="line"><span style="color: #C9D1D9">data, fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> soundfile.read(filename, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;float32&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sounddevice.play(data, fs)</span></span>\n<span class="line"><span style="color: #C9D1D9">status </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sounddevice.wait()</span></span></code></pre>\n<h2 id="clipping-audio-data-with-python">Clipping Audio Data With Python</h2>\n<p>Now that we\u2019ve covered the simplest acts of playing and recording audio, let\u2019s move onto how to change the audio data. The first thing we\u2019ll cover is clipping or trimming audio data. For this example, we\u2019ll need to install two more libraries, <code is:raw>pydub</code> and <code is:raw>ffmpeg-python</code>. We can install these with pip in the command line as usual using <code is:raw>pip install pydub ffmpeg-python</code>.</p>\n<h3 id="clip-audio-with-pydub">Clip Audio With Pydub</h3>\n<p>As we will see here and further down the post, the <code is:raw>pydub</code> library is a swiss army knife of audio manipulation tools. To trim audio data with <code is:raw>pydub</code>, we only need the <code is:raw>AudioSegment</code> object. To start, we\u2019ll define the first and last milliseconds we want to clip out. Then, we\u2019ll load the audio file with <code is:raw>AudioSegment</code>.</p>\n<p>To clip our audio file down, we\u2019ll create a list that only contains the data from the start to the end millisecond in our audio file. Finally, we\u2019ll use the <code is:raw>export</code> function of the <code is:raw>AudioSegment</code> object we extracted to save the file in <code is:raw>.wav</code> format.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># start at 0 milliseconds</span></span>\n<span class="line"><span style="color: #8B949E"># end at 1500 milliseconds</span></span>\n<span class="line"><span style="color: #C9D1D9">start </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>\n<span class="line"><span style="color: #C9D1D9">end </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1500</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;output_pyaudio.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">extract </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound[start:end]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">extract.export(</span><span style="color: #A5D6FF">&quot;trimmed_output_pydub.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h3 id="trim-audio-clips-with-ffmpeg">Trim Audio Clips With FFMPEG</h3>\n<p>FFMPEG is a well known audio manipulation library, usually used in the command line. You can use the <code is:raw>sys</code> and <code is:raw>subprocess</code> libraries that are native to Python to use FFMPEG, but I find that using the SDK is easier and more satisfying.</p>\n<p>Even though we had to install this SDK with <code is:raw>pip install ffmpeg-python</code>, we actually import it as just <code is:raw>ffmpeg</code>. The first thing we\u2019ll do is get an input object. Then, we\u2019ll use the <code is:raw>ffmpeg.input</code> object to call the <code is:raw>atrim</code> function and trim the recording down to 1 second. Next, we\u2019ll create an output using the newly cut data. Finally, we\u2019ll need to call <code is:raw>ffmpeg</code> to actually run the <code is:raw>output</code> call and save our file.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> ffmpeg</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">audio_input </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ffmpeg.input(</span><span style="color: #A5D6FF">&quot;output_sounddevice.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">audio_cut </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> audio_input.audio.filter(</span><span style="color: #A5D6FF">&#39;atrim&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">duration</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">audio_output </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ffmpeg.output(audio_cut, </span><span style="color: #A5D6FF">&#39;trimmed_output_ffmpeg.wav&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;wav&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">ffmpeg.run(audio_output)</span></span></code></pre>\n<h2 id="manipulating-audio-data-sampling-rates-with-python">Manipulating Audio Data Sampling Rates With Python</h2>\n<p>Here\u2019s where things get a bit trickier. Sampling rates play a huge part in how audio data sounds. When you\u2019re changing the number of frames per second that represents a sound, a lot of funky things can happen. If not done right, it can affect the speed, the pitch, and the quality of your sound. For our examples, we\u2019ll be using <code is:raw>pydub</code> and <code is:raw>scipy</code>. Both libraries we already downloaded earlier.</p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654876364/blog/2022/06/best-python-audio-manipulation-tools/sample-rate.png" alt="Sample Rate Change in Audio File"></p>\n<h3 id="pydub">Pydub</h3>\n<p>As mentioned above, <code is:raw>pydub</code> has a variety of tools for manipulating audio data, and changing the sample rate safely is one of them. The <code is:raw>AudioSegment</code> object has a wonderful <code is:raw>set_frame_rate</code> command that can be used to set the frame rate of the audio segment without changing the pitch, speed, or applying any other distortions. To save it, we will use the <code is:raw>export</code> function again.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound_w_new_fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound.set_frame_rate(</span><span style="color: #79C0FF">16000</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound_w_new_fs.export(</span><span style="color: #A5D6FF">&quot;new_fs_output_pydub.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h3 id="scipy">Scipy</h3>\n<p>If you are so inclined and also mathematically skilled, you can apply your own sampling rate change with <code is:raw>scipy</code>. The most popular reasons to use <code is:raw>scipy</code> to customize your sampling is for advanced use cases like research, music, or special effects.</p>\n<p>Read in the sample rate and audio data using <code is:raw>wavfile</code>. Using the read-in sample rate and a desired new sample rate, create a new number of samples. To do the resampling, we call on the <code is:raw>resample</code> function from <code is:raw>scipy.signal</code>. This resample function applies a fourier transform and may cause distortion. This is a much more advanced technique and should probably only be used if necessary.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> scipy.io </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wavfile</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> scipy.signal</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">new_fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">88200</span></span>\n<span class="line"><span style="color: #8B949E"># open data</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_rate, data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wavfile.read(</span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># resample data</span></span>\n<span class="line"><span style="color: #C9D1D9">new_num_samples </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">round</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">len</span><span style="color: #C9D1D9">(data)</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">float</span><span style="color: #C9D1D9">(new_fs)</span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> scipy.signal.resample(data, new_num_samples)</span></span>\n<span class="line"><span style="color: #C9D1D9">wavfile.write(</span><span style="color: #FFA657">filename</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;new_fs_output_scipy.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">88200</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">data</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">data)</span></span></code></pre>\n<h2 id="changing-volume-of-audio-data-with-python">Changing Volume of Audio Data with Python</h2>\n<p>The next four things we\u2019re going to cover all use <code is:raw>pydub</code>. Partially because it is the easiest to use, partially because it is the only one that is updated enough to work with the latest versions of Python.</p>\n<p>Changing volume with the <code is:raw>AudioSegment</code> object from <code is:raw>pydub</code> is extremely easy. After importing the libraries and functions we need and opening up the <code is:raw>.wav</code> file, the only thing we need to do is add or subtract from the object representing the open <code is:raw>.wav</code> file.</p>\n<p>The <code is:raw>play</code> function plays both sounds, one after the other, so that we can hear that one is louder and the other is softer. We can save the files using the <code is:raw>export</code> function as we have been doing so far.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;new_fs_output_pydub.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># 3 dB up</span></span>\n<span class="line"><span style="color: #C9D1D9">louder </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"><span style="color: #8B949E"># 3 dB down</span></span>\n<span class="line"><span style="color: #C9D1D9">quieter </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">play(louder)</span></span>\n<span class="line"><span style="color: #C9D1D9">play(quieter)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">louder.export(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">quieter.export(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="combining-two-audio-files-with-python">Combining Two Audio Files With Python</h2>\n<p>We can also use <code is:raw>pydub</code> to combine two audio data files in Python. Once we open up the <code is:raw>.wav</code> files with <code is:raw>AudioSegment</code>, all we have to do to append them is add them. We can play the sound to make sure we got it and then export it into a file.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">combined </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound1 </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> sound2</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">play(combined)</span></span>\n<span class="line"><span style="color: #C9D1D9">combined.export(</span><span style="color: #A5D6FF">&quot;louder_and_quieter.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="overlay-two-audio-files-with-python">Overlay Two Audio Files With Python</h2>\n<p>You\u2019d think that overlaying audio data would be harder than combining them, but the <code is:raw>AudioSegment</code> object from the <code is:raw>pydub</code> library makes it quite easy. All we do is call the <code is:raw>overlay</code> function and pass it the sound we want to overlay and the position (in milliseconds) we want to overlay it at.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">overlay </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound1.overlay(sound2, </span><span style="color: #FFA657">position</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">play(overlay)</span></span>\n<span class="line"><span style="color: #C9D1D9">overlay.export(</span><span style="color: #A5D6FF">&quot;overlaid_1sec_offset.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="changing-audio-data-file-formats-with-python">Changing Audio Data File Formats With Python</h2>\n<p>We\u2019ve covered a lot of ways to manipulate audio data in Python from the basic playing and recording to overlaying different sounds. What if we just need our audio file in a different format? We can also use <code is:raw>pydub</code> to convert audio formats.</p>\n<p>The <code is:raw>AudioSegment</code> object\u2019s <code is:raw>export</code> function that we\u2019ve been using in the sections above has the capability to define the output object\u2019s format. All we have to do to save it as a different format is pass that format to the <code is:raw>export</code> function. In the example below, I\u2019ve opened up a <code is:raw>.wav</code> file and saved it as a <code is:raw>.mp3</code>.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">wav_audio </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">mp3_audio </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wav_audio.export(</span><span style="color: #A5D6FF">&quot;louder.mp3&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;mp3&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="transcribe-audio-data-with-a-web-api">Transcribe Audio Data With a Web API</h2>\n<p>Finally, we come to the last bit of audio data manipulation to be covered in this primer to audio data in Python. Having the transcription of an audio file can be useful for many reasons. You can use it to <a href="https://blog.deepgram.com/python-graphing-transcripts/">visualize your data</a>, <a href="https://blog.deepgram.com/python-script-compliance/">search for keywords from a library of audio files</a>, or get inputs for Natural Language Understanding (NLU) models.</p>\n<p>To transcribe your audio with a Web API, you\u2019ll need to sign up for a <a href="https://console.deepgram.com/signup?jump=keys">free Deepgram API key</a> and run <code is:raw>pip install deepgram-sdk</code> in your terminal.</p>\n<p>We\u2019ll be using <code is:raw>asyncio</code> to asynchronously make the API request. Before we create our function, we need to make sure that we have the API key and the file name. The function will initialize the Deepgram SDK, open the local file, and send it to the transcription endpoint. Then it will wait for the response and dump it into a JSON file formatted with a tab of 4 spaces. We will then both print the JSON result to the terminal and save it as a <code is:raw>.txt</code> file. Finally, we\u2019ll use <code is:raw>asyncio</code> to run the function.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> config </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> dg_secret_key</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio, json</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dg_secret_key</span></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;louder_output.wav&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">main</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">    deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(</span><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">        source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">        response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">})</span></span>\n<span class="line"><span style="color: #C9D1D9">        json_obj </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> json.dumps(response, </span><span style="color: #FFA657">indent</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(json_obj)</span></span>\n<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;transcribed.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>\n<span class="line"><span style="color: #C9D1D9">            f.write(json_obj)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(main())</span></span></code></pre>\n<h2 id="summary-of-the-best-python-tools-for-manipulating-audio-data">Summary of the Best Python Tools for Manipulating Audio Data</h2>\n<p>Audio data covers a large swath of data that isn\u2019t commonly thought about when it comes to data analysis and manipulation. In this post, we covered how to use some of the most up-to-date Python libraries for manipulating audio data.</p>\n<p>We learned how to play and record audio data using <code is:raw>pyaudio</code> and <code is:raw>python-sounddevice</code>. How to trim data with <code is:raw>pydub</code> and <code is:raw>ffmpeg</code>, and how to resample data with <code is:raw>pydub</code> and <code is:raw>scipy</code>. Then we saw how we can use <code is:raw>pydub</code> as a swiss army knife of audio to change the volume, combine or overlay files, and change the file format. Finally, we saw how we can easily use the Deepgram SDK to transcribe audio data.</p>\n<h2 id="further-reading">Further Reading</h2>\n<ul>\n<li>\n<p><a href="https://www.ling.upenn.edu/courses/Spring_2003/ling538/Lecnotes/AudioData.html">Lecture Notes on Audio Data from Penn</a></p>\n</li>\n<li>\n<p><a href="https://en.wikipedia.org/wiki/Audio_file_format">Audio File Formats</a></p>\n</li>\n</ul>' }, "file": "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/best-python-audio-manipulation-tools/index.md" };
function rawContent() {
  return '\nPython provides us with many packages to manipulate audio data, but they don\u2019t all work. As Python developers, we\u2019re all familiar with the usual challenges - solving environments, compatibility between versions, and finding the right packages. This post covers how to do all of that for working with audio data. You can find a [GitHub repo here](https://github.com/deepgram-devs/basic_audio_data_manip) with all the samples discussed below.\n\nNote that this post is written using Python 3.9 as many audio packages have not yet been upgraded to work with 3.10 or 3.11. In this post we\u2019ll cover:\n\n*   [An Introduction to Audio Data](#an-introduction-to-audio-data)\n*   [Ways To Use Audio Data](#ways-to-use-audio-data)\n*   [Recording Audio Data With Python](#recording-audio-data-with-python)\n*   [Playing Audio Data With Python](#playing-audio-data-with-python)\n*   [Clipping Audio Data With Python](#clipping-audio-data-with-python)\n*   [Manipulating Audio Data Sampling Rates With Python](#manipulating-audio-data-sampling-rates-with-python)\n*   [Changing Volume of Audio Data With Python](#changing-volume-of-audio-data-with-python)\n*   [Combining Two Audio Files With Python](#combining-two-audio-files-with-python)\n*   [Overlay Two Audio Files With Python](#overlay-two-audio-files-with-python)\n*   [Changing Audio Data File Formats With Python](#changing-audio-data-file-formats-with-python)\n*   [Transcribe Audio Data With a Web API](#transcribe-audio-data-with-a-web-api)\n*   [Summary of the Best Python Tools for Manipulating Audio Data](#summary-of-the-best-python-tools-for-manipulating-audio-data)\n\n## An Introduction to Audio Data\n\nWhat is audio data? Simply put, audio data is any data format that comes in the form of audio. At a fundamental level, there are not many ways to represent sound. The large number of audio data file types is due to the number of approaches to compress and package the data. Let\u2019s take a look at two fundamental concepts before we jump deeper - sampling rates and types of audio data formats.\n\n### What Is a Sampling Rate?\n\nA sampling rate, sometimes also referred to as a frame rate, is the number of times per second that we measure the amplitude of the signal. It is measured in frames per second or Hertz (Hz). An ideal rate can be determined using [Nyquist\u2019s Sampling Theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem). Some common sampling rates are 16 kHz (common for VoiP), 44.1 kHz (common in CDs), and 96 kHz (common in DVDs and Blu-Ray).\n\n### Types of Audio Data\n\n![](https://res.cloudinary.com/deepgram/image/upload/v1654876366/blog/2022/06/best-python-audio-manipulation-tools/types-of-audio-data.png)\n\nThere\u2019s one well known way to represent sound - using waves. However, computers can represent that data in many ways. The most common audio data file types are `.wav` and `.mp3`. The main difference between `.wav` and `.mp3` files is that `.wav` files are not compressed and `.mp3` files are. This makes `.wav` files great for when you need the highest quality audio and `.mp3` files best when you need fast streaming.\n\nOther file types include Audio Interchange File Format (AIFF), raw Pulse Code Modulation (PCM) data, and Advanced Audio Coding (AAC). AIFF is a file format developed by Apple to be used on Mac OS much like WAVE files were initially developed by Microsoft. PCM is the raw audio data format. AAC\u2019s were meant to be the successor to MP3 files, but did not catch on as a replay format. However, it did catch on as a popular streaming audio format and is used by YouTube, iPhones, and Nintendo.\n\n## Ways To Use Audio Data\n\nAudio data is becoming more and more ubiquitous. It\u2019s created on phone calls, remote video meeting recordings, for music and videos, and so much more. How can we use all this audio data being created? We can layer sound bites for music, change the volume of different sound streams to make it easier to hear everyone from a VoiP call, or transcribe a call to read later. Of course, this only covers some of the things we can do with sound data, there are many other valuable ways to use audio that we haven\u2019t even discovered.\n\n## Recording Audio Data With Python\n\nTwo of the most basic things you can do with audio data in Python are playing and recording audio. In the next two sections we\u2019ll cover how to use two popular Python sound libraries to play and record audio data. First, we\u2019ll take a look at how to record audio data with `sounddevice` and `pyaudio`.\n\nBefore we get started with the code, we\u2019ll have to install the prerequisite libraries. PyAudio is a wrapper around PortAudio. The installation will be different for Windows and Mac. On Mac OS, you can use `brew` to install `portaudio` after installing your X-Code tools. For Windows, see [this answer on StackOverflow](https://stackoverflow.com/questions/52283840/i-cant-install-pyaudio-on-windows-how-to-solve-error-microsoft-visual-c-14/52284344#52284344).\n\nHow to Install PyAudio (on Mac):\n\n    xcode-select --install\n    brew remove portaudio\n    brew install portaudio\n    pip install pyaudio\n\nIf you are having trouble, use this command instead to specify your build locations for portaudio:\n\n    pip install --global-option=\'build_ext\' --global-option="-I$(brew --prefix)/include" --global-option="-L$(brew --prefix)/lib" pyaudio\n\nTo install `python-sounddevice`, run the line `pip install sounddevice scipy` in the command line. We will need `scipy` for downloading the streamed data and for later use.\n\n### Use PyAudio To Record Sound\n\nIn this example, we\u2019re going to use PyAudio and the Python native `wave` library to record some sound and save it into a file. We\u2019ll start by importing the two libraries and declaring constants. The constants we need to declare up front are the chunk size (the number of frames saved at a time), the format (16 bit), the number of channels (1), the sampling rate (44100), the length of our recording (3 seconds), and the filename we want to save our recording to.\n\nFrom there, we create a PyAudio object. We\u2019ll use the PyAudio object to create a stream with the constants we set above. Then, we\u2019ll initialize an empty list of frames to hold the frames. Next, we\u2019ll use the stream to read data while we still have time left in our 3 second timeframe and save it in the chunk size of 1024 bits.\n\nWe need to close and terminate our stream after 3 seconds. Finally, we\u2019ll use the `wave` library to save the streamed audio data into a `.wav` file with the preset constants we declared above.\n\n```py\nimport pyaudio\nimport wave\n\nchunk = 1024\nsample_format = pyaudio.paInt16\nchannels = 1\nfs = 44100 # frames per channel\nseconds = 3\nfilename = "output_pyaudio.wav"\n\np=pyaudio.PyAudio()\n\nprint("Recording ...")\n\nstream = p.open(format = sample_format,\n                channels = channels,\n                rate = fs,\n                frames_per_buffer =  chunk,\n                input = True)\n\nframes = []\nfor i in range(0, int(fs/chunk * seconds)):\n    data = stream.read(chunk)\n    frames.append(data)\n\nstream.stop_stream()\nstream.close()\np.terminate()\n\nprint("... Ending Recording")\nwith wave.open(filename, \'wb\') as wf:\n    wf.setnchannels(channels)\n    wf.setsampwidth(p.get_sample_size(sample_format))\n    wf.setframerate(fs)\n    wf.writeframes(b\'\'.join(frames))\n    wf.close()\n```\n\n### Record With Python-Sounddevice\n\nPython-Sounddevice, or just `sounddevice` when you import it or install it through `pip`, is a simple sound recording and playing library. We can see below that it takes much less code to simply make a recording than `pyaudio`.\n\nFirst, we import the libraries we need, `sounddevice` and the `write` function from `scipy.io.wavfile`. Next, we declare a couple constants for the sampling rate and the length of recording. Once we have those, we just record, ask `sounddevice` to wait, and then use `scipy` to write the recorded audio.\n\n```py\nimport sounddevice as sd\nfrom scipy.io.wavfile import write\n\nfs = 44100\nseconds = 3\n\nrecording = sd.rec(int(seconds*fs), samplerate=fs, channels=1)\nsd.wait()\nwrite(\'output_sounddevice.wav\', fs, recording)\n```\n\n## Playing Audio Data With Python\n\nPlaying audio data is the sister function to recording audio data. Only being able to record data would be almost useless. For this section, we\u2019re going to use the same libraries we did above, `pyaudio`, and `sounddevice`. However, we will also need one more library for using `sounddevice` to play audio data, `soundfile`. We need to run this command in the terminal: `pip install soundfile` to install it.\n\n### Use Pyaudio To Play Audio\n\nOnce again, we\u2019ll use the built-in `wave` library along with `pyaudio` to play some sound. We\u2019ll use the recording we made above and the same chunk size. We will start our functionality by opening the file and creating a `pyaudio` object.\n\nWe will then use the `pyaudio` object to open a stream with specifications extracted from the wave file. Next, we\u2019ll create a data object that reads the frames of the wave file in the specified chunk size. To actually play the sound, we\u2019ll loop through the data file and write it to the stream while it is not an empty bit. Finally, we\u2019ll close the stream and terminate the `pyaudio` object.\n\n```py\nimport pyaudio\nimport wave\n\n# declare constants and initialize portaudio/pyaudio object\nfilename = \'output_pyaudio.wav\'\nchunk = 1024\nwf = wave.open(filename, \'rb\')\npa = pyaudio.PyAudio()\n\n# create stream using info from the file\nstream = pa.open(format = pa.get_format_from_width(wf.getsampwidth()),\n                channels = wf.getnchannels(),\n                rate = wf.getframerate(),\n                output = True)\n\n# read in the frames as data\ndata = wf.readframes(chunk)\n\n# while the data isn\'t empty\nwhile data != b\'\':\n    stream.write(data)\n    data = wf.readframes(chunk)\n\n# cleanup\nstream.close()\npa.terminate()\n```\n\n### Play Audio With Python-sounddevice\n\nOnce again, we see the simplification of playing audio that `sounddevice` offers over `pyaudio`. Remember that both the playing and recording simplifications also come with the need to install and use two extra libraries though.\n\nFor this example, we will import the `sounddevice` and `soundfile` libraries. Then, we will feed the filename to `soundfile` to `read` us the data and the sampling rate. Finally, we use `sounddevice` to `play` the resulting sound and make the process wait while the sound finishes playing.\n\n```py\nimport sounddevice\nimport soundfile\n\nfilename = "output_sounddevice.wav"\ndata, fs = soundfile.read(filename, dtype=\'float32\')\nsounddevice.play(data, fs)\nstatus = sounddevice.wait()\n```\n\n## Clipping Audio Data With Python\n\nNow that we\u2019ve covered the simplest acts of playing and recording audio, let\u2019s move onto how to change the audio data. The first thing we\u2019ll cover is clipping or trimming audio data. For this example, we\u2019ll need to install two more libraries, `pydub` and `ffmpeg-python`. We can install these with pip in the command line as usual using `pip install pydub ffmpeg-python`.\n\n### Clip Audio With Pydub\n\nAs we will see here and further down the post, the `pydub` library is a swiss army knife of audio manipulation tools. To trim audio data with `pydub`, we only need the `AudioSegment` object. To start, we\u2019ll define the first and last milliseconds we want to clip out. Then, we\u2019ll load the audio file with `AudioSegment`.\n\nTo clip our audio file down, we\u2019ll create a list that only contains the data from the start to the end millisecond in our audio file. Finally, we\u2019ll use the `export` function of the `AudioSegment` object we extracted to save the file in `.wav` format.\n\n```py\nfrom pydub import AudioSegment\n\n# start at 0 milliseconds\n# end at 1500 milliseconds\nstart = 0\nend = 1500\n\nsound = AudioSegment.from_wav("output_pyaudio.wav")\nextract = sound[start:end]\n\nextract.export("trimmed_output_pydub.wav", format="wav")\n```\n\n### Trim Audio Clips With FFMPEG\n\nFFMPEG is a well known audio manipulation library, usually used in the command line. You can use the `sys` and `subprocess` libraries that are native to Python to use FFMPEG, but I find that using the SDK is easier and more satisfying.\n\nEven though we had to install this SDK with `pip install ffmpeg-python`, we actually import it as just `ffmpeg`. The first thing we\u2019ll do is get an input object. Then, we\u2019ll use the `ffmpeg.input` object to call the `atrim` function and trim the recording down to 1 second. Next, we\u2019ll create an output using the newly cut data. Finally, we\u2019ll need to call `ffmpeg` to actually run the `output` call and save our file.\n\n```py\nimport ffmpeg\n\naudio_input = ffmpeg.input("output_sounddevice.wav")\naudio_cut = audio_input.audio.filter(\'atrim\', duration=1)\naudio_output = ffmpeg.output(audio_cut, \'trimmed_output_ffmpeg.wav\', format=\'wav\')\nffmpeg.run(audio_output)\n```\n\n## Manipulating Audio Data Sampling Rates With Python\n\nHere\u2019s where things get a bit trickier. Sampling rates play a huge part in how audio data sounds. When you\u2019re changing the number of frames per second that represents a sound, a lot of funky things can happen. If not done right, it can affect the speed, the pitch, and the quality of your sound. For our examples, we\u2019ll be using `pydub` and `scipy`. Both libraries we already downloaded earlier.\n\n![Sample Rate Change in Audio File](https://res.cloudinary.com/deepgram/image/upload/v1654876364/blog/2022/06/best-python-audio-manipulation-tools/sample-rate.png)\n\n### Pydub\n\nAs mentioned above, `pydub` has a variety of tools for manipulating audio data, and changing the sample rate safely is one of them. The `AudioSegment` object has a wonderful `set_frame_rate` command that can be used to set the frame rate of the audio segment without changing the pitch, speed, or applying any other distortions. To save it, we will use the `export` function again.\n\n```py\nfrom pydub import AudioSegment\n\nsound = AudioSegment.from_wav(\'output_pyaudio.wav\')\nsound_w_new_fs = sound.set_frame_rate(16000)\nsound_w_new_fs.export("new_fs_output_pydub.wav", format="wav")\n```\n\n### Scipy\n\nIf you are so inclined and also mathematically skilled, you can apply your own sampling rate change with `scipy`. The most popular reasons to use `scipy` to customize your sampling is for advanced use cases like research, music, or special effects.\n\nRead in the sample rate and audio data using `wavfile`. Using the read-in sample rate and a desired new sample rate, create a new number of samples. To do the resampling, we call on the `resample` function from `scipy.signal`. This resample function applies a fourier transform and may cause distortion. This is a much more advanced technique and should probably only be used if necessary.\n\n```py\nfrom scipy.io import wavfile\nimport scipy.signal\n\nnew_fs = 88200\n# open data\nsample_rate, data = wavfile.read(\'output_pyaudio.wav\')\n\n# resample data\nnew_num_samples = round(len(data)*float(new_fs)/sample_rate)\ndata = scipy.signal.resample(data, new_num_samples)\nwavfile.write(filename="new_fs_output_scipy.wav", rate=88200, data=data)\n```\n\n## Changing Volume of Audio Data with Python\n\nThe next four things we\u2019re going to cover all use `pydub`. Partially because it is the easiest to use, partially because it is the only one that is updated enough to work with the latest versions of Python.\n\nChanging volume with the `AudioSegment` object from `pydub` is extremely easy. After importing the libraries and functions we need and opening up the `.wav` file, the only thing we need to do is add or subtract from the object representing the open `.wav` file.\n\nThe `play` function plays both sounds, one after the other, so that we can hear that one is louder and the other is softer. We can save the files using the `export` function as we have been doing so far.\n\n```py\nfrom pydub import AudioSegment\nfrom pydub.playback import play\n\nsound = AudioSegment.from_wav("new_fs_output_pydub.wav")\n\n# 3 dB up\nlouder = sound + 3\n# 3 dB down\nquieter = sound - 3\n\nplay(louder)\nplay(quieter)\n\nlouder.export("louder_output.wav", format="wav")\nquieter.export("quieter_output.wav", format="wav")\n```\n\n## Combining Two Audio Files With Python\n\nWe can also use `pydub` to combine two audio data files in Python. Once we open up the `.wav` files with `AudioSegment`, all we have to do to append them is add them. We can play the sound to make sure we got it and then export it into a file.\n\n```py\nfrom pydub import AudioSegment\nfrom pydub.playback import play\n\nsound1 = AudioSegment.from_wav("louder_output.wav")\nsound2 = AudioSegment.from_wav("quieter_output.wav")\n\ncombined = sound1 + sound2\n\nplay(combined)\ncombined.export("louder_and_quieter.wav", format="wav")\n```\n\n## Overlay Two Audio Files With Python\n\nYou\u2019d think that overlaying audio data would be harder than combining them, but the `AudioSegment` object from the `pydub` library makes it quite easy. All we do is call the `overlay` function and pass it the sound we want to overlay and the position (in milliseconds) we want to overlay it at.\n\n```py\nfrom pydub import AudioSegment\nfrom pydub.playback import play\n\nsound1 = AudioSegment.from_wav("louder_output.wav")\nsound2 = AudioSegment.from_wav("quieter_output.wav")\n\noverlay = sound1.overlay(sound2, position=1000)\n\nplay(overlay)\noverlay.export("overlaid_1sec_offset.wav", format="wav")\n```\n\n## Changing Audio Data File Formats With Python\n\nWe\u2019ve covered a lot of ways to manipulate audio data in Python from the basic playing and recording to overlaying different sounds. What if we just need our audio file in a different format? We can also use `pydub` to convert audio formats.\n\nThe `AudioSegment` object\u2019s `export` function that we\u2019ve been using in the sections above has the capability to define the output object\u2019s format. All we have to do to save it as a different format is pass that format to the `export` function. In the example below, I\u2019ve opened up a `.wav` file and saved it as a `.mp3`.\n\n```py\nfrom pydub import AudioSegment\n\nwav_audio = AudioSegment.from_wav("louder_output.wav")\nmp3_audio = wav_audio.export("louder.mp3", format="mp3")\n```\n\n## Transcribe Audio Data With a Web API\n\nFinally, we come to the last bit of audio data manipulation to be covered in this primer to audio data in Python. Having the transcription of an audio file can be useful for many reasons. You can use it to [visualize your data](https://blog.deepgram.com/python-graphing-transcripts/), [search for keywords from a library of audio files](https://blog.deepgram.com/python-script-compliance/), or get inputs for Natural Language Understanding (NLU) models.\n\nTo transcribe your audio with a Web API, you\u2019ll need to sign up for a [free Deepgram API key](https://console.deepgram.com/signup?jump=keys) and run `pip install deepgram-sdk` in your terminal.\n\nWe\u2019ll be using `asyncio` to asynchronously make the API request. Before we create our function, we need to make sure that we have the API key and the file name. The function will initialize the Deepgram SDK, open the local file, and send it to the transcription endpoint. Then it will wait for the response and dump it into a JSON file formatted with a tab of 4 spaces. We will then both print the JSON result to the terminal and save it as a `.txt` file. Finally, we\u2019ll use `asyncio` to run the function.\n\n```py\nfrom deepgram import Deepgram\nfrom config import dg_secret_key\nimport asyncio, json\n\nDEEPGRAM_API_KEY = dg_secret_key\nPATH_TO_FILE = \'louder_output.wav\'\n\nasync def main():\n    # Initializes the Deepgram SDK\n    deepgram = Deepgram(DEEPGRAM_API_KEY)\n    # Open the audio file\n    with open(PATH_TO_FILE, \'rb\') as audio:\n        # ...or replace mimetype as appropriate\n        source = {\'buffer\': audio, \'mimetype\': \'audio/wav\'}\n        response = await deepgram.transcription.prerecorded(source, {\'punctuate\': True})\n        json_obj = json.dumps(response, indent=4)\n        print(json_obj)\n        with open("transcribed.txt", "w") as f:\n            f.write(json_obj)\n\nasyncio.run(main())\n```\n\n## Summary of the Best Python Tools for Manipulating Audio Data\n\nAudio data covers a large swath of data that isn\u2019t commonly thought about when it comes to data analysis and manipulation. In this post, we covered how to use some of the most up-to-date Python libraries for manipulating audio data.\n\nWe learned how to play and record audio data using `pyaudio` and `python-sounddevice`. How to trim data with `pydub` and `ffmpeg`, and how to resample data with `pydub` and `scipy`. Then we saw how we can use `pydub` as a swiss army knife of audio to change the volume, combine or overlay files, and change the file format. Finally, we saw how we can easily use the Deepgram SDK to transcribe audio data.\n\n## Further Reading\n\n*   [Lecture Notes on Audio Data from Penn](https://www.ling.upenn.edu/courses/Spring_2003/ling538/Lecnotes/AudioData.html)\n*   [Audio File Formats](https://en.wikipedia.org/wiki/Audio_file_format)\n\n        ';
}
function compiledContent() {
  return '<p>Python provides us with many packages to manipulate audio data, but they don\u2019t all work. As Python developers, we\u2019re all familiar with the usual challenges - solving environments, compatibility between versions, and finding the right packages. This post covers how to do all of that for working with audio data. You can find a <a href="https://github.com/deepgram-devs/basic_audio_data_manip">GitHub repo here</a> with all the samples discussed below.</p>\n<p>Note that this post is written using Python 3.9 as many audio packages have not yet been upgraded to work with 3.10 or 3.11. In this post we\u2019ll cover:</p>\n<ul>\n<li><a href="#an-introduction-to-audio-data">An Introduction to Audio Data</a></li>\n<li><a href="#ways-to-use-audio-data">Ways To Use Audio Data</a></li>\n<li><a href="#recording-audio-data-with-python">Recording Audio Data With Python</a></li>\n<li><a href="#playing-audio-data-with-python">Playing Audio Data With Python</a></li>\n<li><a href="#clipping-audio-data-with-python">Clipping Audio Data With Python</a></li>\n<li><a href="#manipulating-audio-data-sampling-rates-with-python">Manipulating Audio Data Sampling Rates With Python</a></li>\n<li><a href="#changing-volume-of-audio-data-with-python">Changing Volume of Audio Data With Python</a></li>\n<li><a href="#combining-two-audio-files-with-python">Combining Two Audio Files With Python</a></li>\n<li><a href="#overlay-two-audio-files-with-python">Overlay Two Audio Files With Python</a></li>\n<li><a href="#changing-audio-data-file-formats-with-python">Changing Audio Data File Formats With Python</a></li>\n<li><a href="#transcribe-audio-data-with-a-web-api">Transcribe Audio Data With a Web API</a></li>\n<li><a href="#summary-of-the-best-python-tools-for-manipulating-audio-data">Summary of the Best Python Tools for Manipulating Audio Data</a></li>\n</ul>\n<h2 id="an-introduction-to-audio-data">An Introduction to Audio Data</h2>\n<p>What is audio data? Simply put, audio data is any data format that comes in the form of audio. At a fundamental level, there are not many ways to represent sound. The large number of audio data file types is due to the number of approaches to compress and package the data. Let\u2019s take a look at two fundamental concepts before we jump deeper - sampling rates and types of audio data formats.</p>\n<h3 id="what-is-a-sampling-rate">What Is a Sampling Rate?</h3>\n<p>A sampling rate, sometimes also referred to as a frame rate, is the number of times per second that we measure the amplitude of the signal. It is measured in frames per second or Hertz (Hz). An ideal rate can be determined using <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Nyquist\u2019s Sampling Theorem</a>. Some common sampling rates are 16 kHz (common for VoiP), 44.1 kHz (common in CDs), and 96 kHz (common in DVDs and Blu-Ray).</p>\n<h3 id="types-of-audio-data">Types of Audio Data</h3>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654876366/blog/2022/06/best-python-audio-manipulation-tools/types-of-audio-data.png" alt=""></p>\n<p>There\u2019s one well known way to represent sound - using waves. However, computers can represent that data in many ways. The most common audio data file types are <code is:raw>.wav</code> and <code is:raw>.mp3</code>. The main difference between <code is:raw>.wav</code> and <code is:raw>.mp3</code> files is that <code is:raw>.wav</code> files are not compressed and <code is:raw>.mp3</code> files are. This makes <code is:raw>.wav</code> files great for when you need the highest quality audio and <code is:raw>.mp3</code> files best when you need fast streaming.</p>\n<p>Other file types include Audio Interchange File Format (AIFF), raw Pulse Code Modulation (PCM) data, and Advanced Audio Coding (AAC). AIFF is a file format developed by Apple to be used on Mac OS much like WAVE files were initially developed by Microsoft. PCM is the raw audio data format. AAC\u2019s were meant to be the successor to MP3 files, but did not catch on as a replay format. However, it did catch on as a popular streaming audio format and is used by YouTube, iPhones, and Nintendo.</p>\n<h2 id="ways-to-use-audio-data">Ways To Use Audio Data</h2>\n<p>Audio data is becoming more and more ubiquitous. It\u2019s created on phone calls, remote video meeting recordings, for music and videos, and so much more. How can we use all this audio data being created? We can layer sound bites for music, change the volume of different sound streams to make it easier to hear everyone from a VoiP call, or transcribe a call to read later. Of course, this only covers some of the things we can do with sound data, there are many other valuable ways to use audio that we haven\u2019t even discovered.</p>\n<h2 id="recording-audio-data-with-python">Recording Audio Data With Python</h2>\n<p>Two of the most basic things you can do with audio data in Python are playing and recording audio. In the next two sections we\u2019ll cover how to use two popular Python sound libraries to play and record audio data. First, we\u2019ll take a look at how to record audio data with <code is:raw>sounddevice</code> and <code is:raw>pyaudio</code>.</p>\n<p>Before we get started with the code, we\u2019ll have to install the prerequisite libraries. PyAudio is a wrapper around PortAudio. The installation will be different for Windows and Mac. On Mac OS, you can use <code is:raw>brew</code> to install <code is:raw>portaudio</code> after installing your X-Code tools. For Windows, see <a href="https://stackoverflow.com/questions/52283840/i-cant-install-pyaudio-on-windows-how-to-solve-error-microsoft-visual-c-14/52284344#52284344">this answer on StackOverflow</a>.</p>\n<p>How to Install PyAudio (on Mac):</p>\n<p>xcode-select \u2014install\nbrew remove portaudio\nbrew install portaudio\npip install pyaudio</p>\n<p>If you are having trouble, use this command instead to specify your build locations for portaudio:</p>\n<p>pip install \u2014global-option=\u2018build_ext\u2019 \u2014global-option=\u201C-I$(brew \u2014prefix)/include\u201D \u2014global-option=\u201C-L$(brew \u2014prefix)/lib\u201D pyaudio</p>\n<p>To install <code is:raw>python-sounddevice</code>, run the line <code is:raw>pip install sounddevice scipy</code> in the command line. We will need <code is:raw>scipy</code> for downloading the streamed data and for later use.</p>\n<h3 id="use-pyaudio-to-record-sound">Use PyAudio To Record Sound</h3>\n<p>In this example, we\u2019re going to use PyAudio and the Python native <code is:raw>wave</code> library to record some sound and save it into a file. We\u2019ll start by importing the two libraries and declaring constants. The constants we need to declare up front are the chunk size (the number of frames saved at a time), the format (16 bit), the number of channels (1), the sampling rate (44100), the length of our recording (3 seconds), and the filename we want to save our recording to.</p>\n<p>From there, we create a PyAudio object. We\u2019ll use the PyAudio object to create a stream with the constants we set above. Then, we\u2019ll initialize an empty list of frames to hold the frames. Next, we\u2019ll use the stream to read data while we still have time left in our 3 second timeframe and save it in the chunk size of 1024 bits.</p>\n<p>We need to close and terminate our stream after 3 seconds. Finally, we\u2019ll use the <code is:raw>wave</code> library to save the streamed audio data into a <code is:raw>.wav</code> file with the preset constants we declared above.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wave</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_format </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pyaudio.paInt16</span></span>\n<span class="line"><span style="color: #C9D1D9">channels </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span></span>\n<span class="line"><span style="color: #C9D1D9">fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">44100</span><span style="color: #C9D1D9"> </span><span style="color: #8B949E"># frames per channel</span></span>\n<span class="line"><span style="color: #C9D1D9">seconds </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;output_pyaudio.wav&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">p</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">pyaudio.PyAudio()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Recording ...&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">stream </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.open(</span><span style="color: #FFA657">format</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_format,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">channels</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> channels,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">rate</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> fs,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">frames_per_buffer</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">  chunk,</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">input</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>\n<span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(fs</span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> seconds)):</span></span>\n<span class="line"><span style="color: #C9D1D9">    data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stream.read(chunk)</span></span>\n<span class="line"><span style="color: #C9D1D9">    frames.append(data)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">stream.stop_stream()</span></span>\n<span class="line"><span style="color: #C9D1D9">stream.close()</span></span>\n<span class="line"><span style="color: #C9D1D9">p.terminate()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;... Ending Recording&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> wave.open(filename, </span><span style="color: #A5D6FF">&#39;wb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> wf:</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.setnchannels(channels)</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.setsampwidth(p.get_sample_size(sample_format))</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.setframerate(fs)</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.writeframes(</span><span style="color: #FF7B72">b</span><span style="color: #A5D6FF">&#39;&#39;</span><span style="color: #C9D1D9">.join(frames))</span></span>\n<span class="line"><span style="color: #C9D1D9">    wf.close()</span></span></code></pre>\n<h3 id="record-with-python-sounddevice">Record With Python-Sounddevice</h3>\n<p>Python-Sounddevice, or just <code is:raw>sounddevice</code> when you import it or install it through <code is:raw>pip</code>, is a simple sound recording and playing library. We can see below that it takes much less code to simply make a recording than <code is:raw>pyaudio</code>.</p>\n<p>First, we import the libraries we need, <code is:raw>sounddevice</code> and the <code is:raw>write</code> function from <code is:raw>scipy.io.wavfile</code>. Next, we declare a couple constants for the sampling rate and the length of recording. Once we have those, we just record, ask <code is:raw>sounddevice</code> to wait, and then use <code is:raw>scipy</code> to write the recorded audio.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> sounddevice </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> sd</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> scipy.io.wavfile </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> write</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">44100</span></span>\n<span class="line"><span style="color: #C9D1D9">seconds </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">recording </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sd.rec(</span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(seconds</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">fs), </span><span style="color: #FFA657">samplerate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">fs, </span><span style="color: #FFA657">channels</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sd.wait()</span></span>\n<span class="line"><span style="color: #C9D1D9">write(</span><span style="color: #A5D6FF">&#39;output_sounddevice.wav&#39;</span><span style="color: #C9D1D9">, fs, recording)</span></span></code></pre>\n<h2 id="playing-audio-data-with-python">Playing Audio Data With Python</h2>\n<p>Playing audio data is the sister function to recording audio data. Only being able to record data would be almost useless. For this section, we\u2019re going to use the same libraries we did above, <code is:raw>pyaudio</code>, and <code is:raw>sounddevice</code>. However, we will also need one more library for using <code is:raw>sounddevice</code> to play audio data, <code is:raw>soundfile</code>. We need to run this command in the terminal: <code is:raw>pip install soundfile</code> to install it.</p>\n<h3 id="use-pyaudio-to-play-audio">Use Pyaudio To Play Audio</h3>\n<p>Once again, we\u2019ll use the built-in <code is:raw>wave</code> library along with <code is:raw>pyaudio</code> to play some sound. We\u2019ll use the recording we made above and the same chunk size. We will start our functionality by opening the file and creating a <code is:raw>pyaudio</code> object.</p>\n<p>We will then use the <code is:raw>pyaudio</code> object to open a stream with specifications extracted from the wave file. Next, we\u2019ll create a data object that reads the frames of the wave file in the specified chunk size. To actually play the sound, we\u2019ll loop through the data file and write it to the stream while it is not an empty bit. Finally, we\u2019ll close the stream and terminate the <code is:raw>pyaudio</code> object.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyaudio</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wave</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># declare constants and initialize portaudio/pyaudio object</span></span>\n<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span></span>\n<span class="line"><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>\n<span class="line"><span style="color: #C9D1D9">wf </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wave.open(filename, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">pa </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pyaudio.PyAudio()</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># create stream using info from the file</span></span>\n<span class="line"><span style="color: #C9D1D9">stream </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pa.open(</span><span style="color: #FFA657">format</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pa.get_format_from_width(wf.getsampwidth()),</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">channels</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.getnchannels(),</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">rate</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.getframerate(),</span></span>\n<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">output</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># read in the frames as data</span></span>\n<span class="line"><span style="color: #C9D1D9">data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.readframes(chunk)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># while the data isn&#39;t empty</span></span>\n<span class="line"><span style="color: #FF7B72">while</span><span style="color: #C9D1D9"> data </span><span style="color: #FF7B72">!=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">b</span><span style="color: #A5D6FF">&#39;&#39;</span><span style="color: #C9D1D9">:</span></span>\n<span class="line"><span style="color: #C9D1D9">    stream.write(data)</span></span>\n<span class="line"><span style="color: #C9D1D9">    data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.readframes(chunk)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># cleanup</span></span>\n<span class="line"><span style="color: #C9D1D9">stream.close()</span></span>\n<span class="line"><span style="color: #C9D1D9">pa.terminate()</span></span></code></pre>\n<h3 id="play-audio-with-python-sounddevice">Play Audio With Python-sounddevice</h3>\n<p>Once again, we see the simplification of playing audio that <code is:raw>sounddevice</code> offers over <code is:raw>pyaudio</code>. Remember that both the playing and recording simplifications also come with the need to install and use two extra libraries though.</p>\n<p>For this example, we will import the <code is:raw>sounddevice</code> and <code is:raw>soundfile</code> libraries. Then, we will feed the filename to <code is:raw>soundfile</code> to <code is:raw>read</code> us the data and the sampling rate. Finally, we use <code is:raw>sounddevice</code> to <code is:raw>play</code> the resulting sound and make the process wait while the sound finishes playing.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> sounddevice</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> soundfile</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;output_sounddevice.wav&quot;</span></span>\n<span class="line"><span style="color: #C9D1D9">data, fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> soundfile.read(filename, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;float32&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sounddevice.play(data, fs)</span></span>\n<span class="line"><span style="color: #C9D1D9">status </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sounddevice.wait()</span></span></code></pre>\n<h2 id="clipping-audio-data-with-python">Clipping Audio Data With Python</h2>\n<p>Now that we\u2019ve covered the simplest acts of playing and recording audio, let\u2019s move onto how to change the audio data. The first thing we\u2019ll cover is clipping or trimming audio data. For this example, we\u2019ll need to install two more libraries, <code is:raw>pydub</code> and <code is:raw>ffmpeg-python</code>. We can install these with pip in the command line as usual using <code is:raw>pip install pydub ffmpeg-python</code>.</p>\n<h3 id="clip-audio-with-pydub">Clip Audio With Pydub</h3>\n<p>As we will see here and further down the post, the <code is:raw>pydub</code> library is a swiss army knife of audio manipulation tools. To trim audio data with <code is:raw>pydub</code>, we only need the <code is:raw>AudioSegment</code> object. To start, we\u2019ll define the first and last milliseconds we want to clip out. Then, we\u2019ll load the audio file with <code is:raw>AudioSegment</code>.</p>\n<p>To clip our audio file down, we\u2019ll create a list that only contains the data from the start to the end millisecond in our audio file. Finally, we\u2019ll use the <code is:raw>export</code> function of the <code is:raw>AudioSegment</code> object we extracted to save the file in <code is:raw>.wav</code> format.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># start at 0 milliseconds</span></span>\n<span class="line"><span style="color: #8B949E"># end at 1500 milliseconds</span></span>\n<span class="line"><span style="color: #C9D1D9">start </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>\n<span class="line"><span style="color: #C9D1D9">end </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1500</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;output_pyaudio.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">extract </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound[start:end]</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">extract.export(</span><span style="color: #A5D6FF">&quot;trimmed_output_pydub.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h3 id="trim-audio-clips-with-ffmpeg">Trim Audio Clips With FFMPEG</h3>\n<p>FFMPEG is a well known audio manipulation library, usually used in the command line. You can use the <code is:raw>sys</code> and <code is:raw>subprocess</code> libraries that are native to Python to use FFMPEG, but I find that using the SDK is easier and more satisfying.</p>\n<p>Even though we had to install this SDK with <code is:raw>pip install ffmpeg-python</code>, we actually import it as just <code is:raw>ffmpeg</code>. The first thing we\u2019ll do is get an input object. Then, we\u2019ll use the <code is:raw>ffmpeg.input</code> object to call the <code is:raw>atrim</code> function and trim the recording down to 1 second. Next, we\u2019ll create an output using the newly cut data. Finally, we\u2019ll need to call <code is:raw>ffmpeg</code> to actually run the <code is:raw>output</code> call and save our file.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> ffmpeg</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">audio_input </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ffmpeg.input(</span><span style="color: #A5D6FF">&quot;output_sounddevice.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">audio_cut </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> audio_input.audio.filter(</span><span style="color: #A5D6FF">&#39;atrim&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">duration</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">audio_output </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ffmpeg.output(audio_cut, </span><span style="color: #A5D6FF">&#39;trimmed_output_ffmpeg.wav&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;wav&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">ffmpeg.run(audio_output)</span></span></code></pre>\n<h2 id="manipulating-audio-data-sampling-rates-with-python">Manipulating Audio Data Sampling Rates With Python</h2>\n<p>Here\u2019s where things get a bit trickier. Sampling rates play a huge part in how audio data sounds. When you\u2019re changing the number of frames per second that represents a sound, a lot of funky things can happen. If not done right, it can affect the speed, the pitch, and the quality of your sound. For our examples, we\u2019ll be using <code is:raw>pydub</code> and <code is:raw>scipy</code>. Both libraries we already downloaded earlier.</p>\n<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654876364/blog/2022/06/best-python-audio-manipulation-tools/sample-rate.png" alt="Sample Rate Change in Audio File"></p>\n<h3 id="pydub">Pydub</h3>\n<p>As mentioned above, <code is:raw>pydub</code> has a variety of tools for manipulating audio data, and changing the sample rate safely is one of them. The <code is:raw>AudioSegment</code> object has a wonderful <code is:raw>set_frame_rate</code> command that can be used to set the frame rate of the audio segment without changing the pitch, speed, or applying any other distortions. To save it, we will use the <code is:raw>export</code> function again.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound_w_new_fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound.set_frame_rate(</span><span style="color: #79C0FF">16000</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound_w_new_fs.export(</span><span style="color: #A5D6FF">&quot;new_fs_output_pydub.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h3 id="scipy">Scipy</h3>\n<p>If you are so inclined and also mathematically skilled, you can apply your own sampling rate change with <code is:raw>scipy</code>. The most popular reasons to use <code is:raw>scipy</code> to customize your sampling is for advanced use cases like research, music, or special effects.</p>\n<p>Read in the sample rate and audio data using <code is:raw>wavfile</code>. Using the read-in sample rate and a desired new sample rate, create a new number of samples. To do the resampling, we call on the <code is:raw>resample</code> function from <code is:raw>scipy.signal</code>. This resample function applies a fourier transform and may cause distortion. This is a much more advanced technique and should probably only be used if necessary.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> scipy.io </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wavfile</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> scipy.signal</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">new_fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">88200</span></span>\n<span class="line"><span style="color: #8B949E"># open data</span></span>\n<span class="line"><span style="color: #C9D1D9">sample_rate, data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wavfile.read(</span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># resample data</span></span>\n<span class="line"><span style="color: #C9D1D9">new_num_samples </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">round</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">len</span><span style="color: #C9D1D9">(data)</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">float</span><span style="color: #C9D1D9">(new_fs)</span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9">sample_rate)</span></span>\n<span class="line"><span style="color: #C9D1D9">data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> scipy.signal.resample(data, new_num_samples)</span></span>\n<span class="line"><span style="color: #C9D1D9">wavfile.write(</span><span style="color: #FFA657">filename</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;new_fs_output_scipy.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">88200</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">data</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">data)</span></span></code></pre>\n<h2 id="changing-volume-of-audio-data-with-python">Changing Volume of Audio Data with Python</h2>\n<p>The next four things we\u2019re going to cover all use <code is:raw>pydub</code>. Partially because it is the easiest to use, partially because it is the only one that is updated enough to work with the latest versions of Python.</p>\n<p>Changing volume with the <code is:raw>AudioSegment</code> object from <code is:raw>pydub</code> is extremely easy. After importing the libraries and functions we need and opening up the <code is:raw>.wav</code> file, the only thing we need to do is add or subtract from the object representing the open <code is:raw>.wav</code> file.</p>\n<p>The <code is:raw>play</code> function plays both sounds, one after the other, so that we can hear that one is louder and the other is softer. We can save the files using the <code is:raw>export</code> function as we have been doing so far.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;new_fs_output_pydub.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #8B949E"># 3 dB up</span></span>\n<span class="line"><span style="color: #C9D1D9">louder </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"><span style="color: #8B949E"># 3 dB down</span></span>\n<span class="line"><span style="color: #C9D1D9">quieter </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">play(louder)</span></span>\n<span class="line"><span style="color: #C9D1D9">play(quieter)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">louder.export(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">quieter.export(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="combining-two-audio-files-with-python">Combining Two Audio Files With Python</h2>\n<p>We can also use <code is:raw>pydub</code> to combine two audio data files in Python. Once we open up the <code is:raw>.wav</code> files with <code is:raw>AudioSegment</code>, all we have to do to append them is add them. We can play the sound to make sure we got it and then export it into a file.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">combined </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound1 </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> sound2</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">play(combined)</span></span>\n<span class="line"><span style="color: #C9D1D9">combined.export(</span><span style="color: #A5D6FF">&quot;louder_and_quieter.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="overlay-two-audio-files-with-python">Overlay Two Audio Files With Python</h2>\n<p>You\u2019d think that overlaying audio data would be harder than combining them, but the <code is:raw>AudioSegment</code> object from the <code is:raw>pydub</code> library makes it quite easy. All we do is call the <code is:raw>overlay</code> function and pass it the sound we want to overlay and the position (in milliseconds) we want to overlay it at.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">sound1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">sound2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">overlay </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound1.overlay(sound2, </span><span style="color: #FFA657">position</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">play(overlay)</span></span>\n<span class="line"><span style="color: #C9D1D9">overlay.export(</span><span style="color: #A5D6FF">&quot;overlaid_1sec_offset.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="changing-audio-data-file-formats-with-python">Changing Audio Data File Formats With Python</h2>\n<p>We\u2019ve covered a lot of ways to manipulate audio data in Python from the basic playing and recording to overlaying different sounds. What if we just need our audio file in a different format? We can also use <code is:raw>pydub</code> to convert audio formats.</p>\n<p>The <code is:raw>AudioSegment</code> object\u2019s <code is:raw>export</code> function that we\u2019ve been using in the sections above has the capability to define the output object\u2019s format. All we have to do to save it as a different format is pass that format to the <code is:raw>export</code> function. In the example below, I\u2019ve opened up a <code is:raw>.wav</code> file and saved it as a <code is:raw>.mp3</code>.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">wav_audio </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">mp3_audio </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wav_audio.export(</span><span style="color: #A5D6FF">&quot;louder.mp3&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;mp3&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>\n<h2 id="transcribe-audio-data-with-a-web-api">Transcribe Audio Data With a Web API</h2>\n<p>Finally, we come to the last bit of audio data manipulation to be covered in this primer to audio data in Python. Having the transcription of an audio file can be useful for many reasons. You can use it to <a href="https://blog.deepgram.com/python-graphing-transcripts/">visualize your data</a>, <a href="https://blog.deepgram.com/python-script-compliance/">search for keywords from a library of audio files</a>, or get inputs for Natural Language Understanding (NLU) models.</p>\n<p>To transcribe your audio with a Web API, you\u2019ll need to sign up for a <a href="https://console.deepgram.com/signup?jump=keys">free Deepgram API key</a> and run <code is:raw>pip install deepgram-sdk</code> in your terminal.</p>\n<p>We\u2019ll be using <code is:raw>asyncio</code> to asynchronously make the API request. Before we create our function, we need to make sure that we have the API key and the file name. The function will initialize the Deepgram SDK, open the local file, and send it to the transcription endpoint. Then it will wait for the response and dump it into a JSON file formatted with a tab of 4 spaces. We will then both print the JSON result to the terminal and save it as a <code is:raw>.txt</code> file. Finally, we\u2019ll use <code is:raw>asyncio</code> to run the function.</p>\n<pre is:raw class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>\n<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> config </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> dg_secret_key</span></span>\n<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio, json</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dg_secret_key</span></span>\n<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;louder_output.wav&#39;</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">main</span><span style="color: #C9D1D9">():</span></span>\n<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>\n<span class="line"><span style="color: #C9D1D9">    deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(</span><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #8B949E"># Open the audio file</span></span>\n<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>\n<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>\n<span class="line"><span style="color: #C9D1D9">        source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>\n<span class="line"><span style="color: #C9D1D9">        response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">})</span></span>\n<span class="line"><span style="color: #C9D1D9">        json_obj </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> json.dumps(response, </span><span style="color: #FFA657">indent</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">)</span></span>\n<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(json_obj)</span></span>\n<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;transcribed.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>\n<span class="line"><span style="color: #C9D1D9">            f.write(json_obj)</span></span>\n<span class="line"></span>\n<span class="line"><span style="color: #C9D1D9">asyncio.run(main())</span></span></code></pre>\n<h2 id="summary-of-the-best-python-tools-for-manipulating-audio-data">Summary of the Best Python Tools for Manipulating Audio Data</h2>\n<p>Audio data covers a large swath of data that isn\u2019t commonly thought about when it comes to data analysis and manipulation. In this post, we covered how to use some of the most up-to-date Python libraries for manipulating audio data.</p>\n<p>We learned how to play and record audio data using <code is:raw>pyaudio</code> and <code is:raw>python-sounddevice</code>. How to trim data with <code is:raw>pydub</code> and <code is:raw>ffmpeg</code>, and how to resample data with <code is:raw>pydub</code> and <code is:raw>scipy</code>. Then we saw how we can use <code is:raw>pydub</code> as a swiss army knife of audio to change the volume, combine or overlay files, and change the file format. Finally, we saw how we can easily use the Deepgram SDK to transcribe audio data.</p>\n<h2 id="further-reading">Further Reading</h2>\n<ul>\n<li>\n<p><a href="https://www.ling.upenn.edu/courses/Spring_2003/ling538/Lecnotes/AudioData.html">Lecture Notes on Audio Data from Penn</a></p>\n</li>\n<li>\n<p><a href="https://en.wikipedia.org/wiki/Audio_file_format">Audio File Formats</a></p>\n</li>\n</ul>';
}
const $$Astro = createAstro("/Users/sandrarodgers/web-next/blog/src/content/blog/posts/best-python-audio-manipulation-tools/index.md", "", "file:///Users/sandrarodgers/web-next/blog/");
const $$Index = createComponent(async ($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$Index;
  new Slugger();
  return renderTemplate`<head>${renderHead($$result)}</head><p>Python provides us with many packages to manipulate audio data, but they dont all work. As Python developers, were all familiar with the usual challenges - solving environments, compatibility between versions, and finding the right packages. This post covers how to do all of that for working with audio data. You can find a <a href="https://github.com/deepgram-devs/basic_audio_data_manip">GitHub repo here</a> with all the samples discussed below.</p>
<p>Note that this post is written using Python 3.9 as many audio packages have not yet been upgraded to work with 3.10 or 3.11. In this post well cover:</p>
<ul>
<li><a href="#an-introduction-to-audio-data">An Introduction to Audio Data</a></li>
<li><a href="#ways-to-use-audio-data">Ways To Use Audio Data</a></li>
<li><a href="#recording-audio-data-with-python">Recording Audio Data With Python</a></li>
<li><a href="#playing-audio-data-with-python">Playing Audio Data With Python</a></li>
<li><a href="#clipping-audio-data-with-python">Clipping Audio Data With Python</a></li>
<li><a href="#manipulating-audio-data-sampling-rates-with-python">Manipulating Audio Data Sampling Rates With Python</a></li>
<li><a href="#changing-volume-of-audio-data-with-python">Changing Volume of Audio Data With Python</a></li>
<li><a href="#combining-two-audio-files-with-python">Combining Two Audio Files With Python</a></li>
<li><a href="#overlay-two-audio-files-with-python">Overlay Two Audio Files With Python</a></li>
<li><a href="#changing-audio-data-file-formats-with-python">Changing Audio Data File Formats With Python</a></li>
<li><a href="#transcribe-audio-data-with-a-web-api">Transcribe Audio Data With a Web API</a></li>
<li><a href="#summary-of-the-best-python-tools-for-manipulating-audio-data">Summary of the Best Python Tools for Manipulating Audio Data</a></li>
</ul>
<h2 id="an-introduction-to-audio-data">An Introduction to Audio Data</h2>
<p>What is audio data? Simply put, audio data is any data format that comes in the form of audio. At a fundamental level, there are not many ways to represent sound. The large number of audio data file types is due to the number of approaches to compress and package the data. Lets take a look at two fundamental concepts before we jump deeper - sampling rates and types of audio data formats.</p>
<h3 id="what-is-a-sampling-rate">What Is a Sampling Rate?</h3>
<p>A sampling rate, sometimes also referred to as a frame rate, is the number of times per second that we measure the amplitude of the signal. It is measured in frames per second or Hertz (Hz). An ideal rate can be determined using <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Nyquists Sampling Theorem</a>. Some common sampling rates are 16 kHz (common for VoiP), 44.1 kHz (common in CDs), and 96 kHz (common in DVDs and Blu-Ray).</p>
<h3 id="types-of-audio-data">Types of Audio Data</h3>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654876366/blog/2022/06/best-python-audio-manipulation-tools/types-of-audio-data.png" alt=""></p>
<p>Theres one well known way to represent sound - using waves. However, computers can represent that data in many ways. The most common audio data file types are <code>.wav</code> and <code>.mp3</code>. The main difference between <code>.wav</code> and <code>.mp3</code> files is that <code>.wav</code> files are not compressed and <code>.mp3</code> files are. This makes <code>.wav</code> files great for when you need the highest quality audio and <code>.mp3</code> files best when you need fast streaming.</p>
<p>Other file types include Audio Interchange File Format (AIFF), raw Pulse Code Modulation (PCM) data, and Advanced Audio Coding (AAC). AIFF is a file format developed by Apple to be used on Mac OS much like WAVE files were initially developed by Microsoft. PCM is the raw audio data format. AACs were meant to be the successor to MP3 files, but did not catch on as a replay format. However, it did catch on as a popular streaming audio format and is used by YouTube, iPhones, and Nintendo.</p>
<h2 id="ways-to-use-audio-data">Ways To Use Audio Data</h2>
<p>Audio data is becoming more and more ubiquitous. Its created on phone calls, remote video meeting recordings, for music and videos, and so much more. How can we use all this audio data being created? We can layer sound bites for music, change the volume of different sound streams to make it easier to hear everyone from a VoiP call, or transcribe a call to read later. Of course, this only covers some of the things we can do with sound data, there are many other valuable ways to use audio that we havent even discovered.</p>
<h2 id="recording-audio-data-with-python">Recording Audio Data With Python</h2>
<p>Two of the most basic things you can do with audio data in Python are playing and recording audio. In the next two sections well cover how to use two popular Python sound libraries to play and record audio data. First, well take a look at how to record audio data with <code>sounddevice</code> and <code>pyaudio</code>.</p>
<p>Before we get started with the code, well have to install the prerequisite libraries. PyAudio is a wrapper around PortAudio. The installation will be different for Windows and Mac. On Mac OS, you can use <code>brew</code> to install <code>portaudio</code> after installing your X-Code tools. For Windows, see <a href="https://stackoverflow.com/questions/52283840/i-cant-install-pyaudio-on-windows-how-to-solve-error-microsoft-visual-c-14/52284344#52284344">this answer on StackOverflow</a>.</p>
<p>How to Install PyAudio (on Mac):</p>
<p>xcode-select install
brew remove portaudio
brew install portaudio
pip install pyaudio</p>
<p>If you are having trouble, use this command instead to specify your build locations for portaudio:</p>
<p>pip install global-option=build_ext global-option=-I$(brew prefix)/include global-option=-L$(brew prefix)/lib pyaudio</p>
<p>To install <code>python-sounddevice</code>, run the line <code>pip install sounddevice scipy</code> in the command line. We will need <code>scipy</code> for downloading the streamed data and for later use.</p>
<h3 id="use-pyaudio-to-record-sound">Use PyAudio To Record Sound</h3>
<p>In this example, were going to use PyAudio and the Python native <code>wave</code> library to record some sound and save it into a file. Well start by importing the two libraries and declaring constants. The constants we need to declare up front are the chunk size (the number of frames saved at a time), the format (16 bit), the number of channels (1), the sampling rate (44100), the length of our recording (3 seconds), and the filename we want to save our recording to.</p>
<p>From there, we create a PyAudio object. Well use the PyAudio object to create a stream with the constants we set above. Then, well initialize an empty list of frames to hold the frames. Next, well use the stream to read data while we still have time left in our 3 second timeframe and save it in the chunk size of 1024 bits.</p>
<p>We need to close and terminate our stream after 3 seconds. Finally, well use the <code>wave</code> library to save the streamed audio data into a <code>.wav</code> file with the preset constants we declared above.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyaudio</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wave</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>
<span class="line"><span style="color: #C9D1D9">sample_format </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pyaudio.paInt16</span></span>
<span class="line"><span style="color: #C9D1D9">channels </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1</span></span>
<span class="line"><span style="color: #C9D1D9">fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">44100</span><span style="color: #C9D1D9"> </span><span style="color: #8B949E"># frames per channel</span></span>
<span class="line"><span style="color: #C9D1D9">seconds </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>
<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;output_pyaudio.wav&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">p</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">pyaudio.PyAudio()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;Recording ...&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">stream </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> p.open(</span><span style="color: #FFA657">format</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sample_format,</span></span>
<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">channels</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> channels,</span></span>
<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">rate</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> fs,</span></span>
<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">frames_per_buffer</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">  chunk,</span></span>
<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">input</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">frames </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> []</span></span>
<span class="line"><span style="color: #FF7B72">for</span><span style="color: #C9D1D9"> i </span><span style="color: #FF7B72">in</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">range</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">0</span><span style="color: #C9D1D9">, </span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(fs</span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9"> seconds)):</span></span>
<span class="line"><span style="color: #C9D1D9">    data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> stream.read(chunk)</span></span>
<span class="line"><span style="color: #C9D1D9">    frames.append(data)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">stream.stop_stream()</span></span>
<span class="line"><span style="color: #C9D1D9">stream.close()</span></span>
<span class="line"><span style="color: #C9D1D9">p.terminate()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;... Ending Recording&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> wave.open(filename, </span><span style="color: #A5D6FF">&#39;wb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> wf:</span></span>
<span class="line"><span style="color: #C9D1D9">    wf.setnchannels(channels)</span></span>
<span class="line"><span style="color: #C9D1D9">    wf.setsampwidth(p.get_sample_size(sample_format))</span></span>
<span class="line"><span style="color: #C9D1D9">    wf.setframerate(fs)</span></span>
<span class="line"><span style="color: #C9D1D9">    wf.writeframes(</span><span style="color: #FF7B72">b</span><span style="color: #A5D6FF">&#39;&#39;</span><span style="color: #C9D1D9">.join(frames))</span></span>
<span class="line"><span style="color: #C9D1D9">    wf.close()</span></span></code></pre>
<h3 id="record-with-python-sounddevice">Record With Python-Sounddevice</h3>
<p>Python-Sounddevice, or just <code>sounddevice</code> when you import it or install it through <code>pip</code>, is a simple sound recording and playing library. We can see below that it takes much less code to simply make a recording than <code>pyaudio</code>.</p>
<p>First, we import the libraries we need, <code>sounddevice</code> and the <code>write</code> function from <code>scipy.io.wavfile</code>. Next, we declare a couple constants for the sampling rate and the length of recording. Once we have those, we just record, ask <code>sounddevice</code> to wait, and then use <code>scipy</code> to write the recorded audio.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> sounddevice </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> sd</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> scipy.io.wavfile </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> write</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">44100</span></span>
<span class="line"><span style="color: #C9D1D9">seconds </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">recording </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sd.rec(</span><span style="color: #79C0FF">int</span><span style="color: #C9D1D9">(seconds</span><span style="color: #FF7B72">*</span><span style="color: #C9D1D9">fs), </span><span style="color: #FFA657">samplerate</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">fs, </span><span style="color: #FFA657">channels</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">sd.wait()</span></span>
<span class="line"><span style="color: #C9D1D9">write(</span><span style="color: #A5D6FF">&#39;output_sounddevice.wav&#39;</span><span style="color: #C9D1D9">, fs, recording)</span></span></code></pre>
<h2 id="playing-audio-data-with-python">Playing Audio Data With Python</h2>
<p>Playing audio data is the sister function to recording audio data. Only being able to record data would be almost useless. For this section, were going to use the same libraries we did above, <code>pyaudio</code>, and <code>sounddevice</code>. However, we will also need one more library for using <code>sounddevice</code> to play audio data, <code>soundfile</code>. We need to run this command in the terminal: <code>pip install soundfile</code> to install it.</p>
<h3 id="use-pyaudio-to-play-audio">Use Pyaudio To Play Audio</h3>
<p>Once again, well use the built-in <code>wave</code> library along with <code>pyaudio</code> to play some sound. Well use the recording we made above and the same chunk size. We will start our functionality by opening the file and creating a <code>pyaudio</code> object.</p>
<p>We will then use the <code>pyaudio</code> object to open a stream with specifications extracted from the wave file. Next, well create a data object that reads the frames of the wave file in the specified chunk size. To actually play the sound, well loop through the data file and write it to the stream while it is not an empty bit. Finally, well close the stream and terminate the <code>pyaudio</code> object.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> pyaudio</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wave</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># declare constants and initialize portaudio/pyaudio object</span></span>
<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span></span>
<span class="line"><span style="color: #C9D1D9">chunk </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1024</span></span>
<span class="line"><span style="color: #C9D1D9">wf </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wave.open(filename, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">pa </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pyaudio.PyAudio()</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># create stream using info from the file</span></span>
<span class="line"><span style="color: #C9D1D9">stream </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pa.open(</span><span style="color: #FFA657">format</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> pa.get_format_from_width(wf.getsampwidth()),</span></span>
<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">channels</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.getnchannels(),</span></span>
<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">rate</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.getframerate(),</span></span>
<span class="line"><span style="color: #C9D1D9">                </span><span style="color: #FFA657">output</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># read in the frames as data</span></span>
<span class="line"><span style="color: #C9D1D9">data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.readframes(chunk)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># while the data isn&#39;t empty</span></span>
<span class="line"><span style="color: #FF7B72">while</span><span style="color: #C9D1D9"> data </span><span style="color: #FF7B72">!=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">b</span><span style="color: #A5D6FF">&#39;&#39;</span><span style="color: #C9D1D9">:</span></span>
<span class="line"><span style="color: #C9D1D9">    stream.write(data)</span></span>
<span class="line"><span style="color: #C9D1D9">    data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wf.readframes(chunk)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># cleanup</span></span>
<span class="line"><span style="color: #C9D1D9">stream.close()</span></span>
<span class="line"><span style="color: #C9D1D9">pa.terminate()</span></span></code></pre>
<h3 id="play-audio-with-python-sounddevice">Play Audio With Python-sounddevice</h3>
<p>Once again, we see the simplification of playing audio that <code>sounddevice</code> offers over <code>pyaudio</code>. Remember that both the playing and recording simplifications also come with the need to install and use two extra libraries though.</p>
<p>For this example, we will import the <code>sounddevice</code> and <code>soundfile</code> libraries. Then, we will feed the filename to <code>soundfile</code> to <code>read</code> us the data and the sampling rate. Finally, we use <code>sounddevice</code> to <code>play</code> the resulting sound and make the process wait while the sound finishes playing.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> sounddevice</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> soundfile</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">filename </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&quot;output_sounddevice.wav&quot;</span></span>
<span class="line"><span style="color: #C9D1D9">data, fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> soundfile.read(filename, </span><span style="color: #FFA657">dtype</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;float32&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">sounddevice.play(data, fs)</span></span>
<span class="line"><span style="color: #C9D1D9">status </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sounddevice.wait()</span></span></code></pre>
<h2 id="clipping-audio-data-with-python">Clipping Audio Data With Python</h2>
<p>Now that weve covered the simplest acts of playing and recording audio, lets move onto how to change the audio data. The first thing well cover is clipping or trimming audio data. For this example, well need to install two more libraries, <code>pydub</code> and <code>ffmpeg-python</code>. We can install these with pip in the command line as usual using <code>pip install pydub ffmpeg-python</code>.</p>
<h3 id="clip-audio-with-pydub">Clip Audio With Pydub</h3>
<p>As we will see here and further down the post, the <code>pydub</code> library is a swiss army knife of audio manipulation tools. To trim audio data with <code>pydub</code>, we only need the <code>AudioSegment</code> object. To start, well define the first and last milliseconds we want to clip out. Then, well load the audio file with <code>AudioSegment</code>.</p>
<p>To clip our audio file down, well create a list that only contains the data from the start to the end millisecond in our audio file. Finally, well use the <code>export</code> function of the <code>AudioSegment</code> object we extracted to save the file in <code>.wav</code> format.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># start at 0 milliseconds</span></span>
<span class="line"><span style="color: #8B949E"># end at 1500 milliseconds</span></span>
<span class="line"><span style="color: #C9D1D9">start </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">0</span></span>
<span class="line"><span style="color: #C9D1D9">end </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">1500</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;output_pyaudio.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">extract </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound[start:end]</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">extract.export(</span><span style="color: #A5D6FF">&quot;trimmed_output_pydub.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<h3 id="trim-audio-clips-with-ffmpeg">Trim Audio Clips With FFMPEG</h3>
<p>FFMPEG is a well known audio manipulation library, usually used in the command line. You can use the <code>sys</code> and <code>subprocess</code> libraries that are native to Python to use FFMPEG, but I find that using the SDK is easier and more satisfying.</p>
<p>Even though we had to install this SDK with <code>pip install ffmpeg-python</code>, we actually import it as just <code>ffmpeg</code>. The first thing well do is get an input object. Then, well use the <code>ffmpeg.input</code> object to call the <code>atrim</code> function and trim the recording down to 1 second. Next, well create an output using the newly cut data. Finally, well need to call <code>ffmpeg</code> to actually run the <code>output</code> call and save our file.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> ffmpeg</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">audio_input </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ffmpeg.input(</span><span style="color: #A5D6FF">&quot;output_sounddevice.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">audio_cut </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> audio_input.audio.filter(</span><span style="color: #A5D6FF">&#39;atrim&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">duration</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">audio_output </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> ffmpeg.output(audio_cut, </span><span style="color: #A5D6FF">&#39;trimmed_output_ffmpeg.wav&#39;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&#39;wav&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">ffmpeg.run(audio_output)</span></span></code></pre>
<h2 id="manipulating-audio-data-sampling-rates-with-python">Manipulating Audio Data Sampling Rates With Python</h2>
<p>Heres where things get a bit trickier. Sampling rates play a huge part in how audio data sounds. When youre changing the number of frames per second that represents a sound, a lot of funky things can happen. If not done right, it can affect the speed, the pitch, and the quality of your sound. For our examples, well be using <code>pydub</code> and <code>scipy</code>. Both libraries we already downloaded earlier.</p>
<p><img src="https://res.cloudinary.com/deepgram/image/upload/v1654876364/blog/2022/06/best-python-audio-manipulation-tools/sample-rate.png" alt="Sample Rate Change in Audio File"></p>
<h3 id="pydub">Pydub</h3>
<p>As mentioned above, <code>pydub</code> has a variety of tools for manipulating audio data, and changing the sample rate safely is one of them. The <code>AudioSegment</code> object has a wonderful <code>set_frame_rate</code> command that can be used to set the frame rate of the audio segment without changing the pitch, speed, or applying any other distortions. To save it, we will use the <code>export</code> function again.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">sound_w_new_fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound.set_frame_rate(</span><span style="color: #79C0FF">16000</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">sound_w_new_fs.export(</span><span style="color: #A5D6FF">&quot;new_fs_output_pydub.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<h3 id="scipy">Scipy</h3>
<p>If you are so inclined and also mathematically skilled, you can apply your own sampling rate change with <code>scipy</code>. The most popular reasons to use <code>scipy</code> to customize your sampling is for advanced use cases like research, music, or special effects.</p>
<p>Read in the sample rate and audio data using <code>wavfile</code>. Using the read-in sample rate and a desired new sample rate, create a new number of samples. To do the resampling, we call on the <code>resample</code> function from <code>scipy.signal</code>. This resample function applies a fourier transform and may cause distortion. This is a much more advanced technique and should probably only be used if necessary.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> scipy.io </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> wavfile</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> scipy.signal</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">new_fs </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">88200</span></span>
<span class="line"><span style="color: #8B949E"># open data</span></span>
<span class="line"><span style="color: #C9D1D9">sample_rate, data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wavfile.read(</span><span style="color: #A5D6FF">&#39;output_pyaudio.wav&#39;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># resample data</span></span>
<span class="line"><span style="color: #C9D1D9">new_num_samples </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">round</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">len</span><span style="color: #C9D1D9">(data)</span><span style="color: #FF7B72">*</span><span style="color: #79C0FF">float</span><span style="color: #C9D1D9">(new_fs)</span><span style="color: #FF7B72">/</span><span style="color: #C9D1D9">sample_rate)</span></span>
<span class="line"><span style="color: #C9D1D9">data </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> scipy.signal.resample(data, new_num_samples)</span></span>
<span class="line"><span style="color: #C9D1D9">wavfile.write(</span><span style="color: #FFA657">filename</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;new_fs_output_scipy.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">rate</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">88200</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">data</span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9">data)</span></span></code></pre>
<h2 id="changing-volume-of-audio-data-with-python">Changing Volume of Audio Data with Python</h2>
<p>The next four things were going to cover all use <code>pydub</code>. Partially because it is the easiest to use, partially because it is the only one that is updated enough to work with the latest versions of Python.</p>
<p>Changing volume with the <code>AudioSegment</code> object from <code>pydub</code> is extremely easy. After importing the libraries and functions we need and opening up the <code>.wav</code> file, the only thing we need to do is add or subtract from the object representing the open <code>.wav</code> file.</p>
<p>The <code>play</code> function plays both sounds, one after the other, so that we can hear that one is louder and the other is softer. We can save the files using the <code>export</code> function as we have been doing so far.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">sound </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;new_fs_output_pydub.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #8B949E"># 3 dB up</span></span>
<span class="line"><span style="color: #C9D1D9">louder </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>
<span class="line"><span style="color: #8B949E"># 3 dB down</span></span>
<span class="line"><span style="color: #C9D1D9">quieter </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound </span><span style="color: #FF7B72">-</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">3</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">play(louder)</span></span>
<span class="line"><span style="color: #C9D1D9">play(quieter)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">louder.export(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">quieter.export(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<h2 id="combining-two-audio-files-with-python">Combining Two Audio Files With Python</h2>
<p>We can also use <code>pydub</code> to combine two audio data files in Python. Once we open up the <code>.wav</code> files with <code>AudioSegment</code>, all we have to do to append them is add them. We can play the sound to make sure we got it and then export it into a file.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">sound1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">sound2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">combined </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound1 </span><span style="color: #FF7B72">+</span><span style="color: #C9D1D9"> sound2</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">play(combined)</span></span>
<span class="line"><span style="color: #C9D1D9">combined.export(</span><span style="color: #A5D6FF">&quot;louder_and_quieter.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<h2 id="overlay-two-audio-files-with-python">Overlay Two Audio Files With Python</h2>
<p>Youd think that overlaying audio data would be harder than combining them, but the <code>AudioSegment</code> object from the <code>pydub</code> library makes it quite easy. All we do is call the <code>overlay</code> function and pass it the sound we want to overlay and the position (in milliseconds) we want to overlay it at.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub.playback </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> play</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">sound1 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">sound2 </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;quieter_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">overlay </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> sound1.overlay(sound2, </span><span style="color: #FFA657">position</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">1000</span><span style="color: #C9D1D9">)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">play(overlay)</span></span>
<span class="line"><span style="color: #C9D1D9">overlay.export(</span><span style="color: #A5D6FF">&quot;overlaid_1sec_offset.wav&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;wav&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<h2 id="changing-audio-data-file-formats-with-python">Changing Audio Data File Formats With Python</h2>
<p>Weve covered a lot of ways to manipulate audio data in Python from the basic playing and recording to overlaying different sounds. What if we just need our audio file in a different format? We can also use <code>pydub</code> to convert audio formats.</p>
<p>The <code>AudioSegment</code> objects <code>export</code> function that weve been using in the sections above has the capability to define the output objects format. All we have to do to save it as a different format is pass that format to the <code>export</code> function. In the example below, Ive opened up a <code>.wav</code> file and saved it as a <code>.mp3</code>.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> pydub </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> AudioSegment</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">wav_audio </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> AudioSegment.from_wav(</span><span style="color: #A5D6FF">&quot;louder_output.wav&quot;</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">mp3_audio </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> wav_audio.export(</span><span style="color: #A5D6FF">&quot;louder.mp3&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #FFA657">format</span><span style="color: #FF7B72">=</span><span style="color: #A5D6FF">&quot;mp3&quot;</span><span style="color: #C9D1D9">)</span></span></code></pre>
<h2 id="transcribe-audio-data-with-a-web-api">Transcribe Audio Data With a Web API</h2>
<p>Finally, we come to the last bit of audio data manipulation to be covered in this primer to audio data in Python. Having the transcription of an audio file can be useful for many reasons. You can use it to <a href="https://blog.deepgram.com/python-graphing-transcripts/">visualize your data</a>, <a href="https://blog.deepgram.com/python-script-compliance/">search for keywords from a library of audio files</a>, or get inputs for Natural Language Understanding (NLU) models.</p>
<p>To transcribe your audio with a Web API, youll need to sign up for a <a href="https://console.deepgram.com/signup?jump=keys">free Deepgram API key</a> and run <code>pip install deepgram-sdk</code> in your terminal.</p>
<p>Well be using <code>asyncio</code> to asynchronously make the API request. Before we create our function, we need to make sure that we have the API key and the file name. The function will initialize the Deepgram SDK, open the local file, and send it to the transcription endpoint. Then it will wait for the response and dump it into a JSON file formatted with a tab of 4 spaces. We will then both print the JSON result to the terminal and save it as a <code>.txt</code> file. Finally, well use <code>asyncio</code> to run the function.</p>
<pre class="astro-code" style="background-color: #0d1117; overflow-x: auto;"><code><span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> deepgram </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> Deepgram</span></span>
<span class="line"><span style="color: #FF7B72">from</span><span style="color: #C9D1D9"> config </span><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> dg_secret_key</span></span>
<span class="line"><span style="color: #FF7B72">import</span><span style="color: #C9D1D9"> asyncio, json</span></span>
<span class="line"></span>
<span class="line"><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> dg_secret_key</span></span>
<span class="line"><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #A5D6FF">&#39;louder_output.wav&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color: #FF7B72">async</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">def</span><span style="color: #C9D1D9"> </span><span style="color: #D2A8FF">main</span><span style="color: #C9D1D9">():</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #8B949E"># Initializes the Deepgram SDK</span></span>
<span class="line"><span style="color: #C9D1D9">    deepgram </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> Deepgram(</span><span style="color: #79C0FF">DEEPGRAM_API_KEY</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #8B949E"># Open the audio file</span></span>
<span class="line"><span style="color: #C9D1D9">    </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #79C0FF">PATH_TO_FILE</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&#39;rb&#39;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> audio:</span></span>
<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #8B949E"># ...or replace mimetype as appropriate</span></span>
<span class="line"><span style="color: #C9D1D9">        source </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> {</span><span style="color: #A5D6FF">&#39;buffer&#39;</span><span style="color: #C9D1D9">: audio, </span><span style="color: #A5D6FF">&#39;mimetype&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #A5D6FF">&#39;audio/wav&#39;</span><span style="color: #C9D1D9">}</span></span>
<span class="line"><span style="color: #C9D1D9">        response </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> </span><span style="color: #FF7B72">await</span><span style="color: #C9D1D9"> deepgram.transcription.prerecorded(source, {</span><span style="color: #A5D6FF">&#39;punctuate&#39;</span><span style="color: #C9D1D9">: </span><span style="color: #79C0FF">True</span><span style="color: #C9D1D9">})</span></span>
<span class="line"><span style="color: #C9D1D9">        json_obj </span><span style="color: #FF7B72">=</span><span style="color: #C9D1D9"> json.dumps(response, </span><span style="color: #FFA657">indent</span><span style="color: #FF7B72">=</span><span style="color: #79C0FF">4</span><span style="color: #C9D1D9">)</span></span>
<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #79C0FF">print</span><span style="color: #C9D1D9">(json_obj)</span></span>
<span class="line"><span style="color: #C9D1D9">        </span><span style="color: #FF7B72">with</span><span style="color: #C9D1D9"> </span><span style="color: #79C0FF">open</span><span style="color: #C9D1D9">(</span><span style="color: #A5D6FF">&quot;transcribed.txt&quot;</span><span style="color: #C9D1D9">, </span><span style="color: #A5D6FF">&quot;w&quot;</span><span style="color: #C9D1D9">) </span><span style="color: #FF7B72">as</span><span style="color: #C9D1D9"> f:</span></span>
<span class="line"><span style="color: #C9D1D9">            f.write(json_obj)</span></span>
<span class="line"></span>
<span class="line"><span style="color: #C9D1D9">asyncio.run(main())</span></span></code></pre>
<h2 id="summary-of-the-best-python-tools-for-manipulating-audio-data">Summary of the Best Python Tools for Manipulating Audio Data</h2>
<p>Audio data covers a large swath of data that isnt commonly thought about when it comes to data analysis and manipulation. In this post, we covered how to use some of the most up-to-date Python libraries for manipulating audio data.</p>
<p>We learned how to play and record audio data using <code>pyaudio</code> and <code>python-sounddevice</code>. How to trim data with <code>pydub</code> and <code>ffmpeg</code>, and how to resample data with <code>pydub</code> and <code>scipy</code>. Then we saw how we can use <code>pydub</code> as a swiss army knife of audio to change the volume, combine or overlay files, and change the file format. Finally, we saw how we can easily use the Deepgram SDK to transcribe audio data.</p>
<h2 id="further-reading">Further Reading</h2>
<ul>
<li>
<p><a href="https://www.ling.upenn.edu/courses/Spring_2003/ling538/Lecnotes/AudioData.html">Lecture Notes on Audio Data from Penn</a></p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Audio_file_format">Audio File Formats</a></p>
</li>
</ul>`;
}, "/Users/sandrarodgers/web-next/blog/src/content/blog/posts/best-python-audio-manipulation-tools/index.md");

export { compiledContent, $$Index as default, frontmatter, metadata, rawContent };
